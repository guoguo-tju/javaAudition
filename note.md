

任务:

1.石杉的架构课三季看完

2.力扣算法题 , 每天15道 , 先看慕课的算法课 , 小灰的算法书

3.简历中的项目 , 三板斧改造方案 , 中间件比如DRM

5.网上找面试题

6.DDD

7.spring源码

8.设计秒杀系统

9.service mesh









<h3 id="分布式篇">分布式篇</h3> 

1. 如何设计一个高并发系统 (每秒上千个请求以上

   1. **系统拆分**:  将一个大系统拆分为多个子系统 , 用分布式框架dubbo或者spring cloud来搞 , 每个系统对应一个数据库.

   2. **缓存 :**  大部分的高并发场景，都是**读多写少**，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存。毕竟 redis 轻轻松松单机几万的并发。

   3. **MQ:** 针对高并发的写场景 . 大量的写请求灌入 MQ 里进行削峰，排队慢慢玩儿，**后边系统消费后慢慢写**，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的 .

   4. **分库分表:** 请求量如果再高一些 ,可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表**拆分为多个表**，每个表的数据量保持少一点，提高 sql 跑的性能。

   5. **数据库的读写分离 :** 大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，**主库写**入，**从库读**取，搞一个读写分离。**读流量太多**的时候，还可以**加更多的从库**。

   6. **Elasticsearch**: 简称 es。es是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用
      es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。

   7. 之前搞过微服务架构，个人经历说下，阿里云ECS弹性伸缩，高峰特别是秒杀时，NGINX限流一个IP每秒1个，前端CDN静态化，还有秒杀前不要暴露真实秒杀地址，单机+cache，配置ECS感应流量，自动扩展到20-30台，单台扛几百用户单纯响应是没啥问题的（这里说的是单纯响应，就是说先确保不出现500或502这类错误），后端代码逻辑Redis防刷，需要同步调用的接口尽可能少（比如一般只走支付网关，拉起支付接口），redis+lua预热加减库存，如果需要限流redis队列排序限流等（比如队列里用户数控制最多50000），同步接口返回速度尽可能高（这里面需要JVM、各种SQL优化以及读写分离、分库分表），能走异步的尽量走异步，比如短信通知，购买成功加积分级别，抵用券等。

      忘了补充一点，事务尽可能的小，就是说都是小事务提交（不要把什么写日志，调接口也包在开启事务逻辑里面），还有乐观锁，悲观锁，间隙锁（特别是间隙锁，MySQL在RR隔离级别下产生的间隙锁要特别小心），快照读，当前读，mvcc这些一定要清楚认知和使用恰当，不然事务隔离级别下的锁竞争，平峰时快速普通SQL不光会跑到十几甚至几十秒，而且会造成MySQL线程数跑满，或者直接挂了

      ![设计一个高并发系统](C:\Users\guozh\Desktop\java\石杉\设计一个高并发系统.jpg)

      



1. 服务框架 , Dubbo , spring cloud , gRPC , Thrift . 

服务注册和发现 , 通信和序列化 , 负载均衡 , 扩展机制 , 请求重试 , 请求超时

2. spring cloud核心组件

   1. 注册中心Eureak
   2. 服务调用Feign
   3. 负载均衡Ribbon
   4. 网关Zuul / Gateway
      1. 灰度发布: 流量分发给灰度部署的机器
      2. 统一限流:
      3. 统一熔断:
      4. 统一鉴权:

3. Dubbo调用底层实现

   1. 消费者

      1. 动态代理:Proxy 
         1. 动态代理策略 : 默认使用 javassist 动态字节码生成，创建代理类。但是可以通过 spi 扩展机制配置自己的动态代理策略。
      2. 负载均衡:Cluster , 故障转移
         1. random loadbalance: 
            1. 默认情况下，dubbo 是 random load balance ，即**随机**调用实现负载均衡，可以对 provider 不同实例**设置不同的权重**，会按照权重来负载均衡，权重越大分配流量越高，一般就用这个默认的就可以了。
         2. consistanthash loadbalance
            1. 一致性 Hash 算法，相同参数的请求一定分发到一个 provider 上去，provider 挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大。**如果你需要的不是随机负载均衡**，是要一类请求都到一个节点，那就走这个一致性 Hash 策略。
      3. 通信协议:Protocol , http/rmi/dubbo等协议
         1. dubbo 协议 :  **默认**就是走 dubbo 协议，单一长连接，进行的是 NIO 异步通信，基于 hessian 作为序列化协议。使用的场景是：传输数据量小（每次请求在 100kb 以内），但是并发量很高。
         2. rmi 协议: 走 Java 二进制序列化，多个短连接，适合消费者和提供者数量差不多的情况，适用于文件的传输，一般较少用。
         3. hessian 协议: 走 hessian 序列化协议，多个短连接，适用于提供者数量比消费者数量还多的情况，适用于文件的传输，一般较少用。
         4. http 协议 : 走 json 序列化。
         5. webservice : 走 SOAP 文本序列化。
      4. 信息交换: Exchange , Request , Response
      5. 网络通信: Transport , 基于netty/mina实现
      6. 序列化: 封装好的请求序列化成二进制数组 , 通过netty/mina发送出去
         1. dubbo支持的序列化协议: dubbo 支持 hession、Java 二进制序列化、json、SOAP 文本序列化多种序列化协议。但是 hessian 是其默认的序列化协议。

   2. 生产者

      1. 反序列化
      2. 网络通信: Transport
      3. 信息交换: Exchange
      4. 通信协议: Protocol 
      5. 动态代理: Proxy

      ![Dubbo底层调用原理](C:\Users\guozh\Desktop\java\石杉\Dubbo底层调用原理.jpg)

   3. dubbo集群容错策略

      1. #### failover cluster 模式

         1. 失败自动切换，自动重试其他机器，**默认**就是这个，常见于读操作。

      2. #### failfast cluster 模式

         1. 一次调用失败就立即失败，常见于非幂等性的写操作，比如新增一条记录（调用失败就立即失败）

      3. #### failsafe cluster 模式

         1. 出现异常时忽略掉，常用于不重要的接口调用，比如记录日志。

      4. #### failback cluster 模式

         1. 失败了后台自动记录请求，然后定时重发，比较适合于写消息队列这种。

      5. #### forking cluster 模式

         1. **并行调用**多个 provider，只要一个成功就立即返回。常用于实时性要求比较高的读操作，但是会浪费更多的服务资源，可通过 `forks="2"` 来设置最大并行数。

   4. Dubbo的SPI机制

      1. SPI是啥?

         1. spi，简单来说，就是 `service provider interface`，说白了是什么意思呢，比如你有个接口，现在这个接口有 3 个实现类，那么在系统运行的时候对这个接口到底选择哪个实现类呢？这就需要 spi 了，需要**根据指定的配置**或者是**默认的配置**，去**找到对应的实现类**加载进来，然后用这个实现类的实例对象。
         2. spi 经典的思想体现，大家平时都在用，比如说 jdbc。Java 定义了一套 jdbc 的接口，但是 Java 并没有提供 jdbc 的实现类。但是实际上项目跑的时候，要使用 jdbc 接口的哪些实现类呢？一般来说，我们要**根据自己使用的数据库**，比如 mysql，你就将 `mysql-jdbc-connector.jar` 引入进来；oracle，你就将 `oracle-jdbc-connector.jar` 引入进来。

      2. dubbo 也用了 spi 思想，不过没有用 jdk 的 spi 机制，是自己实现的一套 spi 机制。

         ```
         Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();
         ```

         Protocol 接口，在系统运行的时候，，dubbo 会判断一下应该选用这个 Protocol 接口的哪个实现类来实例化对象来使用。它会去找一个你配置的 Protocol，将你配置的 Protocol 实现类，加载到 jvm 中来，然后实例化对象，就用你的那个 Protocol 实现类就可以了。

         实例代码: https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/distributed-system/dubbo-spi.md

         ![dubbo的spi机制](C:\Users\guozh\Desktop\java\石杉\dubbo的spi机制.png)

   5. Dubbo的服务治理,服务降级 , 失败重试,超时机制

      1. 服务治理

         1. 调用链路自动生成
         2. 服务访问压力以及时长统计
         3. 调用链路失败监控和报警 , 接口的可用率
         4. 服务分层（避免循环依赖）

      2. 服务降级

         1. 比如说服务 A 调用服务 B，结果服务 B 挂掉了，服务 A 重试几次调用服务 B，还是不行，那么直接降级，走一个备用的逻辑，给用户返回响应.
         2. 实例代码: https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/distributed-system/dubbo-service-management.md

      3. 失败重试和超时机制

         1. 通过timeout 和 retries两个配置

         2. ```
            <dubbo:reference id="xxxx" interface="xx" check="true" async="false" retries="3" timeout="2000"/>
            ```

   6. 网络通信netty

      1. 基于NIO实现的

      2. 服务提供者

         1. Acceptor线程通过Selector组件轮询ServerSocketChannel的网络事件  , 同时ServerSockerChannle会持续监听端口号 , 看有没有消费者netty来建立网络连接.
         2. 消费者通过netty框架与服务提供者的端口号和ServerSocketChannel建立连接 , 每个消费者建立一个SocketChannel对象 . netty会将建立好的连接SocketChannle分配给Processor线程 , 每一个Processor线程通过多路服用轮询组件Selector , 来不断轮询看这些SocketChannel对应的服务消费者有没有发请求过来. 轮询到有请求过来就会解析请求走后面的流程.
         3. 每个Processor可以支撑多个消费者的请求.
         4. 服务响应也是通过Processor线程 , 通过对应消费者的SockerChannel发响应发回到消费者的netty .

      3. 服务消费者

         1. 同提供者类似 ,也是对一个提供者建立一个SocketChannel连接, 一个Processor线程通过Selector轮询多个SocketChannel的网络事件 , 把响应值返回给消费者.

         ![网络通信netty框架原理](C:\Users\guozh\Desktop\java\石杉\网络通信netty框架原理.jpg)

4. 如何设计一个RPC框架

   1. 动态代理  
      1. 消费者和提供者都要实现某个框架的动态代理的, PRC框架的一切细节都在这个动态代理里面实现.调用动态代理的方法.
   2. 服务注册中心
      1. 服务注册,服务发现 . 或者 基于zookeeper .
   3. Cluster层 
      1. 从本地服务注册表根据负载均衡找到要调用的机器列表 .
      2. 负载均衡策略 . 
   4. 调用信息交给协议层 
      1. 协议
      2. 网络通信框架
      3. 序列化和反序列化
   5. 我给大家说个最简单的回答思路：
      - 上来你的服务就得去注册中心注册吧，你是不是得有个注册中心，保留各个服务的信息，可以用 zookeeper 来做，对吧。
      - 然后你的消费者需要去注册中心拿对应的服务信息吧，对吧，而且每个服务可能会存在于多台机器上。
      - 接着你就该发起一次请求了，咋发起？当然是基于动态代理了，你面向接口获取到一个动态代理，这个动态代理就是接口在本地的一个代理，然后这个代理会找到服务对应的机器地址。
      - 然后找哪个机器发送请求？那肯定得有个负载均衡算法了，比如最简单的可以随机轮询是不是。
      - 接着找到一台机器，就可以跟它发送请求了，第一个问题咋发送？你可以说用 netty 了，nio 方式；第二个问题发送啥格式数据？你可以说用 hessian 序列化协议了，或者是别的，对吧。然后请求过去了。
      - 服务器那边一样的，需要针对你自己的服务生成一个动态代理，监听某个网络端口了，然后代理你本地的服务代码。接收到请求的时候，就调用对应的服务代码，对吧。

5. Springcloud底层原理

   1. 注册中心Eureka

      1. 服务注册与发现
         1. 服务注册表 , 二级缓存(ReadWrite缓存+ReadOnly缓存) , 后台有线程会定时将ReadWrite缓存同步给ReadOnly缓存 , 服务发现定时(每隔30s)拉取ReadOnly的缓存 . 
      2. 心跳与故障
         1. 服务注册机器会每30s发送一次心跳 , 服务注册表会记录心跳 , 后台有个心跳线程会定时检查,当发现一定时间内某个机器没有心跳 , 任务机器挂了 , 将该机器剔除服务注册表 , 同事会发指令ReadWrite缓存 , ReadWrite缓存会清空自己 , 然后定时同步线程也会清空ReadOnly缓存 . 当下次的服务发现时会去服务注册表拉取最新的数据更新到两个缓存中.

      ![Eureka注册中心原理](C:\Users\guozh\Desktop\java\石杉\Eureka注册中心原理.jpg)

   2. Ribbon

   3. Feign 

      1. 对一个接口打了一个注解 , 他会针对这个注解标注的接口生成动态代理 , 调用时底层生成http协议格式的请求 , 通过Ribbon 从本地的服务注册列表中根据负载均衡算法获选出一个机器 , 接着对机器发送http请求即可.

   4. Zuul

      1. 配置一下不同请求路径和服务的对应关系 , 把请求直接匹配到服务 , 基于Ribbon , 发请求到指定的机器上去.

6. Dubbo和Springcloud的优缺点

​	1.总结：dubbo优点：深度优化后，基于TCP的RPC调用更加轻量级，速度更快。 dubbo缺点：只是一		套RPC服务框架没有配套设施，需要自己再找其他的组件去做配合使用。 SpringCloud优点：开箱即用，和spring完美搭配，提供一整套分布式系统解决方案。 SpringCloud缺点：基于http请求，较慢。有些组件存在问题（springCloud config） 两者差异：最大的差异在对请求的处理上，一个基于TCP一个基于HTTP。一个是RPC服务框架，一个是分布式系统解决方案。

7. 服务注册中心比较

   1. Eureka集群架构

      1. peer2peer，每个注册中心服务的节点地位相等，会将每次心跳和更新请求同步到每一个节点上，因此并发高了之后，注册中心的内部流量会很大。注册列表的更新方式是通过客户端拉取

   2. Zookeeper集群

      1. master-follower，通过只对主节点进行写，然后由主节点同步到从节点后，主动向节点推送到各个服务节点。时效性较高 .  服务消费者可以去加监听服务列表, ZK会主动通知给消费者服务列表的变动.当有机器新增或者下线, ZK的leader节点先感知到然后同步给Follower节点,Follower节点主动通知服务消费者.

         ![ZooKeeper服务注册与发现原理](C:\Users\guozh\Desktop\java\石杉\ZooKeeper服务注册与发现原理.jpg)

   3. 一致性保障 CP or AP

      1. C:Consisitency(一致性)

         A:Availability(可用性) 

         P:Partition Tolerance(分区容错性) .

         CAP相关文章: https://juejin.im/post/6844903936718012430

         在分布式的环境下，网络无法做到100%可靠，有可能出现故障，因此分区是一个必须的选项，如果选择了CA而放弃了P，若发生分区现象，为了保证C，系统需要禁止写入，此时就与A发生冲突，如果是为了保证A，则会出现正常的分区可以写入数据，有故障的分区不能写入数据，则与C就冲突了。因此分布式系统理论上不可能选择CA架构，而必须选择CP或AP架构。

      2. zk: 基于cp，保证数据的顺序一致性，因此需要牺牲掉一些可用性，例如主节点宕机后，就不再可用（不提供读写服务），需要从从节点中再次选取出主节点后才会继续提供服务。

      3. Eureka：基于ap，保证节点的可用性，在某一些服务节点挂掉之后，其余节点可以继续提供服务，但是因为数据未能同步，所以其它节点提供的数据可能是不一致的, 会确保最终一致性。 这两者之间的差异，都是因为模式造成的，一个是中心化，一个是去中心化。

   4. 服务注册发现的时效性

      1. zk时效性好 , 秒级别可以感知

      2. Eureka , 默认配置比较糟糕 , 服务发现感知到要几十秒 , 甚至分钟级别.

         优化:  

         1. ReadOnly缓存和ReadWrite缓存的同步周期缩短(30s->3s) , eureka.server.responseCacheUpdateIntervalMs = 3000

         2. 服务发现拉取的周期缩短(30s->3s),

            eureka.client.registryFetchIntervalSeconds = 3

         3. 服务心跳上报周期缩短(30s->3s)

            eureka.client.leaseRenewalIntervalInseconds = 3

         4. 心跳检查周期缩短(60s->6s)

            eureka.server.evictionIntervalTimeMs=6000

         5. 心跳超时时间(超过这个时间判定为死亡.90s->9s)

            eureka.instance.leaseExpirationDurationInSeconds= 90

         6. 关闭eureka的自我保护机制(突然网络故障,一定比例机器没有发生心跳,会触发保护机制,保护服务注册表不会被修改 , 源码的bug较多)

            eureka.server.enableSelfPreservation: false

   5. 容量

      1. zk: 不适合大规模的服务实例 , 因为服务上下线的时候会瞬间推送数据通知到所有的其他服务实例 , 一旦达到几千服务实例时 , 会导致网络带宽被大量地占用.
      2. Eureka: 也很难支撑大规模的服务实例 , 因为每个节点收到数据通知都要同步给其他节点 , 相当于每次更新会落到集群的每个节点上 , 如果服务过多 , Eureka整个集群内部流量巨大.
      3. 实际生成部署,会采用比较高的配置的机器来做,8C16G, 16C32G的高配机器来做,基本可以做到每台机器每秒钟支撑几千请求.

   6. 部署上万服务实例 , 服务注册中心如何优化(自研注册中心)

      1. 服务注册表分片存储. 每台机器存储部分的服务注册表,机器不互相同步数据 , 将集群请求分散到多个节点.应对. (高并发)
      2. 每个机器都有自己的Slave机器做备份机器来保证(高可用).
      3. 通过主从节点都写成功了再返回ack(一致性).
      4. 服务消费者 通过代理层去指定的节点拉取部分注册信息，不用每次都拉取集群的全集。

      ![自研注册中心架构](C:\Users\guozh\Desktop\java\石杉\自研注册中心架构.jpg)

   7. 其他注册中心比较

      |       Feature        | Consul                                  | Zookeeper                      | Etcd                  | Eureka                           | SofaRegistry           |
      | :------------------: | :-------------------------------------- | ------------------------------ | --------------------- | -------------------------------- | ---------------------- |
      |     服务健康检查     | 定期healthcheck(http/tcp/script/docker) | 定期心跳保持会话(session) +TTL | 定期refresh(http)+TTL | 定期心跳+TTL;支持自定义healcheck | 定期连接心跳＋锻炼敏感 |
      |        一致性        | raft                                    | ZAB                            | raft                  | 最终一致性BASE                   | 最终一致性BASE         |
      |         cap          | cp                                      |                                |                       |                                  |                        |
      | 使用接口(多语言能力) | 支持http和dns                           | 客户端                         | http/grpc             | 客户端/http                      | 客户端(java)           |
      |      watch支持       | 全量/支持long polling                   | 支持                           | 支持long polling      | 不支持(client定期fetch)          | 支持(服务端推送)       |
      |         安全         | acl/https                               | acl                            | https支持(弱)         | -                                | acl                    |
      |   spring cloud集成   | 支持                                    | 支持                           | 支持                  | 支持                             | 支持                   |

   

8.网关

1. 网关的作用:

   1. 动态路由 , 负载均衡: 新开发某个服务 , 动态把请求路径和服务的映射关系加载到网关;服务增减机器,网关自动热感知.
   2. 灰度发布 . 可以调整流量比例到新代码的机器上.比如默认是50%的流量到新机器,如果新代码有问题,50%的服务就不可用了,可以通过网关来调整流量的比例 , 逐步扩大灰度比例 . 降低新代码上线的影响.
   3. 鉴权认证
   4. 接口性能监控 . 每个api接口的RT , QPS , 成功率等.
   5. 系统日志
   6. 限流熔断
   7. 数据缓存 . 某些接口的响应做缓存

2. 网关的技术选型

   1. Kong : 依托于Nginx实现，OpenResty，lua实现的模块，现成的一些插件，可以直接使用 . Nginx抗高并发的能力很强，少数几台机器部署一下，就可以抗很高的并发，精通Nginx源码，很难，c语言，很难从Nginx内核层面去做一些二次开发和源码定制
   2. Zuul : Spring cloud , 基于java开发,核心网关功能比较简单 , 但是比如灰度发布 , 限流 , 动态路由之类的都需要二次开发. 高并发能力不强.
   3. 自研网关: Java技术栈为主的大厂，很多其实用Java、Servlet、Netty来开发高并发、高性能的网关系统，自己可以把控一切

3. 动态路由的实现

   1. 动态路由实现: 可以使用第三方组件保存路由关系，然后在网关里面通过定时任务去定时刷新组件中保存的路由信息。 因此就可以基于mqsql去做路由关系的保存，然后通过后台管理系统去操作db，再由网关去定时查询db更新路由表，实现动态路由效果。 
   2. 代码实现: C:\Users\guozh\Desktop\java\石杉\代码2\zuul-gateway\src\main\java\com\zhss\demo\zuul\gateway 中

4. 网关抗住每秒10w的高并发访问 ,如何优化

   1. zuul集群部署  , 前面有一层Ngnix反向代理 , 前面再有一层LVS负载均衡层.

      LVS是Linux virtual 
      server的缩写，是一个高可用性、高性能的虚拟服务器集群系统。主要针对高可伸缩、高可用网络服务的需求，给出了基于IP层和基于内容请求分发的负载平衡调度解决方法，并在Linux内核中实现了这些方法，将一组服务器构成一个实现可伸缩的、高可用网络服务的虚拟服务器。

   2. zuul网关部署机器,部署8C16G , 每秒几千请求不是问题 . 10w请求要几十台网关机器

   3. 生产级的网关应该具备上面的几个特点和功能.需要二次开发. 动态路由/灰度发布/鉴权认证/限流熔断

5. 如何基于网关实现灰度发布

   1. 开发流程： 首先自己建一张表，存入具体uri以及是否灰度发布的一些信息，然后搞一张映射表。 启动个线程每个多少时间就去刷新数据写到concurrenthashmap里面。 接着搞一个filter继承ZuulFilter，重写里面几个函数，其中shouldFilter根据返回值去判断执不执行run。 因此再should里面遍历map去看这次请求是否有开启灰度发布，如果有就执行run里面的逻辑，就自定义一些分发逻辑，这里用的时通过version去判断和分发。 2、灰度发布流程 首先通过后台系统更改灰度发布标识，后台线程更新了map后，就会去执行根据version分发的策略，将少部分流量分发到new上，然后监控和对应的后台，如果没问题，就更改为current，全线上线，最后将灰度发布表示改回来。
   2. 代码实现:  C:\Users\guozh\Desktop\java\石杉\代码 3\zuul-gateway\src\main\java\com\zhss\demo\zuul\gateway 里面 GrayRelease*的三个文件.

6. 公司的网关mbgw的架构图

   ![公司网关架构图](C:\Users\guozh\Desktop\java\石杉\公司网关架构图.jpg)



9.分布系统实践问题

1. 各服务在生产环境如何部署

   1. 中小型公司，一般服务拆分大概在十几二十个，那么相对来说比较好部署。

      注册中心，4核8G的机器，可以抗住每秒大概1000左右的请求，那么部署两台，就完全足够了。另外部署两台还可以作为高可用的冗余，相关的优化参数可以调到很小，让服务的发现，服务注册，服务异常等等信息的时效性很高。 

      网关的话，4核8G的机器，也是差不多能抗1000左右，但是一般会部署3-4机器，保证高可用的同时也可以降低每个网关系统的压力，通常在网关之前还会用ngx的反向代理+LVS负载均衡。 

      数据库，16核32G的机器部署mysql，高峰期可以抗住三四千的请求。 

      以上是对应机器配置的相对经验值，如果要求对应的qps达到几千几万的话。需要一个个模块再次进行优化

   2. 服务的高峰QPS是多少? 压测工具最大QPS是多少

      1. 可以在代码里,家加一些metrics统计机制. 对核心接口,用AtomicLong统计一下每分钟的请求量,成功次数,失败次数,在内存里做一些计数 . 
      2. 统计每个接口的耗时RT , TP99 = 100ms (99%的接口请求耗时在100ms以内), TP95 也是同理. 
      3. 百度java压测工具 , 开源可用的 . 如果1000/s发送压测请求 , 然后800/s被处理 . 200/s的请求被阻塞,压测工具可以感知到.

   3. 如果访问量增加十倍 , 考虑过扩容方案么

      1. 网关直接多部署10倍的机器 . 改一下nginx里面的方向代理.
      2. 服务扩容 , 加机器 , 服务会自动注册 感知到.
      3. 升级成几百个服务实例 , eureka机器可以考虑升级成8C16G的机器 , 可以抗每秒上千请求 , 横向扩容eureka用处不大 , 因为每台机器都是要保存全部的注册列表.
      4. 数据库 , 每秒高峰期几千请求 , 可以考虑给单个数据库提高配置 , 32C128G机器 , 可以抗几千并发.

2. 生产环境的超时和重试参数

   1. Spring cloud项目第一次启动的时候 , 人家调用经常会出现timeout , 是因为第一次请求的时候会去初始化Ribbon组件 , 初始化组件比较耗时 , 比较容易导致超时. 通过配置参数让服务启动时组件就初始化.

      ribbon.eager-load.enabled:true

      zuul.ribbon.eager-load.enable:true

   2. 配置超时和重试参数:

      ribbon.ConnecTimeout: 1000

      ribbon.ReadTimeout: 1000

      ribbon.OkToRetryOnAllOperations: true

      ribbon.MaxAutoRetries: 1  (重试目标机器1次)

      ribbon.MaxAutoRetriesNextServer:1  (目标机器重试失败换一台机器重试一次)

   3. 服务重试 , 防止服务重复下单的问题 , 接口的幂等性

      1. 如果是插入类型的请求：可以通过db的唯一键去做，如果插入失败则说明已存在，直接丢弃或者其他逻辑。或者用redis(接口+请求参数)拼成一个唯一的key，检查这个key是否存在，如果存在就丢弃或者其他逻辑.

      2. 如果是更新类型的请求 : 可以将请求过程分为几个节点，在各个阶段进行对应的幂等性保证 , 例如老师讲的前后拦截器，执行逻辑前，检查redis唯一key的值，如果是1说明已被成功执行，直接不做处理了；如果是0说明有同样的请求在执行，但是未完成，这时可以直接执行也可以等一段时间再检查再执行。当请求处理过程中，增加必要的异常处理，如果异常就回滚不修改key的值；如果执行成功，检查key值是否已被修改为1，已被修改就回滚，如果不能回滚就需要执行一些数据恢复的措施。如果要求不允许第二个请求执行逻辑，就在进入方法的时候就不允许执行了，不过这样吞吐量会降低。 我的思路跟下面有位同学的思路一样，不过通过注解去标识需要保证幂等的设计感觉很棒。

         也可用通过给数据加独占锁(select * from table for update no wait) , 来保证改数据只被一个请求在修改.

3. 分布式服务接口请求的顺序性如何保证？

   1. 个人建议是，你们从业务逻辑上设计的这个系统最好是不需要这种顺序性的保证，因为一旦引入顺序性保障，比如使用**分布式锁**，会**导致系统复杂度上升**，而且会带来**效率低下**，热点数据压力过大等问题。
   2. 方案:
      1. 首先你得用 dubbo 的一致性 hash 负载均衡策略，将比如某一个订单 id 对应的请求都给分发到某个机器上去，接着就是在那个机器上，因为可能还是多线程并发执行的，你可能得立即将某个订单 id 对应的请求扔一个**内存队列**里去，强制排队，这样来确保他们的顺序性。 https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/distributed-system/distributed-system-request-sequence.md
      2. 1.HASH分发，将需要保证顺序的请求打到同一台服务器上。 2.引入消息队列 3.分布式锁，请求携带标识，序列号等。
      3. 接入服务可以用redis毫秒级或版本号有序列表排序，系统根据有序列表中的数据，顺序性消费

4. 画一下系统链路图 , 说一下分布式架构存在的问题

   1. 分布式事务 , 核心链路保证数据一致性

      1. 两阶段提交方案 / XA方案:

         1. 事务管理器 , 先询问每一个系统是否能执行 , 如果都可以执行 , 再进入第二阶段一次每个系统去执行. 如果其中一个不 能执行 , 就取消事务的执行. 常见于单个系统跨多个库的分布式事务(现在分布式系统不允许这么做了) , 因为严重依赖与数据库层面来搞定复杂的事务,效率低,不适合高并发场景. 基于spring + JTA就能实现.

      2. TCC方案: Try/Confirm/Cancel

         1. Try阶段: 对各个服务的资源做检测以及对资源进行锁定或者预留
         2. Confirm阶段: 在各个服务中执行实际的操作
         3. Cancel阶段: 如果任务一个服务执行报错 , 就要进行补偿 , 就是执行已经成功的业务逻辑的回滚操作.
         4. 很少有人用,比较依赖自己写代码来回滚补偿 , 业务代码比较难维护. 比较适合的场景: 一致性要求太高了,比如资金类的场景 , 可以用TCC方案 , 自己编写大量的业务逻辑 , 自己判断一个事务中的各个环节是否ok , 不ok就执行补偿/回滚代码. 最好每个系统执行时间比较短.

      3. 本地消息表方案

         1. A系统在自己本地的一个事务里面操作同时 , 插入一条数据到消息表.
         2. 消息表有个后台不断轮询 , 去执行消息(调用系统B).
         3. 系统B自己需要保证幂等性 , 如果B处理成功了 ,返回成功 , 系统A更改消息表中的状态为已完成 , 继续之后的业务逻辑. 如果B处理异常或者超时 , A的后台线程会定时轮询未完成的消息来执行 , 知道系统B成功为止.
         4. 方案缺陷: 严重依赖于数据库的消息表来管理事务的 , 如果是高并发场景有问题,数据库扛不住.

      4. 可靠消息最终一致性方案

         1. 不要用本地消息表了 , 直接基于MQ来实现事务  , 比如阿里的RoceketMq(3.2.6版本之前的都有回调的接口);

         2. 过程:

            1. A系统先发送一个prepared消息到MQ , 如果这个prepared消息发送失败那么直接取消不执行了.

            2. 如果这个消息发送成功过了 , 那么接着执行本地事务 , 执行成功之后给MQ发送confirm消息. 如果执行失败了就告诉MQ回滚消息 . 

            3. 如果发送了确认消息 ,B系统会收到确认消息 , 然后执行本地事务.

            4. MQ会自动定时轮询所有prepared消息回调你的接口,询问A系统这个消息是不是本地事务失败了 , 没有发送确认消息 , 是继续重试还是回滚 ? 这里A系统可以查一下数据库看事务是否执行失败了, 如果回滚了 , 那么这里也回滚 , 如果没有回滚 , 那要重新发一次confirm消息.. 这个就是避免可能本地事务执行成功了 , 但confirm的消息发送失败了.

            5. 如果B系统执行的事务失败了怎么办? B系统自身需要具备一套失败重试的机制 , 进行失败重试 ; 如果没有的话B系统可以通过MQ的相关机制让MQ重新发送消息 ; 也可以通过ZK , A系统发完消息之后一直监听ZK上的一个值 , B如果失败了 , 通知ZK , 然后ZK反过来通知A系统 , A系统把confirm消息再发一遍. 在这里B系统一定要保证自己的幂等性.

               ![分布式事务-可靠消息最终一致性方案](C:\Users\guozh\Desktop\java\石杉\分布式事务-可靠消息最终一致性方案.jpg)

         3. 订单服务的可靠消息最终一致性方案(上述过程细化):

            整个订单服务可以分为两个链路 , 一个是核心链路(订单业务) , 一个是非核心链路(wms发货服务),整个流程:

            1. 先向RocketMQ发送half message . (为什么不把发送ma放在核心交易链路之后? 如果放在核心链路之后 , 有可能发送消息失败,这样导致后序操作无法进行.之前发半消息的话 , MQ会通过回调反复确认核心链路的状态. )
            2. MQ返回成功 , half message在MQ里面有持久化的记录.
            3. 调用核心链路.
            4. 核心链路如果失败 , 走失败的逻辑 : 调用支付服务进行退款 , 更改订单的状态为取消 , 给MQ发送rollback消息废弃掉刚刚half message消息.
            5. 核心链路成功 , 就给MQ发送commit message让消费者继续消费.
            6. 在half message等待期间,一直没有commit/rolback的消息 , MQ会有后台线程来轮询,走回调去查询状态.
            7. 消费者收到消息,消费完成后回复MQ一个ack , 如果消费失败了 , MQ会重新投递或者换一个机器投递消息.

         ![分布式事务-订单系统可靠消息最终一致性原理](C:\Users\guozh\Desktop\java\石杉\分布式事务-订单系统可靠消息最终一致性原理.jpg)

         

      5. 一般分布式事务常用的是TCC和可靠消息一致性这两种思路。一个要求强一致，一个要求最终一致。强一致主要用于核心模块，例如交易/订单等等。最终一致一般用于边缘模块例如库存，通过mq去通知，保证最终一致性，也可以业务解耦。

      6. TCC事务框架 , seata框架(阿里的),支持dubbo和spring cloud

         1. seata 的使用demo: 直接在github页面上下载：[https://github.com/seata/seata-samples](https://github.com/seata/seata-samples%EF%BC%8C%E5%BB%BA%E8%AE%AE%E8%BF%99%E7%A7%8D%E6%96%B9%E5%BC%8F%EF%BC%8C%E6%AF%94%E8%BE%83%E5%BF%AB%E4%B8%80%E7%82%B9%EF%BC%8Cgit) , 

         2. 然后先要下载一个seata-server到本地，在这里下载：[https://github.com/seata/seata/releases](https://github.com/seata/seata/releases%EF%BC%8C%E7%84%B6%E5%90%8E%E5%90%AF%E5%8A%A8%E8%B5%B7%E6%9D%A5%EF%BC%8C%E8%BF%99%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E4%B8%AD%E5%BF%83%EF%BC%8C%E8%B4%9F%E8%B4%A3%E7%BB%B4%E6%8A%A4%E6%AF%8F%E4%B8%80%E4%B8%AA%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E7%8A%B6%E6%80%81%EF%BC%8C%E8%A7%A6%E5%8F%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E6%8F%90%E4%BA%A4%E5%92%8C%E5%9B%9E%E6%BB%9A) , 然后启动起来，这是分布式事务管理中心，负责维护每一个分布式事务的状态，触发分布式事务的提交和回滚.

         3. seata-server.bat -h 127.0.0.1 -p 8091 -m file

            直接把Spring Cloud版本的例子运行起来，观察一下依赖、配置和代码，以后自己在系统里使用直接仿照即可，eureka、account、order、storage、business，依次运行起来，修改一些配置，比如说数据库连接配置

            但是任何一个服务报错之后，seata这个分布式事务的框架会感知到，自动触发所有服务之前做的数据库操作全部进行回滚

         4. seata框架的实现原理

            1. 在seata中存在以下角色： 
               1. Transaction Coordinator（TC）:协调器，单独的一个server。维护全局和分支事务的状态，驱动全局事务的提交或回滚。 
               2. Transaction Manager(TM)：全局事务的发起者，负责开始/提交/回滚一个全局事务。（对应订单服务）. 
               3. Resource Manager(RM)：管理分支事务（注册分支事务/状态/提交/回滚），并负责与TC通讯。
            2. 整个使用seata进行分布式事务管理的生命周期:
               1. TM向TC发起全局事务 , TC返回XID作为本次全局事务标识.
               2. XID通过链路向下传播 , RM将本地的事务注册到TC中表示为XID的全局事务中的一个分支事务.
               3. 当执行成功 , 后由TM向TC请求标识为XID的全局事务的提交. 当有一个服务失败时,TM会通过返回值感知到,然后告诉TC将XID的全局事务回滚掉. 由TC来驱动所有的分支事务进行提交/回滚.

            ![seata中tcc处理流程图](C:\Users\guozh\Desktop\java\石杉\seata中tcc处理流程图.png)

         5. TCC事务方案的性能瓶颈在哪里 , 能支撑高并发交易场景么

            1. 每个TM和RM要和TC进行频繁的网络通信 , 会带来系能的消耗 , 比如一个本地事务要耗时100ms , 引入分布式事务之后会耗时200ms
            2. TC(seata-server)中对事务日志和状态的存储 , 如果要支持高并发的话 ,TC也需要进行横向扩容 , 同时TC背后的db也要进行一些分库分表之类的优化.

      7. 可靠消息一致性方案 , 基于ActiveMQ或者RabbitMQ自己开发一下可靠消息服务, 收到一个消息后尝试投递到MQ上去 , 投递失败重试投递 , 当消费者消费成功后必须回调接口来通知处理成功 , 如果一段时间后生产者没有收到成功的消息,要重试投递消息到MQ. 

         也可以用RocketMQ直接提供了分布式事务的支持.

   2. 分布式锁 

      1. 当多个服务需要竞争一个单体资源时，可以考虑加上分布式锁。如果并发量高的话，可以考虑拆分掉那个单体资源，50个拆成5个10个资源，从而缩小锁的粒度，提高吞吐量。

      2. Redis最普通的分布式锁

         1. 最普通的实现方式，就是在 redis 里使用 `setnx` 命令创建一个 key，这样就算加锁。

            ```
            SET key my_random_value NX PX 30000
            ```

            执行这个命令就 ok。

            - `NX`：表示只有 `key` 不存在的时候才会设置成功。（如果此时 redis 中存在这个 key，那么设置失败，返回 `nil`）
            - `PX 30000`：意思是 30s 后锁自动释放。别人创建的时候如果发现已经有了就不能加锁了。

            释放锁就是删除 key ，但是一般可以用 `lua` 脚本删除，判断 value 一样才删除：

            ```
            -- 删除锁的时候，找到 key 对应的 value，跟自己传过去的 value 做比较，如果是一样的才删除。
            if redis.call("get",KEYS[1]) == ARGV[1] then
                return redis.call("del",KEYS[1])
            else
                return 0
            end
            ```

            ​	为啥要用 `random_value` 随机值呢？因为如果某个客户端A获取到了锁，但是阻塞了很长时间才执行完，比如说超过了 30s，此时可能redis已经自动释放锁了，此时可能别的客户端B已经获取到了这个锁，要是客户端A这个时候直接删除 key 的话就会把B加的锁给删掉会有问题，所以得用随机值加上面的 `lua` 脚本来释放锁。

            ​	这种分布式锁的实现不行的。因为如果是普通的 redis 单实例，那就是单点故障。或者是 redis 普通主从，那 redis  主从异步复制，如果主节点挂了（key 就没有了），key 还没同步到从节点，此时从节点切换为主节点，别人就可以 set key，从而拿到锁。

      3. 基于Redisson框架实现:

         1. 支持redis单实例 , redis哨兵 , redis cluster , redis master-slave等部署架构.

         2. 代码:

            ```java
            RLock lock = redisson.getLock("myLock");
            lock.lock();
            lock.unlock();
            ```

         3. 原理流程图

            ![分布式锁-基于Redisson实现原理图](C:\Users\guozh\Desktop\java\石杉\分布式锁-基于Redisson实现原理图.jpg)

            1. redisson根据hash节点选择一台机器, 发送一段lua脚本到redis上, 用lua脚本是将一堆逻辑封装在lua脚本中 , 保证这段逻辑的原子性. 

            2. lua脚本的逻辑: 先判断key是否已经存在 , 不存在就可以继续加锁 , 然后生成一个当前客户端的hash值为该客户端的id作为value(例如123343-234234-545-321-dcgaga:1) ,然后key-vaule的实行set到redis里数据结构如下  , 设置存活时间默认30s; 加锁成功.

               mylock:

               {

               ​	"123343-234234-545-321-dcgaga:1":1

               }

            3. 当客户端2要进来加锁时 , 也执行同样的一段lua脚本 , 先发现key已经存在 , 然后判断key对应的vaule是否包含了客户端2的id , 显然是不包含的 . 然后客户端2会获取到pttl mylock返回的一个数字 ,代表了myLock锁的剩余生存时间. 此时客户端2会进入一个while循环 , 不停尝试加锁.

            4. watch dog自动延期机制: 客户端1一旦加锁成功就会自动启动一个watchdog线程 , 每隔10s检查一下 , 如果客户端1还持有锁key , 那么就延长锁的生存时间.

            5. 可重入加锁机制:  lua脚本中先判断exits mylock , key已经存在的 , 然后再判断因为mylock的key的hash数据结构中包含客户端1的id , 此时就会执行可重入加锁的逻辑 , 会用:

               incrby mylock 123343-234234-545-321-dcgaga:1 1 

               通过这个指令堆客户端1的加锁次数累加1. 数据结构如下:

               mylock:

               {

               ​	"123343-234234-545-321-dcgaga:1":2

               }

            6. 释放锁机制: 执行lock.unlock() , 每次堆mylock数据结构中的那个加锁次数减1 . 如果发现加锁次数是0 , 说明这个客户端已经不再持有锁了 , 此时用del mylock 指令 , 从redis中删除这个key. 另外的客户端2就可以尝试加锁了.

            7. 缺点: 客户端1在redis master上写入了mylock对应的key-vaule , 但是还没等master-slave完成异步的复制 , master出现的宕机 , slave变成了master , 接着客户端2尝试mylock加锁时在新的redis master上完成了加锁 , 但客户端1也以为自己成功加了锁. 此时系统在业务语义上会出现问题 , 导致脏数据的产生 . 

               所以这就是redis的master-slave架构的主从异步复制导致的, 在master宕机时,可能导致多个客户端同事完成加锁.

      4. RedLock算法

         1. 就是基于redis集群来做的锁 , 假设有一个redis cluster , 有5组redis master-slave节点,然后执行一下步骤:
            1. 获取当前时间戳 , 单位时毫秒
            2. 尝试在每个master节点上加锁 , 过期时间较短 , 一般就几十毫秒.
            3. 尝试在大多数节点(n/2 +１)上建立锁，客户端计算建立好锁的时间 , 如果建立锁的时间小于超时时间 , 就算建立成功了.
            4. 要是锁建立失败了,就一次删除锁.
            5. 只要别人建立一把锁成功 , 其余节点也是不断轮询锁.
         2. 实际用的比较少 , 算法有争议 , 比如过期时间如何设置.

      5. zookeeper的实现

         1. zookeeper有哪些应用场景

            1. 分布式协调 :

               这个其实是 zookeeper 很经典的一个用法，简单来说，就好比，你 A 系统发送个请求到 mq，然后 B 系统消息消费之后处理了。那 A 系统如何知道 B 系统的处理结果？用 zookeeper 就可以实现分布式系统之间的协调工作。A 系统发送请求之后可以在 zookeeper 上**对某个节点的值注册个监听器**，一旦 B 系统处理完了就修改 zookeeper 那个节点的值，A 系统立马就可以收到通知，完美解决。

               ![zk的分布式协调实例图](C:\Users\guozh\Desktop\java\石杉\zk的分布式协调实例图.png)

            2. 分布式锁

               1. 系统A先去zk上获取锁 , 创建了一个临时节点 , 同时判断当前你创建成功的这个节点是不是第一个节点(最小节点) , 如果是 ,获取锁成功 , 临时节点如果创建成功了就属于系统A. (使用临时节点: 系统A挂了 , 就会和zk断开会话 , zk感知到之后就会把A创建的临时节点删除掉,然后通知后面系统来获取锁)

               2. 此时系统B也尝试在zk创建一个同名的临时节点 , 判断自己这个节点是不是最小节点 , 如果不是 , 说明别人已经加锁了 , 系统B加锁失败. 那就找到排在自己前面的节点来监听.

               3. 系统A处理完成释放锁 , 删除掉临时节点就可以.

               4. 一旦临时节点被删除 , zk就会去通知监听节点A的系统B来获取锁.

                  ![分布式锁-基于zookpeer来实现](C:\Users\guozh\Desktop\java\石杉\分布式锁-基于zookpeer来实现.jpg)

               5. demo代码 : https://gitee.com/shishan100/Java-Interview-Advanced/blob/master/docs/distributed-system/distributed-lock-redis-vs-zookeeper.md

               6. 其他zk文章: https://juejin.im/post/6850418115143335943

               7. 基于curator框架:

                  1. 客户端A先在目录下(/lock/product_1_stock)创建一个临时顺序节点00001 , 同事客户端A ,获取目录下的所有节点, 发现自己的节点是所有节点中序号最小的, 加锁成功.

                  2. 客户端B通过curator框架来获取锁 , 会在目录下创建一个临时顺序节点00002, 同目录下的临时节点一定是有顺序的 , 02节点会来看自己是否为目录的第一个节点 , 不是的话加锁失败 , 堆上一个节点加一个watch监听器.

                  3. 客户端A如果想再次加锁(可重入加锁) , 将原节点中的加锁累计次数加一 .

                  4. 客户端A想释放锁 , 将节点中的加锁次数减一 , 当加锁次数为0时, 就释放锁 , 删除临时节点A , 客户端B会收到通知上一个节点被删除 , 此时回来再次尝试加锁 , 加锁成功.

                     ![分布式锁-基于zookpeer的curator框架来实现](C:\Users\guozh\Desktop\java\石杉\分布式锁-基于zookpeer的curator框架来实现.jpg)

               8. zk分布式锁的羊群效应如何解决

                  1. 羊群效应：当几十个节点争抢同一把基于zk的锁时，如果都是监听第一个节点，那么当释放锁时，zk会同时反向通知所有客户端又来重新争抢。 影响：主要是多了很多没必要的请求，从而会加重网络的负载。 
                  2. 解决：就基于curator去做就好了，通过监听上一级节点，降低了争抢次数，还实现了公平锁。 redis：redis因为是客户端自己主动隔一段时间去尝试加锁，所以羊群效应影响不大，因为请求都错开了，而不是一群一拥而上。

               9. zk分布式锁的脑裂问题如果解决

                  1. 脑裂问题:  分布式系统，主控节点有一个Master，此时因为网络故障，导致其他人以为这个Master不可用了，其他节点出现了别的Master，导致集群里有2个Master同时在运行.
                  2. 问题出现：当客户端a与zk之间出现网络故障，zk感知不到客户端a的心跳，那么就会删除对应的临时节点，那么此时监听该临时节点的客户端b就会拿到锁，此时就出现问题了。 
                  3. 问题解决：网络问题是一个比较难解决的事情。修改curator框架源码,对整个父级上个锁标识，但是这样的话一旦宕机就完蛋，后续还需要加上更加复杂的协调控制操作。

            3. 元数据 / 配置信息管理 : https://juejin.im/post/6850418115143335943

            4. HA高可用性:

               这个应该是很常见的，比如 hadoop、hdfs、yarn 等很多大数据系统，都选择基于 zookeeper 来开发 HA 高可用机制，就是一个**重要进程一般会做主备**两个，主进程挂了立马通过 zookeeper 感知到切换到备用进程。

            ![zk的高可用场景](C:\Users\guozh\Desktop\java\石杉\zk的高可用场景.png)

      6. redis分布式锁和zk分布式锁对比

         1. redis锁需要自己不断尝试去获取锁 , 比较消耗性能; zk分布式锁只需要注册一个监听器即可 , 不需要不断轮询 .
         2. redis的客户端如果挂了 , 锁要等到超时时间过了才会释放 , 而zk因为创建的是临时节点 , 只要客户端挂了 , znode就会被zk删除,自动释放锁.
         3. redis集群是AP架构,主从同步是异步的 , 如果同步完成之前主宕机 , 会出现数据不一致的问题 ; zk集群是CP的 , 强一致性的 , 不会存在一致性问题.

      7. 分布式锁抗高并发

         1. 分段加锁 + 合并扣减

         2. 对某个商品下单，对一个分布式锁每秒突然有上万请求过来，都要进行加锁，此时怎么办呢？

            比如你的苹果库存有10000个，此时你在数据库中创建10个库存字段

            一个表里有10个库存字段，stock_01，stock_02，每个库存字段里放1000个库存

            此时这个库存的分布式锁，对应10个key，product_1_stock_01，product_1_stock_02

            请求过来之后，你从10个key随机选择一个key，去加锁就可以了，每秒过来1万个请求，此时他们会对10个库存分段key加锁，每个key就1000个请求，每台服务器就1000个请求而已

            万一说某个库存分段仅仅剩余10个库存了，此时我下订单要买20个苹果，合并扣减库存，你对product_1_stock_5，加锁了，此时查询对应的数据库中的库存，此时库存是10个，不够买20个苹果

            你可以尝试去锁product_1_stock_1，再查询他的库存可能有30个

            此时你就可以下订单，锁定库存的时候，就对product_1_stock_5锁定10个库存，对product_1_stock1锁定10个库存，锁定了20个库存

         3. 疑问: 合并扣减时 , 发现其他分段已经被人加锁了 ,怎么办? 这个时候就得等待别人释放锁，去获取那个锁分段 , 尝试获取其他锁超过一定时间没获取到就返回库存不足然后释放持有的锁.

         4. 库存服务 , 能不能不用分布式锁实现高并发的库存更新?

            1. 大厂一般不用分布式锁 , 采用nosql数据库里面的k-v存储类型(如tair , redis , mongdb) , 然后不查询 ,直接扣 , 扣到负数就回滚库存 , 返回提示给用户 . 然后将本次操作发送给mq , mq交给另外一个服务去慢慢修改关系型数据库里面的数据(异步同步数据库). 这个主要做好一致性保证方法以及两个库之间的数据同步.
            2. 比如nosql扣减库存,然后发消息队列 , 一致性怎么保证? 可以使用redis + lua脚本 , 进行扣减 , 成功后发送mq , 这样做成原子性的操作.

   3. 分布式session方案

      1. session 是啥？浏览器有个 cookie，在一段时间内这个 cookie 都存在，然后每次发请求过来都带上一个特殊的 `jsessionid cookie`，就根据这个东西，在服务端可以维护一个对应的 session 域，里面可以放点数据。

         一般的话只要你没关掉浏览器，cookie 还在，那么对应的那个 session 就在，但是如果 cookie 没了，session 也就没了。常见于什么购物车之类的东西，还有登录状态保存之类的。

      2. tomcat + redis

         1. 就是使用 session 的代码，跟以前一样，还是基于 tomcat 原生的 session 支持即可，然后就是用一个叫做 `Tomcat  RedisSessionManager` 的东西，让所有我们部署的 tomcat 都将 session 数据存储到 redis 即可。
         2. 会与 tomcat 容器重耦合，如果我要将 web 容器迁移成 jetty，难道还要重新把 jetty 都配置一遍？因为上面那种 tomcat + redis 的方式好用，但是会**严重依赖于web容器**，不好将代码移植到其他 web 容器上去，尤其是你要是换了技术栈咋整？比如换成了 spring cloud 或者是 spring boot 之类的呢？

      3. spring session + redis

         1. 配置代码:  https://gitee.com/shishan100/Java-Interview-Advanced/blob/master/docs/distributed-system/distributed-session.md
         2. 给 sping session 配置基于 redis 来存储 session 数据，然后配置了一个 spring session 
            的过滤器，这样的话，session 相关操作都会交给 spring session 来管了。接着在代码中，就用原生的 session 操作，就是直接基于 spring sesion 从 redis 中获取数据了。
         3. 相关文章: https://juejin.im/post/6844903869634478088

   4. 分库分表

      1. 为什么要进行分库分表

         1. 单表的数据量过大会影响sql性能 . 单表的数据不要过大 , 超过1000w就应该考虑拆分了. 保持每个表几百万的数据 , 这样sql跑的不会太慢.

         2. 一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。以及单个库磁盘会有很大压力.

            | #            | 分库分表前                   | 分库分表后                                   |
            | ------------ | ---------------------------- | -------------------------------------------- |
            | 并发支撑情况 | MySQL 单机部署，扛不住高并发 | MySQL从单机到多机，能承受的并发增加了多倍    |
            | 磁盘使用情况 | MySQL 单机磁盘容量几乎撑满   | 拆分为多个库，数据库服务器磁盘使用率大大降低 |
            | SQL 执行性能 | 单表数据量太大，SQL 越跑越慢 | 单表数据量减少，SQL 执行效率明显提升         |

      2. 分库分表的中间件

         1. Sharding-jdbc

            当当开源的，属于 client 层方案，目前已经更名为 [`ShardingSphere`](https://github.com/apache/incubator-shardingsphere)（后文所提到的 `Sharding-jdbc`，等同于 `ShardingSphere`）。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且截至 2019.4，已经推出到了 `4.0.0-RC1`  版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC  事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017  年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也**可以选择的方案**。

         2. Mycat

            基于 Cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 Sharding jdbc 来说，年轻一些，经历的锤炼少一些。

         3. 对比

            1. Sharding-jdbc 这种 client 层方案的**优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高**，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要**耦合** Sharding-jdbc 的依赖；
            2. Mycat 这种 proxy 层方案的**缺点在于需要部署**，自己运维一套中间件，运维成本高，但是**好处在于对于各个项目是透明的**，如果遇到升级之类的都是自己中间件那里搞就行了。

      3. 数据拆分

         1. 垂直拆分: 

            1. 就是**把一个有很多字段的表给拆分成多个表**，**或者是多个库上去**。一般来说，会**将较少的访问频率很高的字段放到一个表里去**，然后**将较多的访问频率很低的字段放到另外一个表里去**。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。
            2. 举例: 把一个大表拆开，订单表、订单支付表、订单商品表。一般在数据库表设计时就会考虑到.

         2. 水平拆分: 

            1. 把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。

               ![数据库的水平拆分](C:\Users\guozh\Desktop\java\石杉\数据库的水平拆分.png)

         3. 表层面的拆分:

            1. 就是分表，将一个表变成 N 个表，就是**让每个表的数据量控制在一定范围内**，保证 SQL 的性能。否则单表数据量越大，SQL 性能就越差。一般是 200 万行左右，不要太多，但是也得看具体你怎么操作，也可能是 500 万，或者是 100 万。你的SQL越复杂，就最好让单表行数越少。

         4. 进行时机:

            1. 垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；
            2. 水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；
            3. 分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都 ok 了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。

         5. 分库分表的方式

            1. range 分发，就是每个库一段连续的数据，这个一般是按比如**时间范围**来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。
            2. hash分发 , 是按照某个字段 hash 一下均匀分散，这个较为常用。根据你指定的某个字段值，比如说 userid，自动路由到对应的库上去，然后再自动路由到对应的表里去。好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。

         6. 评论区: MySQL自带的分区功能慎用，慎用，慎用；垂直分表结合微服务相对比较好搞，水平分表mycat太依赖运维配置了，关联查询不灵活，而且需要各种配置全局表和ER表，DDL甚至DML都比较麻烦，资源比较充裕还是可以考虑现在tidb之类的分布式数据库.

      4. 如何把系统不停机迁移到分库分表?

         1. 双写迁移方案

            1. 修改原来的系统 , 之前写数据的地方 , 同时写老库和新库. 新库就通过数据库中间件写入分库和分表.

            2. 然后将系统部署后 , 用后台数据迁移临时工具 跑起来读老库数据写新库 , 写的时候根据gmt_modified这类时间戳字段判断数据最后的修改时间 ,读出来的数据在新库里没有，或者是比新库的数据新才会写 . 

            3. 导完一轮之后 , 程序自动做一轮校验 对比数据 , 如果有不一样的 , 就针对不一样的从老库再次读出来然后写 , 反复循环 , 直到两个库每个表的数据都完全一直为止.

               ![数据库的双写迁移方案](C:\Users\guozh\Desktop\java\石杉\数据库的双写迁移方案.png)

      5. 如何设计可动态扩容的分库分表方案

         1. 原先的库和表的数量都不变 , 只是增加服务器的数量 , 比如32库32表 , 原来是4台服务器 , 每台机器装8个数据库 , 每个库有32张表 . 最多可以扩展到3台机器, 每个服务器装一个库, 每个库里有32张表. 这样扩容之后程序里直接改一下数据的地址就行.
         2. 步骤
            1. 设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 * 32 表，对于大部分公司来说，可能几年都够了。
            2. 路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表
            3. 扩容的时候，申请增加更多的数据库服务器，装好 mysql，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。
            4. 由 dba 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。
            5. 我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。
            6. 重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。

      6.  分库分表之后全局的id主键怎么生成

         1.  基于单库生成自增id : 单库的性能瓶颈,不适用于高并发.

         2. UUID : 

            1. 不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，作为主键长度不适合。
            2. 信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。
            3. 对MySQL索引不利：作为数据库主键，在InnoDB引擎下，UUID 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作（连续的 ID 可以产生部分顺序写），还有，由于在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 
               树节点到内存，在插入这条记录后会将整个节点写回磁盘，而且也会引起数据位置的频繁变动 ，性能下降明显。

         3. snowflake 算法

            1. snowflake 算法是 twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的  id，1 个 bit 是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id，12 bit 作为序列号。

               - 1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。
               - 41 bit：表示的是时间戳，单位是毫秒。41 bit 可以表示的数字多达 `2^41 - 1`，也就是可以标识 `2^41 - 1` 个毫秒值，换算成年就是表示69年的时间。
               - 10 bit：记录工作机器 id，代表的是这个服务最多可以部署在 2^10台机器上哪，也就是1024台机器。但是 10 bit 里 5 个 bit 代表机房 id，5 个 bit 代表机器 id。意思就是最多代表 `2^5`个机房（32个机房），每个机房里可以代表 `2^5` 个机器（32台机器）。
               - 12 bit：这个是用来记录同一个毫秒内产生的不同 id，12 bit 可以代表的最大正整数是 `2^12 - 1 = 4096`，也就是说可以用这个 12 bit 代表的数字来区分**同一个毫秒内**的 4096 个不同的 id。

               ```
               0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000
               ```

            2. 优点:

               1. 毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。
               2. 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。
               3. 可以根据自身业务特性分配bit位，非常灵活。

            3. 缺点:

               1. 强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。

                  时间回拨问题：由于机器的时间是动态的调整的，有可能会出现时间跑到之前几毫秒，如果这个时候获取到了这种时间，则会出现数据重复

               2. 机器id分配及回收问题：目前机器id需要每台机器不一样，这样的方式分配需要有方案进行处理，同时也要考虑，如果改机器宕机了，对应的workerId分配后的回收问题.

               3. 机器id上限：机器id是固定的bit，那么也就是对应的机器个数是有上限的，在有些业务场景下，需要所有机器共享同一个业务空间，那么10bit表示的1024台机器是不够的。这种场景可以把获取id功能单独作为一个系统独立出来.

         4. 改进方案1 , Leaf-segment方案: (参考:https://tech.meituan.com/2017/04/21/mt-leaf.html)

            1. 在使用数据库的方案上，做了如下改变 :

               1. 每次获取一个segment(step决定大小)号段的值。用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力。
               2. 各个业务不同的发号需求用biz_tag字段来区分，每个biz-tag的ID获取相互隔离，互不影响。如果以后有性能需求需要对数据库扩容，不需要上述描述的复杂的扩容操作，只需要对biz_tag分库分表就行。

               3. biz_tag用来区分业务，max_id表示该biz_tag目前所被分配的ID号段的最大值，step表示每次分配的号段长度。原来获取ID每次都需要写数据库，现在只需要把step设置得足够大，比如1000。那么只有当1000个号被消耗完了之后才会去重新读写一次数据库从max_id之后数字开始获取。读写数据库的频率从1减小到了1/step.

               4. 表设计:

                  ```sql
                  +-------------+--------------+------+-----+-------------------+-----------------------------+
                  | Field       | Type         | Null | Key | Default           | Extra                       |
                  +-------------+--------------+------+-----+-------------------+-----------------------------+
                  | biz_tag     | varchar(128) | NO   | PRI |                   |                             |
                  | max_id      | bigint(20)   | NO   |     | 1                 |                             |
                  | step        | int(11)      | NO   |     | NULL              |                             |
                  | desc        | varchar(256) | YES  |     | NULL              |                             |
                  | update_time | timestamp    | NO   |     | CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP |
                  +-------------+--------------+------+-----+-------------------+-----------------------------+
                  ```

            2. 优点:

               1. Leaf服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景。
               2. ID号码是趋势递增的8byte的64位数字，满足上述数据库存储的主键要求。
               3. 容灾性高：Leaf服务内部有号段缓存，即使DB宕机，短时间内Leaf仍能正常对外提供服务。
               4. 可以自定义max_id的大小，非常方便业务从原有的ID方式上迁移过来。

            3. 缺点:

               1. ID号码不够随机，能够泄露发号数量的信息，不太安全。容易被竞争对手算出一天的订单量.

               2. TP999数据波动大，当号段使用完之后还是会hang在更新数据库的I/O上，tg999数据会出现偶尔的尖刺。

                  这个可以通过双buffer优化 . Leaf服务内部有两个号段缓存区segment。当前号段已下发10%时，如果下一个号段未更新，则另启一个更新线程去更新下一个号段。当前号段全部下发完后，如果下个号段准备好了则切换到下个号段为当前segment接着下发，循环往复。详见: https://tech.meituan.com/2017/04/21/mt-leaf.html

               3. DB宕机会造成整个系统不可用。

         5. 改进方案二 : leaf - snowflake方案 (参考:https://tech.meituan.com/2017/04/21/mt-leaf.html)

            1. Leaf-snowflake方案完全沿用snowflake方案的bit位设计，即是“1+41+10+12”的方式组装ID号. 改进点: 

               1. 服务规模较大 , workId手动配置成本太高时: 

                  使用Zookeeper持久顺序节点的特性自动对snowflake节点配置wokerID. 

                  除了每次会去ZK拿数据以外，也会在本机文件系统上缓存一个workerID文件。当ZooKeeper出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。这样做到了对三方组件的弱依赖。一定程度上提高了SLA .

               2. 解决时钟回拨问题: 

                  1. 服务启动时先通过zookeeper的上的node记录的时间来校验是否发生了时间回拨.
                  2. 发现后 , 可以做一定期限的等待 , 等时钟自己追上 如果还是小于 , 抛异常/自动摘除本身节点 并报警.

      7. MySQL读写分离的原理 , 主从同步的延时问题

         主库写并发越高 , 从库延长越高 , 经验值: 主库写1000/s从库延长几ms,比如新增1000条数据  ; 主库2000/s , 从库延迟几十ms; 主库写并发达到4000/s,6000/s,8000/s,主库都快死了,从库延迟会有几秒.

         1. 读写分离: 基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。

         2. 主从复制原理:

            1. 主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 
               relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 
               日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的。

               ![mysql主从复制原理](C:\Users\guozh\Desktop\java\石杉\mysql主从复制原理.png)

         3. 主从复制数据丢失问题: 

            1. 如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。
            2. **半同步复制**，用来解决主库数据丢失问题: 也叫 `semi-sync` 复制，指的就是主库写入 binlog 日志之后，就会将**强制**此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到**至少一个从库**的 ack 之后才会认为写操作完成了。

         4. 主从复制的延时问题:

            1. 从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。所以这就是一个非常重要的点了，由于从库从主库拷贝日志以及串行执行 SQL 的特点，在高并发场景下，从库的数据一定会比主库慢一些，是**有延时**的。所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。

            2. 是这个么场景。有个同学是这样写代码逻辑的。先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了  2000/s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。

               我们通过 MySQL 命令：

               ```
               show status
               ```

               查看 `Seconds_Behind_Master`，可以看到从库复制主库的数据落后了几 ms。

            3. 解决方案:

               1. 分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。

               2. 打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。

                  所谓**并行复制**，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后**并行重放不同库的日志**，这是库级别的并行。

               3. 重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。

               4. 如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询**设置直连主库**。**不推荐**这种方法，你要是这么搞，读写分离的意义就丧失了。

   5. 设计一个高可用系统

      ​	HA? 主备切换.

      1. 一些概念	

         1. 资源隔离: 系统里某一块东西故障了 , 不会耗尽系统所有的资源 , 比如线程资源.
         2. 限流: 高并发流量进来 , 比如100w/s , 我只让10w/s进来 , 其他流量都拒绝
         3. 熔断: 系统后端一些依赖挂了 ,比如mysql挂了 , 每次请求都报错,就熔断 , 后续请求过来直接不接收了 , 拒绝访问 , 10min之后再尝试看看mysql恢复了没.
         4. 降级: mysql挂了 , 系统发现了 , 自动降级 , 从内存里存的少量数据 , 继续提供服务.

      2. Hystrix:

         1. 设计原则
            1. 阻止任何一个依赖服务耗尽所有的资源，比如 tomcat 中的所有线程资源。
            2. 避免请求排队和积压，采用限流和 `fail fast` 来控制故障。
            3. 提供 fallback 降级机制来应对故障。
            4. 使用资源隔离技术，比如 `bulkhead`（舱壁隔离技术）、`swimlane`（泳道技术）、`circuit breaker`（断路技术）来限制任何一个依赖服务的故障的影响。
            5. 通过近实时的统计/监控/报警功能，来提高故障发现的速度。
            6. 通过近实时的属性和配置**热修改**功能，来提高故障处理和恢复的速度。
            7. 保护依赖服务调用的所有故障情况，而不仅仅只是网络故障情况。
         2. Hystrix是如何实现他的目标的
            1. 通过HystrixCommand或者HystrixObservableCommand 来封装对外部依赖的访问请求 , 这个访问请求一般对运行在独立的线程中. 
            2. 为每一个依赖服务维护一个独立的线程池 , 或者是semaphore , 当线程池已满时 , 直接拒绝对这个服务的调用.
            3. 对于超出我们设定阈值的服务调用 , 直接进行超时 , 不允许其耗费过长时间阻塞住. 这个超时时间默认是99.5%的访问时间 , 但是一般我们可以自己设置一下.
            4. 对依赖服务的调用的成功次数 , 失败次数 , 拒绝次数 , 超时次数 , 进行统计.
            5. 如果对一个依赖服务的调用失败次数超过了一定的阈值 , 自动进行熔断 , 在一定时间内对该服务的调用直接降级 , 一段时间后再自动尝试恢复.
            6. 当一个服务调用出现失败 , 被拒绝 , 超时 , 短路等异常情况时 , 自动调用fallback降级机制.
            7. 对属性和配置的修改提供近实时的支持.

      3. 大型电商网站系统详情页的架构

         1. 大型电商网站商品详情页的系统设计中，当商品数据发生变更时，会将变更消息压入 MQ 消息队列中。**缓存服务**从消息队列中消费这条消息时，感知到有数据发生变更，便通过调用数据服务接口，获取变更后的数据，然后将整合好的数据推送至  redis 中。Nginx 本地缓存的数据是有一定的时间期限的，比如说 10 分钟，当数据过期之后，它就会从 redis  获取到最新的缓存数据，并且缓存到自己本地。

            用户浏览网页时，动态将 Nginx 本地数据渲染到本地 html 模板并返回给用户。

            虽然没有直接返回 html 页面那么快，但是因为数据在本地缓存，所以也很快，其实耗费的也就是动态渲染一个 html 页面的性能。如果 html模板发生了变更，不需要将所有的页面重新静态化，也不需要发送请求，没有网络请求的开销，直接将数据渲染进最新的 html 页面模板后响应即可。

            ![大型电商网站详情页架构](C:\Users\guozh\Desktop\java\石杉\大型电商网站详情页架构.png)

         2. 如果系统访问量很高，Nginx 本地缓存过期失效了，redis 中的缓存也被 LRU  算法给清理掉了，那么会有较高的访问量，从缓存服务调用商品服务。但如果此时商品服务的接口发生故障，调用出现了延时，缓存服务全部的线程都被这个调用商品服务接口给耗尽了，每个线程去调用商品服务接口的时候，都会卡住很长时间，后面大量的请求过来都会卡在那儿，此时缓存服务没有足够的线程去调用其它一些服务的接口，从而导致整个大量的商品详情页无法正常显示。

            这其实就是一个商品接口服务故障导致缓存服务资源耗尽的现象。

      4. 资源隔离

         1. 利用线程池实现资源隔离

            1. 对某一个依赖服务的全部请求 , 全部隔离到线程池内 , 对商品服务的每次调用请求都封装在一个command里面. 每次该服务的调用请求都是使用线程池内的线程去执行的 , 线程池内线程的个数决定了请求最大会消耗的线程数. 

               缓存服务默认的商品服务线程大小是 10 个，最多就只有 10 个线程去调用商品服务的接口。即使商品服务接口故障了，最多就只有 10 个线程会 hang 死在调用商品服务接口的路上，缓存服务的 tomcat 内其它的线程还是可以用来调用其它的服务，干其它的事情。

            2. 利用 HystrixCommand 获取单条数据

            3. 利用 HystrixObservableCommand 批量获取数据

               1. 示例代码: https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/high-availability/hystrix-thread-pool-isolation.md

         2. 利用信号量实现资源隔离

            1. 信号量的资源隔离只是起到一个开关的作用，比如，服务 A 的信号量大小为 10，那么就是说它同时只允许有 10 个 tomcat 线程来访问服务 A，其它的请求都会被拒绝，从而达到资源隔离和限流保护的作用。
            2. 线程池隔离和信号量隔离的区别
               1. 线程池隔离技术，是用 Hystrix 自己的线程去执行调用 , 控制的是tomcat线程的执行；而信号量隔离技术，是直接让 tomcat 线程去调用依赖服务。信号量隔离，只是一道关卡，信号量有多少，就允许多少个 tomcat 线程通过它，然后去执行。
               2. 使用场景:
                  1. **线程池技术**，适合绝大多数场景，比如说我们对依赖服务的网络请求的调用和访问、需要对调用的 timeout 进行控制（捕捉 timeout 超时异常）。
                  2. **信号量技术**，适合说你的访问不是对外部依赖的访问，而是对内部的一些比较复杂的业务逻辑的访问，并且系统内部的代码，其实不涉及任何的网络请求，那么只要做信号量的普通限流就可以了，因为不需要去捕获 timeout 类似的问题。
            3. 信号量隔离的实例: https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/high-availability/hystrix-semphore-isolation.md

         3. 细粒度的配置

            1. 指定了 HystrixCommand.run() 的资源隔离策略：`THREAD` or `SEMAPHORE`，一种基于线程池，一种基于信号量。

               ```java
               // to use thread isolation
               HystrixCommandProperties.Setter().withExecutionIsolationStrategy(ExecutionIsolationStrategy.THREAD)
               
               // to use semaphore isolation
               HystrixCommandProperties.Setter().withExecutionIsolationStrategy(ExecutionIsolationStrategy.SEMAPHORE)
               ```

            2. command key & command group & command thread pool

               1. **command key** ，代表了一类 command，一般来说，代表了底层的依赖服务的一个接口。

               2. **command group** ，代表了某一个底层的依赖服务，一个依赖服务可能会暴露出来多个接口，每个接口就是一个 command key。command 
                  group 在逻辑上去组织起来一堆 command key 的调用、统计信息、成功次数、timeout 
                  超时次数、失败次数等，可以看到某一个服务整体的一些访问情况。一般来说，根据一个服务区划分出一个线程池，command key 默认都是属于同一个线程池的。

               3. **command thread pool** , command group 对应了一个服务，而这个服务暴露出来的几个接口，访问量很不一样，差异非常之大。你可能就希望在这个服务 command 
                  group 内部，包含的对应多个接口的 command key，做一些细粒度的资源隔离。就是说，对同一个服务的不同接口，使用不同的线程池。如果你的 command key 要用自己的线程池，可以定义自己的 thread pool key .

                  

                  ```java
                  private static final Setter cachedSetter = Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey("ExampleGroup"))
                                                              .andCommandKey(HystrixCommandKey.Factory.asKey("HelloWorld"))
                                                                  .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey("HelloWorldPool"));
                  ```

            3. coreSize

               1. 设置线程池的大小，默认是 10。一般来说，用这个默认的 10 个线程大小就够了。

                  ```java 
                  HystrixThreadPoolProperties.Setter().withCoreSize(int value);
                  ```

            4. queueSizeRejectionThreshold

               1. 如果说线程池中的 10 个线程都在工作中，没有空闲的线程来做其它的事情，此时再有请求过来，会先进入队列积压。如果说队列积压满了，再有请求过来，就直接 reject，拒绝请求，执行 fallback 降级的逻辑，快速返回。这个参数可以热修改，控制队列的最大大小。

               ```java
               HystrixThreadPoolProperties.Setter().withQueueSizeRejectionThreshold(int value);
               ```

            5. maxConcurrentRequests

               1. 设置使用 SEMAPHORE 隔离策略的时候允许访问的最大并发量，超过这个最大并发量，请求直接被 reject。默认值是 10，尽量设置的小一些，因为一旦设置的太大，而且有延时发生，可能瞬间导致 tomcat 本身的线程资源被占满。

               ```java
               HystrixCommandProperties.Setter().withExecutionIsolationSemaphoreMaxConcurrentRequests(int value);
               ```

      5. Hystrix执行时内部原理(8大执行步骤)

         1. 创建command.

            ```java
            // 创建 HystrixCommand
            HystrixCommand hystrixCommand = new HystrixCommand(arg1, arg2);
            
            // 创建 HystrixObservableCommand
            HystrixObservableCommand hystrixObservableCommand = new HystrixObservableCommand(arg1, arg2);
            ```

         2. 调用command执行方法

         3. 检查是否开启缓存

            1. 如果这个 command 开启了请求缓存 Request Cache，而且这个调用的结果在缓存中存在，那么直接从缓存中返回结果。否则，继续往后的步骤。

         4. 检查是否开启了断路器

            1. 检查这个 command 对应的依赖服务是否开启了断路器。如果断路器被打开了，那么 Hystrix 就不会执行这个 command，而是直接去执行 fallback 降级机制，返回降级结果。

         5. 检查线程池/队列/信号量是否已满

            1. 如果这个 command 线程池和队列已满，或者 semaphore 信号量已满，那么也不会执行 command，而是直接去调用 fallback 降级机制，同时发送 reject 信息给断路器统计。

         6. 执行command

            1. 调用 HystrixObservableCommand 对象的 construct() 方法(获取多条结果)，或者 HystrixCommand 的 run() 方法来实际执行这个 command(获取单挑结果)。
            2. 如果是采用线程池方式，并且 HystrixCommand.run() 或者 HystrixObservableCommand.construct() 的执行时间超过了 timeout 时长的话，那么 command 所在的线程会抛出一个 TimeoutException，这时会执行 fallback 降级机制，不会去管 run() 或 construct()返回的值了。另一种情况，如果 command 执行出错抛出了其它异常，那么也会走 fallback 降级。这两种情况下，Hystrix 都会发送异常事件给断路器统计。

         7. 短路健康检查

            1. Hystrix 会把每一个依赖服务的调用成功、失败、Reject、Timeout 等事件发送给 circuit breaker  断路器。断路器就会对这些事件的次数进行统计，根据异常事件发生的比例来决定是否要进行断路（熔断）。如果打开了断路器，那么在接下来一段时间内，会直接断路，返回降级结果。

               如果在之后，断路器尝试执行 command，调用没有出错，返回了正常结果，那么 Hystrix 就会把断路器关闭。

         8. 调用fallback降级机制

            1. 在以下几种情况中，Hystrix 会调用 fallback 降级机制。
               - 断路器处于打开状态；
               - 线程池/队列/semaphore满了；
               - command 执行超时；
               - run() 或者 construct() 抛出异常。
            2. 一般在降级机制中，都建议给出一些默认的返回值，比如静态的一些代码逻辑，或者从内存中的缓存中提取一些数据，在这里尽量不要再进行网络请求了。

            ![Hystrix的8个执行步骤](C:\Users\guozh\Desktop\java\石杉\Hystrix的8个执行步骤.jpg)

      6. request cache缓存技术

         1. 首先，有一个概念，叫做 Request Context 请求上下文，一般来说，在一个 web 应用中，如果我们用到了  Hystrix，我们会在一个 filter  里面，对每一个请求都施加一个请求上下文。就是说，每一次请求，就是一次请求上下文。然后在这次请求上下文中，我们会去执行 N 多代码，调用 N  多依赖服务，有的依赖服务可能还会调用好几次。
         2. 在一次请求上下文中，如果有多个  command，参数都是一样的，调用的接口也是一样的，而结果可以认为也是一样的。那么这个时候，我们可以让第一个 command  执行返回的结果缓存在内存中，然后这个请求上下文后续的其它对这个依赖的调用全部从内存中取出缓存结果就可以了。这样的话，好处在于不用在一次请求上下文中反复多次执行一样的 command，**避免重复执行网络请求，提升整个请求的性能**。
         3. 举个栗子。比如说我们在一次请求上下文中，请求获取 productId 为 1 的数据，第一次缓存中没有，那么会从商品服务中获取数据，返回最新数据结果，同时将数据缓存在内存中。后续同一次请求上下文中，如果还有获取 productId 为 1 的数据的请求，直接从缓存中取就好了。
         4. 实例demo : https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/high-availability/hystrix-request-cache.md

      7. fallback降级机制

         1. Hystrix 出现以下四种情况，都会去调用 fallback 降级机制：
            - 断路器处于打开的状态。
            - 资源池已满（线程池+队列 / 信号量）。
            - Hystrix 调用各种接口，或者访问外部依赖，比如 MySQL、Redis、Zookeeper、Kafka 等等，出现了任何异常的情况。
            - 访问外部依赖的时候，访问时间过长，报了 TimeoutException 异常。
         2. 两种经典的降级机制
            1. 纯内存数据
               在降级逻辑中，你可以在内存中维护一个 ehcache，作为一个纯内存的基于 LRU 自动清理的缓存，让数据放在缓存内。如果说外部依赖有异常，fallback 这里直接尝试从 ehcache 中获取数据。
            2. 默认值
               fallback 降级逻辑中，也可以直接返回一个默认值。
         3. 示例代码:
            1. 在 `HystrixCommand`，降级逻辑的书写，是通过实现 getFallback() 接口；而在 `HystrixObservableCommand` 中，则是实现 resumeWithFallback() 方法。
            2. demo : https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/high-availability/hystrix-fallback.md

      8. 断路器配置

         1. Enable	

            1. 控制是否允许断路器工作，包括跟踪依赖服务调用的健康状况，以及对异常情况过多时是否允许触发断路。默认值是 `true`。

               ```java
               HystrixCommandProperties.Setter()
                   .withCircuitBreakerEnabled(boolean)
               ```

         2.  RequestVolumeThreshold

            1. 表示在滑动窗口中，至少有多少个请求，才可能触发断路。Hystrix 经过断路器的流量超过了一定的阈值，才有可能触发断路。比如说，要求在 10s 内经过断路器的流量必须达到 20 个，而实际经过断路器的流量才 10 个，那么根本不会去判断要不要断路。

               ```java
               HystrixCommandProperties.Setter()
                   .withCircuitBreakerRequestVolumeThreshold(int)
               ```

         3. ErrorThresholdPercentage

            1. 表示异常比例达到多少，才会触发断路，默认值是 50(%)。如果断路器统计到的异常调用的占比超过了一定的阈值，比如说在 10s 内，经过断路器的流量达到了 30 个，同时其中异常访问的数量也达到了一定的比例，比如 60% 的请求都是异常（报错 / 超时 / reject），就会开启断路。

               ```java
               HystrixCommandProperties.Setter()
                   .withCircuitBreakerErrorThresholdPercentage(int)
               ```

         4. SleepWindowInMilliseconds

            1. 断路开启，也就是由 close 转换到 open 状态（close -> open）。那么之后在 `SleepWindowInMilliseconds` 时间内，所有经过该断路器的请求全部都会被断路，不调用后端服务，直接走 fallback 降级机制。

               而在该参数时间过后，断路器会变为 `half-open` 半开闭状态，尝试让一条请求经过断路器，看能不能正常调用。如果调用成功了，那么就自动恢复，断路器转为 close 状态。

               ```java
               HystrixCommandProperties.Setter()
                   .withCircuitBreakerSleepWindowInMilliseconds(int)
               ```

         5. 示例demo: https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/high-availability/hystrix-circuit-breaker.md

      9. 限流

         1. Hystrix 通过判断线程池或者信号量是否已满，超出容量的请求，直接 Reject 走降级，从而达到限流的作用。
         2. 限流是限制对后端的服务的访问量，比如说你对 MySQL、Redis、Zookeeper 以及其它各种后端中间件的资源的访问的限制，其实是为了避免过大的流量直接打死后端的服务。

      10. 超时设置

          1. 般来说，在调用依赖服务的接口的时候，比较常见的一个问题就是**超时**。超时是在一个复杂的分布式系统中，导致系统不稳定，或者系统抖动。出现大量超时，线程资源会被 hang 死，从而导致吞吐量大幅度下降，甚至服务崩溃。

          2. `TimeoutMilliseconds` 默认值是 1000，也就是 1000ms。

             ```java
             HystrixCommandProperties.Setter()
                 ..withExecutionTimeoutInMilliseconds(int)
             ```

          3. TimeoutEnabled 这个参数用于控制是否要打开 timeout 机制，默认值是 true。

             ```java
             HystrixCommandProperties.Setter()
                 .withExecutionTimeoutEnabled(boolean)
             ```

6. 









<h3 id="第三季">第三季</h3> 

1. HashMap相关

   1. hashmap的底层数据结构

      1. 数组+链表 / 数组+红黑树

   2. hash算法和寻址算法如何优化的

      1. hash算法优化:  (h = key.hashCode()) ^ (h >>> 16);
         1. 先将原hash值右移16位 , 然后与原hash值做异或运算. 让原来hash的高低16位进行了异或 , 让新hash的低16位同时保持了老hash的高低16位的特征. 
         2. 因为后序与(n-1)做&运算 , n-1一般不会太大,高16位都会是0 , 主要是低16位做运算 , 高16位没有参与到整个算法中. 所以新hash的低16位保留了高低16位的特征会避免一些hash冲突.
      2. 寻址算法优化:  hash & (n - 1) 代替 hash % n
         1. hash值与n(数组长度) - 1 做与&运算 . 取模运算性能较差, 并且还要考虑对负数进行额外处理 , 当数组长度是2的n次方时 , hash&(n-1)与hash对n取模效果是等价的 , &运算二进制运算性能更高 .
         2. 在初始化时 , 如果数组的长度输入其他数字，它初始化的时候会调用一个roundUpToPowerOf2方法，就是把它调整为2的幂 . 

   3. 为什么数组容量会是2的倍数，以及扩容为什么是扩成两倍

      1. 可以减少碰撞几率，2的倍数 -1 得到值所有位都是1，和计算值相与后能保证结果单一，如果位上的0越多，碰撞概率越大 举个例子。。 比如容量是2的4次方 减1就是 1111. 那么计算值1110过来和他相与， 结果是1110，另一个计算值1111和他相与结果仍是1111 各自结果不一样 不会碰撞 如果容量不是2的4次方 比如15 减1就是1110. 那么计算值1110过来和他相与， 结果是1110，另一个计算值1111和他相与结果是1110 跟前一个一样 发生碰撞了.

   4. 如何解决hash碰撞问题

      1. HashMap在hash碰撞的时候会形成链表，当链表长度超过8，并且当前数组长度大于64的时候才会转化为红黑树结构。这样做的原因是红黑树的查询复杂度是log（n），而链表的复杂度是O(n)。而当HashMap的红黑树的元素小于6时重新转化为链表结构。

         并不是链表的长度超过了默认的阈值8时，就一定转树状结构，还要判断数组的长度是否已经经过了扩容。MIN_TREEIFY_CAPACITY的值是64，就是说如果你的数组没有经过扩容操作的情况下，如果链表长度已经超过8了， 此时不转树状结构，而是进行数组扩容，数组扩容时会重新散列，将链表的节点均匀的分布，查询效率对比转树状结构也要好.

      2.  问题1：本节题目是：你知道HashMap是如何解决hash碰撞问题的吗？但是通篇好像没讲如何解决hash碰撞。个人理解，没有完美的方法完全解决hash碰撞，jdk是通过上节讲的key哈希值的高16与低16位的抑或的结果来降低hash碰撞的概率。 

      3. 问题2：jdk为什么要选择在链表长度大于8且数组长度大于64的时候转为红黑树，而在红黑树元素小于6时重新回归链表，这里面为什么时8和6呢？不是12，16等其他数字？

         长度为8时树化 长度为6时链表化；hash随机算法足够好(碰撞概率低)，就会遵从泊松分布，达到长度8的概率是 0.00000006 (百万分之六源码里的数据)；当节点的个数小于等于 6 时，红黑树会自动转化成链表，主要还是考虑红黑树的空间成本问题，当节点个数小于等于 6 时，遍历链表也很快，所以红黑树会重新变成链表

      4. 问题3:为什么不直接用红黑树就可以了，还要转化为链表再转化成红黑树呢？

         红黑树得每次增加去除元素都比较复杂,伴随着整个树得左旋右旋还有元素得重新排列,因此,它得出现是为了针对某种特殊情况下得一种优雅得操作.是一种兜底得操作.理论上讲,链表长度超过8得情况发生得概率不超过百万分之六.小概率事件得发生意味着某种错误操作得出现,所以这种情况还会继续发生,为了应对以后要到来得这种恶劣得情况才会转化成红黑树,这个玩意儿其实并不好,理想情况下不发生哈希碰撞得才是最完美得.

   5. HashMap如何进行扩容

      1. 首先是扩容的时机：是在put的最后一步来判断要不要扩容的 , 扩容阈值是数组容量*负载因子 , 2倍扩容，0.75阈值 . 
      2. 扩容过程中涉及rehash操作: 
         1. 如果该桶单元只有一个数据 , 直接 e.hash & (newCap -1 ) 重新计算新桶的位置 .
         2. 如果该桶单元是一个链表 , 每个元素 (e.hash & oldCap) == 0 判断在新桶中的位置是在原位置还是原位置+oldCap 链表的顺序不变 , 会分成两部分 , 一部分在新桶中的原位置 , 另一部分放在新桶中的原位置+oldCap , 可以看到这里并不是避免了定位的与运算 , 而是避免了链表数据进入新桶多次的hash冲突 , 
         3. 如果桶单元是一个红黑树 , (e.hash & oldCap) == 0与桶单元是链表逻辑类似，判断在新桶中的位置是原位置，还是原位置+oldCap，红黑树顺序不变 , 同时将根节点放到桶单元中会判断树中数据长度，小于等于6转换成链表。与链表的原理一致，只是多了转换成链表的判断。

   6. HashMap扩容时的线程安全问题

      1. jdk1.8之前 , 链表才有用头插思路(新增的节点放在头部 ,  这么设计考虑新增的节点会有更大概率被用到) , 但是头插在hashmap扩容(扩容时机: hashmap中元素个数 >= 容量 * 扩容因子)的时候 , 高并发情况下 , 链表在transfer的时候会形成环 , 造成死循环 . jdk1.8之后链表采用尾插法 , 同时在扩容的时候 , 将通过 e.hash & oldCap == 0将链表分为两个部分 , 一分部留在原位置 , 另一部分整体迁移到原位置+oldCap , 这样保留了原来的顺序 , 避免了resize时候的hash碰撞 , 解决了死循环问题.

2. 并发编程

   1. synchoronized关键字原理.

      1. synchronized底层的原理是跟jvm指令和monitor有关系的。每个对象内部都有一个monitor，monitor里面有一个计数器，从0开始的。如果一个线程想对一个对象加锁，就得先获取这个对象关联的monitor的lock锁。如果这个线程想获取monitor的锁，就先判断monitor的计数器是不是为0，如果为0，说明没人获取锁，这个线程就可以获取锁，执行monitorenter指令就是对monitor计数器加1  ; 如果不为0，说明已经有其他线程已经获取了锁，判断该线程是不是已经持有锁的线程 , 如果是支持重入monitor计数器加1 , 如果不是 , 这个线程就必须阻塞等待 . 当线程出synchronized代码片段，执行monitorexit指令就是对monitor计数器减1 .

      2.  synchronized一般会用来做同步控制，已经配合wait/notify做线程间通讯。该关键字在编译成class文件后可以看到对应的语句是monitorEnter与monitorExit，实际上是对应到了OS的互斥量。而1.6之前这个关键字性能不佳，所以在1.6之后引入了一系列的优化，包括偏向锁，轻量级锁，以及自适应自旋锁等等，其实核心理念都是根据当前的并发程度去尽量避免直接用到OS的互斥量去完成同步操作，因为这样会导致线程在用户态与内核态之间来回切换，比较重。

      3. syn底层，除了enter和exit，还有一个变量记录当前持有锁的线程名 ? 偏向锁的时候有，markword中存储了一个指针，指向当前偏向的线程 . 

      4. synchronized保证原子性,可见性,有序性

         1. 底层原理(保证原子性)

            1. java对象都是分为对象头和实例变量两块的，其中实例变量就是大家平时看到的对象里的那些变量数据。然后对象头包含了两块东西，一个是Mark Word（包含hashCode、锁数据、GC数据，等等），另一个是Class Metadata Address（包含了指向类的元数据的指针）.在Mark Word里就有一个指针，是指向了这个对象实例关联的monitor的地址，这个monitor实际上是c++实现的一个ObjectMonitor对象，里面包含了一个owner指针，指向了持有锁的线程 , 还有一个entrylist，想要加锁的线程全部先进入这个entrylist等待获取机会尝试加锁，实际有机会加锁的线程 .

            2. 各个线程首先都进入entryList , 通过monitorenter指令尝试竞争进行加锁，此时竞争加锁是在JDK 1.6以后优化成了基于CAS来进行加锁, 操作count计数器，比如说将count值尝试从0变为1 , 如果成功了,说明获取到锁,将owner指向该线程. 然后释放锁的时候执行monitorexit指令，先是对count计数器递减1，如果为0了就会设置owner为null，不再指向自己，代表自己彻底释放锁.

            3. 如果获取锁的线程执行wait，就会将计数器count递减为0，同时owner设置为null，然后自己进入waitset中等待唤醒，别人获取了锁执行notify的时候就会唤醒waitset中的线程进入entryList尝试竞争获取锁.

               ![synchronized的底层原理](C:\Users\guozh\Desktop\java\石杉\synchronized的底层原理.jpg)

         2. 保证可见性

            1. 在获取到锁,montorenter指令之后,添加Load屏障 , 让线程执行refresh操作 , 到总线嗅探, 对别的处理器更新过的变量,从其他处理器的高速缓存或者主内存中加载到自己的高速缓存中,确保自己看到的是最新的数据.
            2. 在释放锁,monitorexit指令之后,添加store屏障,执行flush操作,把自己处理器更新的变量的值都刷新到高速缓存中或者主内存中.

         3. 保证有序性

            1.  在monitorenter之后,Load屏障之后,加Accquire屏障 , 在monitorexit之前,加Release屏障 , 可以保障同步代码块内部的指令和外部的指令是不能重排的 , 但是同步代码快内部的指令可以重排.

               ```java
               synchronized(this){ -> monitorenter
                   Load内存屏障
                   Accquire内存屏障
                   int a= b;
                   c = 1;
                   Release内存屏障
               } -> monitorexit
               Store内存屏障
               ```

      5. Java虚拟机对锁的优化

         1. 锁消除：JIT编译器通.过逃逸分析等技术发现有些被加锁的代码不会出现线程安全问题，那么动态编译的时候就会消除掉这个加锁的操作。（一般是有些框架里面自己加的synchronized而我们作为程序员并不知道，主要是优化这个） 
         2. 锁粗化：多个同步块合并在一起去执行。
         3. 偏向锁:  偏向于第一个加锁的线程(加偏向标记Bias)，下一次这个线程再来加锁就不用加锁了，提升性能。但是仅仅适用于非常低的并发场景，因为一旦有第二个线程去尝试加锁，就会回收之前分配的偏向标记，升级为轻量级锁.
         4. 轻量级锁: 主要是基于对象头里面的mark word有个轻量级锁指针, 尝试指向持有锁的线程判断一下是不是自己加的锁 , 如果不是自己加的锁 , 那就加锁失败, 说明有别人加了锁, 这时候升级为重量级锁.
         5.  自旋锁: 对于线程持有锁很短的情况 , 采取原地自旋等待, 不会切换线程上下文 (自旋锁).
         6. 重量级锁:  线程持有锁时间很长 , 其他线程长时间获取不到锁,就会切换线程 , 执行其他线程 , 这种自己暂停切换上下文获取锁的方式就是重量级锁. 

   2. CAS的底层原理

      1. CAS（compare and set），先读旧值，再拿旧值与当前值进行比较，如果一致则可进行修改；如果不一致说明，在第一步读取旧值后，有线程将数据修改，则此次修改失败 , 会自旋进行下一次的CAS操作.

      2. cas的原子性是指compare和set这两个过程中保持原子，不会让别人来打扰我的操作，其次为什么还要compare呢，那是因为你在取值范围时候是并发取值，有可能取值都一样，所以第二个线程进来的时候必须进行compare.

         cas主要基于mesi协议中的e，也就是对该变量在硬件级别上加一个独占锁，从而来实现原子性的比较替换。

      3. CAS虽然高效的解决了原子操作问题，但仍然存在三大问题：

         1. 1.ABA问题：如果变量V初次读取的时候值是A，后来变成了B，然后又变成了A，你本来期望的值是第一个A才会设置新值，第二个A跟期望不符合，但却也能设置新值。针对这种情况，java并发包中提供了一个带有标记的原子引用类AtomicStampedReference，它可以通过控制变量值的版本号来保证CAS的正确性，比较两个值的引用是否一致，如果一致，才会设置新值。

         2.  无限循环问题（自旋）：看源码可知，Atomic类设置值的时候会进入一个无限循环，只要不成功，就会不停的循环再次尝试。在高并发时，如果大量线程频繁修改同一个值，可能会导致大量线程执行compareAndSet()方法时需要循环N次才能设置成功，即大量线程执行一个重复的空循环（自旋），造成大量开销。解决无线循环问题可以使用java8中的LongAdder，分段CAS和自动分段迁移。

            为了解决这个问题，JDK8 提供了一个类 LongAdder。把一个变量分成多个变量，让同样多的线程去竞争多个资源，就解决了性能问题。LongAdder  在内部维护了多个 Cell 原子变量，另外，多个线程在争夺同一个 Cell 原子变量时如果失败了，并不是在当前 Cell 变量上一直尝试，而是尝试对其他 Cell 变量进行 CAS 操作。最后，在获取 LongAdder 当前值时，是把所有 Cell 变量的 value 值累加后再加上 base 返回的。https://juejin.im/post/6844904175218737159

         3. 多变量原子问题：只能保证一个共享变量的原子操作。一般的Atomic类，只能保证一个变量的原子性，但如果是多个变量呢？可以用AtomicReference，这个是封装自定义对象的，多个变量可以放一个自定义对象里，然后他会检查这个对象的引用是不是同一个。如果多个线程同时对一个对象变量的引用进行赋值，用AtomicReference的CAS操作可以解决并发冲突问题。 但是如果遇到ABA问题，AtomicReference就无能为力了，需要使用AtomicStampedReference来解决。

   3. ConcurrentHashMap实现线程安全的底层原理

      1.  jdk1.8之前ConcurrentHashMap实现线程安全使用的是分段锁技术，即将一个大数组分成几个小Sequence，当并发put时，处于同一个小Sequence的put操作会串行；不同小Sequence间的put操作不受影响

      2.  jdk1.8ConcurrentHashMap优化了锁的细粒度，并发操作时，当数组元素为null时 , 对数组进行CAS ,若CAS失败,说明此时数组内不为null, 如果数组不为null(是链表或红黑树) , 不走CAS , 先用synchronized锁住 , 再对链表或者红黑树进行增删操作 . 这么设计的原因:

      3. 当数组得位置存放得是链表或者红黑树得引用得时候,此时已经发生了一次哈希冲突了,讲道理,哈希冲突得概率有,但不是很高,链表里面得数据进行添加得时候,运用cas操作是比较麻烦得,因为在多线程情况下往链表里面插数据是会报错得,这个时候只能采用sync锁来进行了.cas是比较后set,那对链表来讲,这个操作是实现不了的,链表在内存中不连续,节点的增加记录下上一个的位置就行,cas操作跟谁比较,怎么比较,hashmap的entry是个单向链表,cas操作中链表的指针如果不为null,那就得到另一个地址在进行比较,在这个过程中,链表长度突破8,对于后续的转化红黑树的操作影响也是非常巨大的.

         总的来讲,就是这个过程中进行cas的消耗,以及对编码的复杂度,都没有sync来的方便快捷,哈希冲突也是个小概率事件,对数组的不同位置加锁或者cas操作,已经完全够用了,

   4. AQS实现原理

      1. Abstract Queue Synchronizer，抽象队列同步器 . JUC包下的ReentrantLock , Semaphore等都是基于AQS做的.

         ![AQS原理图](C:\Users\guozh\Desktop\java\石杉\AQS原理图.png)

      2. 过程: 1、线程1和线程2同时对state变量CAS。2、线程1成功，更新state值为1，然后加锁。3、线程2CAS失败进去等待队列。4、线程1执行完锁住的代码块逻辑后释放锁。5、线程2被唤醒，执行CAS成功，然后加锁，执行锁住的代码块后释放锁。6.如果设置是公平锁 , 线程池3会直接进入等待队列排队, 不会去同线程2争抢.

      3. AQS的原理就是提供了一个volatile修饰的状态变量和一个双向的同步队列。提供模板方法对于独占锁和共享锁的获取和释放，至于公平锁和非公平锁是它的实现类去覆盖抽象方法做的事情，和AQS无关。

      4. ReentLock中的condition:

         1. 在使用Lock之前，我们使用的最多的同步方式应该是synchronized关键字来实现同步。配合Object的wait()、notify()系列方法可以实现等待/通知模式。Condition接口也提供了类似Object的监视器方式，与Lock配合可以实现更细粒度的等待/通知模式.
         2. 调用await()方法，将当前线程加入Condition等待队列中，当前线程释放锁，否则别的线程将无法拿到锁而发生死锁。自旋（while）挂起，不断检测节点是否在同步队列中，如果是则尝试获取锁，否则挂起。当前线程被signal()方法唤醒，被唤醒的线程将从await()方法中的while循环中退出来，然后调用acquireQueue()方法竞争同步状态。
            https://juejin.im/post/6844904030590730253

   5. 线程池的底层原理

      1. 过程:  线程池初始时是没有线程的。首先任务过来会去判断当前线程池里面的线程数是否大于核心线程数，如果小于则新建线程执行任务。执行完任务后的核心线程线程会阻塞，等待任务队列中有任务到来。如果任务过来发现当前线程池里面的线程数等于核心线程数，就将任务放在任务队列中，等待有线程来处理。如果任务队列放满了，就去判断当前线程池里面的线程数是否小于最大线程数，如果小于就新建普通线程执行任务，执行完毕之后会等待空闲时间之后 , 会销毁普通线程；如果等于最大线程数(此时任务队列也放满了)，就执行拒绝策略 . 

      2. 线程池的核心参数配置

         1.  core：核心worker数量，线程池会一直维持这个数量的worker，哪怕没有任务。
         2.  queue：如果core用完了会先将task放到queue中。
         3.  max：如果queue也满了才会再次创建新的worker直到这个max限值。
         4.  reject：如果max都满了，那就执行对应的拒绝策略了。
         5.  keepalive：超过core数量时，而queue又为空，这个时候多余的woker会等待空闲时间后就被回收掉。

      3. 在线程池中使用无界阻塞队列会发生什么问题? 

         1. 同: 在远程服务异常的情况下，使用无界阻塞队列，是否会导致内存异常飙升？
         2. 调用超时，队列变得越来越大，此时会导致内存飙升起来，同时队列里的对象GC无法回收 , 还可能会导致你会OOM，内存溢出. 如果使用有界队列，然后设置max线程数=max那么会导致创建很多线程，也可能导致服务器崩溃。 
         3. 所以要根据具体的场景以及具体的压测数据，来设定这些参数。最后就是我们可以手动去实现一个拒绝策略，将请求持久化一下，然后后台线程去等线程池负载降下来了后再读出来继续执行。\

      4. 线上机器突然宕机 , 线程池的阻塞队列中请求怎么办

         1. 因为请求数据都在内存中的，因此宕机就会丢失，但是我们可以之前将任务落库 , 机器恢复后再重新捞起执行，然后针对不同类型的请求，去做幂等或者去重的一些操作。

      5. ce线程池默认的参数

         1. 核心线程数:80

            最大线程数:400

            线程队列:1000->50

            之前几起的ce堵塞故障，就是因为队列长度设置过长，没有给予最大线程数扩增到400的机会，在队列里hold时，上游就已经超时、请求异常了。我们将队列数改为50，是为了给予更大机会开启最大线程数执行任务的机会

   6. Java内存模型

      1.  java内存模型 :  是对计算机的一个抽象，将整个计算过程分成了6步(read、load、use、assign、store、write)去执行。因为每个线程都对应一个工作内存，所以导致主存中的数据值可能并不是最新的，因此多线程情况下，data++的这个操作就会被覆盖掉。 为什么要有工作内存的？它带来了内存不可见性与伪共享这些问题。是因为CPU的速度远高于内存的读写速度，因此为了充分利用CPU资源，设计了对应的缓存，还有一些其他的加载机制。 避免内存不可见用volatie就行，但是volatile的语义并不能保证data++能达到预期效果，因为它没办法保证这个执行的原子性。

         ![java内存模型](C:\Users\guozh\Desktop\java\石杉\java内存模型.png)

      2. java内存模型的原子性 , 可见性 , 有序性

         1. 可见性: 不同线程并发对同一个数据进行操作是没有可见性的的，会发生数据错误的情况。如果能保证原子性就是在线程1修改了数据后，线程2中缓存的老数据会被过期 , 会从从主内存中获取最新的数据到工作线程进行后续操作。 

         2. 原子性是指：线程1对数据读取并操作是一个原子过程，线程1在处理过程中，其他线程不能对数据进行操作.

         3. 有序性: java虚拟机会对写好的代码进行指令重排，在多线程情况就可能会因为代码顺序调整出现问题。比如线程1判断flag准备数据，线程2判断flag确定是否准备好，依赖准备好的数据进行业务操作。如果指令重排序就可能导致线程1还未准备好数据，线程2就开始执行业务操作，发生错误。有序性是指：通过一定手段，保证不会对代码进行指令重排序.

            重排序是为了提高处理器的运用效率,处理器会保证重排序后执行代码的结果跟重排序前是一样的(单线程环境下)

      3. volatile关键字的原理

         1. volatile主要是用来解决多线程场景下变量的可见性以及顺序性。 

         2. 可见性

            对volatile修饰的变量，执行写操作的话，JVM会发送一条lock前缀指令给CPU，CPU在计算完之后会立即将这个值写回主内存，同时因为有MESI缓存一致性协议，所以各个CPU都会对主内存进行嗅探，主内存中的数据是否被别人修改 .如果发现别人修改了某个主内存，那么CPU就会将自己本地缓存的数据过期掉，然后这个CPU上执行的线程在读取那个变量的时候，就会从主内存重新加载最新的数据了 .

            1. 可见性底层硬件概念

               1.  硬件方面：处理器，寄存器，写缓冲器，高速缓存 , 内存屏障。 

                  MESI协议的实现需要两个机制: flush处理器缓存和refresh处理器缓存.

                  写的过程：处理器在计算完某个变量以后，可能将计算后的值写到以上各个硬件中去，如果该变量加了volatile，会在写操作之后加Store屏障就会走MESI缓存一致性协议，把最新的计算值flush到高速缓存或主存中（硬件实现差异）, 再将该变量更改的消息发送到总线bus中.

                  volatile变量在读操作之前加Load屏障 , 那么在其他处理器在读时候, 会进行refresh操作，就会去总线嗅探该变量的更改，就会到更改了该变量的高速缓存或者主存中去加载最新的变量值，从而保证用来计算的值是最新的.

                  ![java内存模型-volatile可见性底层原理](C:\Users\guozh\Desktop\java\石杉\java内存模型-volatile可见性底层原理.jpg)

         3. 开源代码中使用:

            1. 在很多的开源中间件系统的源码里，大量的使用了volatile，每一个开源中间件系统，或者是大数据系统，都多线程并发，volatile

               ```java
               public class Kafka{
                   private volatile boolean running = true;
                   public void shutdown(){
                   // 别的线程调用shutdown来关闭kafka , 由于 volatile保证了running变量的可见性,主线程会立刻感知到最新值,从而完成关闭.
                       running= false;
                   }
                   public static void main(){
                       // 启动kafka会运行一大堆代码 , 不能直接让其退出
                       Kafka kafka = new Kafka();
                       while(running){
                           ...
                       }
                   }  
               }
               ```

         4. 有序性

            1.  指令重排：两个没有关联关系的代码可能会被打乱顺序去执行，主要原因是为了充分利用CPU的算力。指令重排的不良影响主要发生多线程并发的情况，因此需要用到volatile关键字去保证在volatile变量赋值前的语句的顺序性。 

               1. 发生指令重排的时机: 指令重排有好几个层面都可能发生，从JIT动态编译，再到处理器运算完 , 内存重排序等。 2、指令重排也会遵守一些规则，例如两条互不相关的赋值语句，还有happen-before等等。 3、指令重排在单线程运行的情况下没有什么影响，但是在多线程的场景下会存在一些问题。

               2. JIT编译器对创建对象的指令重排以及单例模式double check实践

                  创建新对象一行语句，可以大致上分为：1、内存分配，2、执行构造函数(比较耗时)，3、赋值引用。在JIT之后可能就顺序就变成了132，可能导致NPE，因此在有一种单例模式double check的时候还需要volatile来防止指令重排导致空指针异常.

               ![单例模式懒汉式代码](C:\Users\guozh\Desktop\java\石杉\单例模式懒汉式代码.jpg)

               3. 处理器指令重排
                  1. 处理器为了提升性能会出现两种重排序情况： 1、指令乱序：指令可能会按照谁先就绪就先执行谁，然后放入重排序处理器，重新整理顺序后再放入高速缓存。 2、猜测执行：可能先执行判断体内的逻辑，在判断条件生效后再采纳原先的计算结果。
               4. 高速缓存和写缓冲器的内存重排序
                  1. 指令在处理的过程中，很可能因为一些内存组件的优化出现重排序的假象。

            2. happens-before：这个主要是由java自身去保证一些场景下代码执行的顺序性，而不用程序员去操心。里面比较重要的就是**volatile变量规则**：对一个volatile变量的写操作先行发生于后面对这个volatile变量的读操作，volatile变量写，再是读，必须保证是先写，再读.

            3. 对于volatile修改变量的读写操作，都会加入内存屏障

               1. 每个volatile写操作前面，加Release屏障，禁止上面的普通写和他重排；每个volatile写操作后面，加StoreLoad屏障，禁止跟下面的volatile读/写重排
               2. 每个volatile读操作前面，加Accquire屏障，禁止下面的普通读和voaltile读重排；每个volatile读操作后面，加LoadStore屏障，禁止下面的普通写和volatile读重排

         5. 关于原子性

            1. 32位Java虚拟机中的long和double变量写操作为何不是原子的？

               1.  long / double类型对应的是8个字节,1个字节时8bit 8*8=64位在32的虚拟机中则被拆分为高低32位,导致对long类型的变量操作不是原子性的 . 如果多个线程同时并发的执行long i = 30，就会导致有的线程在修改i的高32位，有的线程在修改i的低32位，多线程并发给long类型的变量进行赋值操作.

               2. volatile保障原子性只用于一种情况:32位的java虚拟机里 , 对long/double的赋值操作不是原子的 , 加上volatile可以保障原子的. 

                  最根本的原因是32jvm对long类型操作是2次完成的，首先，这种情况是出现在32位多核CPU上，如果是32位单核CPU，是不存在线程调度的，所以也不会有CPU中断这事儿，也就出现不了这种bug。 下面说的过程，都是在32位多核CPU上发生的： 1、CPU对long类型计算，会把long类型放到寄存器中 2、寄存器最大放32位，所以需要将long的二进制分成2段存放 3、接着多核多线程对long类型的两段二进制分别操作 4、线程1修改long的一半二进制，修改完后放到自己的高速缓存，没刷到主存。 5、线程2修改long的同一半二进制，此时重点【线程2并没有拿到线程1修改的那一半最新值】，线程2依然拿到了这个long的旧的一半二进制进行了写操作。 6、最终线程1线程2都操作long的同一半二进制，并且相互不可见时，刷到主存后就必然会导致乱码 这也就是volatile可见性和有序性“变相的”解决了long再32jvm下的原子性问题。

               3. 哪些操作在java规范中是不保证原子性的

                  1.  所有变量的简单赋值写操作，jva语言规范原生给你保证原子性的；特例: 32位java虚拟机里的long/double是不保证赋值写的原子性的；volatile可以解决这个问题；

                  2. 涉及到读取-计算-赋值的复杂操作，volatile是无法保证原子操作的，这个关键字的应用场景也不是用来保证原子性的。

                     i++

                     i = y + 1

                     i = x * y ==> 先把x和y分别从主内存里加载到工作内存里面来，然后再从工作内存里加载出来到处理其执行计算，计算后的结果写回到工作内存里去，最后还要从工作内存里把i的最新的值刷回主内存.

      4. 内存屏障硬件层面的原理

         1. 高速缓存的数据结构: 拉链散列表

            1. 1、高速缓存的底层数据结构是一个拉链散列表，也就是多个bucket。 2、每个bucket挂了很多的cache entry，由tag（对应主存中的地址），cache line(缓存数据)，flag（缓存行状态）组成。 3、在处理器对高速缓存进行读写的时候，会通过变量名执行一个内存地址解码的操作，解码出三个东西：index（哪个bucket）、tag（定位到bucket中具体的一个cacke entry）、offset（找到在cache entry中cache line的相对位置） 4、如果处理器从高速缓存中读不到对应的数据，就会去主存或者其他处理器的高速缓存中读取放到高速缓存中。 5、高速缓存是分层的，L1、L2、L3越靠前的读写速度越快。

               ![高速缓存的结构-拉链散列表](C:\Users\guozh\Desktop\java\石杉\高速缓存的结构-拉链散列表.jpg)

         2. MESI协议(缓存一致性协议)的实现原理

            1. MESI协议规定：对一个共享变量的读操作可以是多个处理器并发执行的，但是如果是对一个共享变量的写操作，只有一个处理器可以执行，其实也会通过排他锁的机制保证就一个处理器能写.

               MESI协议规定: 一组消息，就说各个处理器在操作内存数据的时候，都会往总线发送消息，而且各个处理器还会不停的从总线嗅探最新的消息，通过这个总线的消息传递来保证各个处理器的协作.

            2. 整个MESI协议运作过程。 1、存在一个变量x=0，在所有处理器中都不存在，处理器1需要用到的时候，由总线去加载完放到对应的cache entry中，此时状态是S。 2、处理器2也需要读取该值，像总线发请求，然后总线从处理器1的高速缓存或者主存中取得最新的变量值返回给处理器2，此时处理器2中的变量状态也是S。 3、此时处理器1需要执行修改，因此向总线发送invalidate的消息，等待所有处理器回复invalidate ack后，对自己高速缓存中的变量进行加独占锁，此时处理器1中的变量状态是E，而处理器2的变量状态是I。 4、最后处理器1计算完后，写回高速缓存中，释放掉独占锁，将变量状态修改为M。 5、处理器2在需要计算的时候流程同上。

            3. cache entry的flag代表了缓存数据的状态，MESI协议中划分为：

               （1）invalid：无效的，标记为I，这个意思就是当前cache entry无效，里面的数据不能使用

               （2）shared：共享的，标记为S，这个意思是当前cache entry有效，而且里面的数据在各个处理器中都有各自的副本，但是这些副本的值跟主内存的值是一样的，各个处理器就是并发的在读而已

               （3）exclusive：独占的，标记为E，这个意思就是当前处理器对这个数据独占了，只有他可以有这个副本，其他的处理器都不能包含这个副本

               （4）modified：修改过的，标记为M，只能有一个处理器对共享数据更新，所以只有更新数据的处理器的cache entry，才是exclusive状态，表明当前线程更新了这个数据，这个副本的数据跟主内存是不一样的

            4. 采用写缓存器和无效队列优化MESI的性能:  

               1. 写缓冲器：修改的操作会变成：将修改的后的值直接写到写缓冲器，然后像主线发送invalidate失效消息，就认为写成功了 , 处理器就去处理别的事情了。在写缓存器收到全部的ack后，处理器再去对高速缓存进行独占和修改的操作。 

               2. 无效队列：同样是为了提高处理器的利用率，将收到的失效请求先放进一个无效队列，收到后就直接返回ack，最后自己慢慢消费无效队列的请求去将高速缓存中的数据失效掉。

                  ![写缓冲器和无效队列优化MESI性能](C:\Users\guozh\Desktop\java\石杉\写缓冲器和无效队列优化MESI性能.jpg)

               3. 引入写缓存器和无效队列带来的有序性和可见性问题

                  1.  可见性：处理器1直接将变量x修改后的值写入写缓冲器，而此时处理器2需要读x变量的值，那么就会去找主线bus加载主存或者处理器中的x变量值，那么此时处理器2读到的就是旧数据，也就是看不到处理器1对x变量的修改。还有一种情况就是，处理器2还没消费无效队列的无效请求，处理器2的高速缓存中依旧存在一个有效的旧值。 

                     有序性： storeLoad重排：处理器先写x的数据，写到了自己的写缓冲器里面了，导致其他处理器读不到，而load操作却正常执行了。结果对其他处理器而言，看起来就像是load先发生，而store确没发生。 storeStore重排：变量a的状态是s，因此将修改后的数据写到了写缓冲器里面，而变量b的状态是m，因此直接独占后直接修改高速缓存中的值。因此在这种情况下，对于其他处理器而言，就相当于a的修改不可见，而b的修改可见，也就是看到他们的顺序重排了。

                  2. 解决: 

                     1. 可见性: Store屏障 + Load屏障

                        加Store屏障 , 就会强制性要求你对一个写操作必须阻塞等待到其他处理器返回invalidate ack之后 , 才对数据加锁修改到高度缓存中,在写数据之后强制flush操作刷到高速缓存或主存中通知其他处理器.

                        加Load屏障, refresh操作就是发现无效队列里有有invalidate消息, 就读取invalidate消息把自己本地高速缓存置为 I (过期)，重新取其他处理器或者主内存中重新获取新值.

                     2. 有序性: Acquire屏障(StoreStore) , Release屏障(StoreLoad)

                        acquire还有release其实就是store和load屏障的两两组合，他们唯一的目的就是保证（本来处理器在执行代码时可能为了提交执行的效率，会让一些不太耗时的先执行，这样就会导致一些耗时的可能就后执行，这样它们就是乱序执行的）加上了此类的屏障，它们必须和前面的指令保持，相同的硬件执行过程，比如强制走主内存呀，强制读取新值呀 ,强制将写缓存器的数据写入高速缓存，这样就能保证其执行的先后顺序不再发生改变。

      5. volatile、synchronized答题套路(从硬件层面)

         1. 硬件层面的原理 -> MESI协议在硬件层面运行的原理 -> 这套原理为何会导致可见性和有序性的问题 -> 各种内存屏障是如何在硬件层面解决可见性和有序性的问题 -> volatile和synchroized是如何加各种内存屏障来分别保证可见性和有序性的.
         2.  首先硬盘和内存的发展数据远不及cpu的发展速度，而要保证cpu的告诉运行就对cpu增加一个高速缓存。但是增加高速缓存以后这就导致了各个cpu之间内的高速缓存造成数据不一致的现象， 
         3. 为了解决这种数据不一致的现象就提出了MESI协议，通过修改各个高速缓存中数据的状态来保证数据一致性的问题。M是修改状态、E是独占状态也就是加锁、S是共享状态、I是无效状态。
         4.  虽然通过MESI可以保证数据的一直性，但是却会大大的影响cpu的处理速度，因为cpu在修改一个处于S状态的数据时，首先会对总线发出一条invalid的通知，告诉所有其他的cpu(持有该数据)数据失效，然后等到接受到其他cpu的invalid ack消息才会对这条数据进行修改，等待ack这个时候其实是阻塞的，cpu只有等待所有ack返回之后才会执行其他的指令，而相对于cpu修改数据而言，等待ack消息的耗时是特别长的，这就体现出了cpu性能下降这个问题。 
         5. 为了解决这个问题，就又对cpu内增加写缓存和失效队列这两个概念，cpu要写一个数据的时候首先发送invalid指令，然后把接收ack这个工作交给写缓存器，然后cpu自己去执行其他的指令。其他的cpu收到invalid消息之后直接把invalid消息扔到失效队列中然后返回invalid ack消息，这样cpu就不用因为等待ack指令而降低处理速度。 
         6. 但是这种情况又会引发可见性和有序性的问题，被扔到写缓存里的数据不会保证什么时候完成，这就可能cpu顺序写入指令1、指令2，将他们扔到写缓存中，但是指令2先执行完成，而其他线程先看到该线程的执行顺序为指令2、指令1，这是有序性的问题。可见性也就不用说了，要修改的数据还在写缓存中等着没执行呢。
         7.  为了解决这种可见性和有序性的问题就引入了内存屏障的概念，store屏障:在修改一个数据之后强制cpu执行完写缓存,等待所有的ack消息把数据刷新到高速缓存或者主内存。load屏障: 在读取一个数据之前强制执行无效队列中对该数据时效的指令，然后从其他高速缓存或者主内存中读取最新数据。

3. Spring相关

   1. spring的IOC机制

      1. 没有spring的情况: tomcat最初的流程是接受http请求，然后封装后转发给我们自己写的servlet，最后由我们手动 new 实现类的对象去执行业务逻辑 , 假如有几十处new对象,当我们要替换对象的时候就要改几十次。弊端：耦合性太高。 

      2. 紧接着整个体系进行演化，Tomcat启动后会去启动一个spring容器，由spring将对应的bean进行创建于初始化，并且管理对应的依赖关系，这里的就是控制反转了，将类的调用关系由主动变成了被动，交给了spring去管理。有了这个机制以后，就可以轻松的完成解耦.  spring的IOC的核心技术就是通过反射技术 .

      3. spring +springmvc启动过程:

         1. tomcat在启动时会触发容器初始化事件.

         2. spring的contextLoaderListener监听到这个事件后会执行contextinitialized方法,在该方法中会初始化spring的根容器即ioc容器,初始化完成之后,会将这个容器放入到servletContext中,以便获取 

         3. tomcat在启动过程中还会去扫描加载servlet,比如springmvc的dispatchServlet(前端控制器),用来处理每一个servlet 

         4. servlet一般采用延时加载,当一个请求过来的时候发现dispatchservlet还未初始化,则会调用其init方法,初始化时候会建立自己的容器spring mvc容器,同时spring mvc容器通过servletcontext上下文来获取到spring ioc容器将ioc容器设置为其父容器; 

         5. #### 注意事项:spring mvc中容器可以访问spring ioc容器中的bean反之不能 . 即在controller中可以注入service bean对象,在service中不能注入controller容器.

      4. spring ioc循环依赖问题

         1.  Spring解决IOC的循环依赖

            1. Prototype的场景不支持循环依赖 , spring内部会判断 ,抛出异常.

            2. Singleton场景 :  https://juejin.im/post/6844903968238206990

               1. 通过构造器注入的循环依赖会报错BeanCurrentlyInCreationException , 这个无法解决

               2. 通过setter(注解)注入的. 通过提前暴露一个单例工厂方法，从而使其他 bean 能引用到，最终解决循环依赖的问题。
                  1. 在创建A的时候会将实例化的A通过addSingleFactory方法缓存beanFactoryA到singletonFactories的Map缓存中,然后执行A的属性填充方法populateBean ,检测到B, 去实例化B
                  2. 开始实例化B,经历创建A的流程,到了属性填充方法,检测到依赖A
                  3. 调用A的getBean()方法 , 先去缓存中检测是否已经有创建好的bean或者beanFactory , 检测到缓存中有beanFactoryA,直接调用beanFactoryA获取到A的引用.这样B的依赖注入完成.
                  4. B创建完成后,A也会依赖注入成功,创建完成.
                  5. 参考processon的流程图.

               ![Spring IOC解决循环依赖原理图](C:\Users\guozh\Desktop\java\石杉\Spring IOC解决循环依赖原理图.jpg)

            3. 工作中，经常会遇到与其它团队的合作，也会遇到同时需要对方的新接口支持，例如在 RPC 中遇到循环调用，那我建议还是换一种方案，例如通过消息解耦，避免循环调用，实在没办法要循环调用，要记得在方法中加上退出条件，避免无限循环

   2. Spring的AOP机制

      1. AOP面向切面编程，所谓切面就是对一类重复业务的抽象，例如事务。本来事务的操作耦合在各个业务层代码中，不好统一管理，这也叫做编程式事务。我们就可以通过AOP将事务定义成一个切面，然后定义对应的通知与切点，这样事务的管理变得更加清晰，代码也变得更加优雅。
      2. 关于AOP的实现，基于动态代理，动态代理的实现有两种: jdk动态代理和cglib动态代理，分别对应静态代理中的两种实现——组合/继承。一种通过组合的方式获取目标函数，一个通过继承目标类通过父类调用函数。
      3. aop:面向切面,通过动态代理的方式来生成其代理对象 , 在方法执行前后加入自己的逻辑
         1. 代理方式:jdk动态代理(接口) cglib动态代理(基于类) 
         2. 相关名词: 1. JoinPoint连接点:拦截的接口的方法 2. Pointcut切入点:对哪些连接点进行拦截 3. Advice通知:比如前置通知 后置通知 环绕通知 4. aspect切面:切入点和通知组成 
         3. 切入点 execution表达式 : execution 权限修饰符 返回值类型 包名.类名.方法名(参数) 
         4. 通知类型 1. 前置通知:方法执行之前 2. 后置通知:在方法正常执行完毕后(提交事务) 3. 最终通知:在方法正常执行完毕或者出现异常 4. 异常通知:执行过程中出现异常(事物回滚) 5. 环绕通知:方法执行前后,目标方法默认不执行需自己调用方法
      4. cglib动态代理
         1. jdk基于接口，cglib基于子类.cglib创建的动态代理对象比JDK的动态代理对象的性能高，但是创建对象的时间长.对于单例无需频繁创建对象,用cglib合适 . 

   3. Spring中的Bean是线程安全的么

      1. bean一般只用两种，singleton与prototype。大部分情况下都使用的默认状态，也就是单例模式。 因此就意味着ioc容器里面该实现只有那么一个类，也没有加其他的同步措施，自然就是非线程安全的。但是线程安全与否取决于是否有多线程与全局变量，大部分的应用中，各个bean都是无状态的，因此不需要额外特别关心是否安全的问题。所以单例中的成员变量要使用线程安全的,比如CurrentHashMap之类的.

   4. Spring的事务

      1. 实现原理

         1. spring使用AOP思想，对你的这个方法在执行之前，先去开启事务，执行完毕之后，根据你方法是否报错，来决定回滚还是提交事务.

      2. 事务传播机制 . https://juejin.im/post/6844903600943022088

         1. 事务的传播，是用于servcie层的类相互调用时，解决事务作用范围的一个机制。

         2. 同service内方法A内部直接调用本类的方法B，方法B的事务传播行为会失效 , 在不同的bean才会生效.

         3. 传播类型:

            1. PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。

            2. PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。

               方法Ａ调用方法Ｂ，Ａ和Ｂ的是两个独立的事务互不影响．如果说方法A出错了，此时仅仅回滚方法A，不能回滚方法B，用REQUIRES_NEW传播机制，让他们俩的事务是不同独立的.

            3. PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则按REQUIRED属性执行。

               嵌套事务，外层的事务如果回滚，会导致内层的事务也回滚；但是内层的事务如果回滚，仅仅是回滚自己的代码 , 会回滚到之前的savePoint点. 方法A调用方法B，如果出错，方法B只能回滚他自己，方法A可以带着方法B一起回滚

   5. Spring Boot的核心架构

      1. springboot主要是对各个常用框架的整合，然后自动装配，而简化spring繁杂的xml配置 . springboot还内嵌了一个web服务器，一定程度上简化了部署。
      2. spring boot的启动流程
         1. 在main中调用run()之后 , 收集各种回调接口和监听器 , 通告started();
         2. 创建并准备Environment,设置给Application.
         3. 创建并初始化ApplicationContext , 设置Environment,加载配置等. 将之前通过@EnableAutoConfiguration获取的所有配置以及其他形式的IoC容器配置加载到已经准备完毕的ApplicationContext.
         4. ioc容器refresh , 进行配置的解析、各种BeanFactoryPostProcessor和BeanPostProcessor的注册、国际化配置的初始化、web内置容器的构造等等 , 之后完成程序的启动.

   6. Spring Bean的生命周期

      1. 根据配置生成bean对象 -> 为bean传入参数 -> 实现了ApplicationContextAware接口可以拿到spring容器 -> 实现beanpostProcessor接口可以在bean构造完成创建的前后去做一些操作, postProcessBeforeInitialization ,  postProcessAfterInitialization(AOP是在这个过程中的)-> 最后还可以配置init-method会调用对应的函数 -> 当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，会调用其实现的destroy()方法 , 如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的销毁方法。

   7. Spring中使用哪些设计模式

      1. 工厂模式
         1. pring ioc核心的设计模式的思想提现，他自己就是一个大的工厂，把所有的bean实例都给放在了spring容器里（大工厂），如果你要使用bean，就找spring容器就可以了，你自己不用创建对象
      2. 单例模式
         1. 每个bean走的都是一个单例模式，确保说你的一个类在系统运行期间只有一个实例对象，只有一个bean，用到了一个单例模式的思想
      3. 代理模式
         1. AOP ,  对一些类的方法切入一些增强的代码，会创建一些动态代理的对象，让你对那些目标对象的访问，先经过动态代理对象，动态代理对象先做一些增强的代码，调用你的目标对象

   8. 如何排查cpu过高(80%,90%)？

      1. top -c 查看所有的进程 
      2. 在1的基础上键入P让cpu从高到底排序
      3.  选择2中cpu占比最高的pid进程 
      4. top -Hp pid 查看pid对应的线程对cpu的占比 
      5. 在4的页面键入P让当前pid的线程cpu占比从高到低排序 
      6. 获取第5步骤中的线程占比最高的线程id,由于linux打印的id是16进制的 
      7. 将第6的线程id十六进制转为10进制 print "%xn" tid 
      8. 打印指定pid下指定tid的jstack日志,jstack pid | grep tid -C 10 --color 
      9. 根据堆栈信息找到代码块

   9. 线上进程kill不掉怎么办

      1. 之前遇到过一个case: kill一个进程死活杀不死，那个进程成了僵尸进程，就是zombie状态。这是因为这个进程释放了资源，但是没有得到父进程的确认。
      2. ps aux，看看STAT那一栏，如果是Z，那么就是zombie状态的僵尸进程 
      3. ps -ef | grep 僵尸进程id，可以找到父进程id , 然后kill掉父进程.

   10. 服务器存储空间磁盘快满了（95%），该如何解决？

       1. df -h，先看看磁盘使用的情况
       2. 到你的系统部署的地方 , 看看是不是日志过多导致的.如果过多，就删除掉一些日志就行了(rm -f xxx.txt).还可以写个shell脚本，crontab定时，定期删除7天以前的日志.
       3. 要是不行，那就：find / -size +100M |xargs ls -lh，找找大于100m的文件，但是如果有大量的小文件，那么这样是不行的.
       4. 用：du -h >fs_du.log，看看各个目录占用的磁盘空间大小，看看是不是哪个目录有大量的小文件

4. 网络模型

   1. TCP/IP四层网络模型 , OSI七层网络模型

      1. OSI七层模型: 应用层,表示层,会话层,传输层,网络层,数据链路层,物理层.

      2. TCP/IP四层模型: 数据链路层,网络层,传输层,应用层 , [笔记链接](https://mp.weixin.qq.com/s?__biz=MzU0OTk3ODQ3Ng==&mid=2247486988&idx=1&sn=bccd20d613e4f6e1a8724880740ad8c0&chksm=fba6e60fccd16f190124b9c130ea4b6339fa443fea0e4dd3f443ef23abd51f5a34d9b44238ac&mpshare=1&scene=1&srcid=09032Jm5Fn5yEVbox11j8uFv&sharer_sharetime=1599141411956&sharer_shareid=23c6153a783d02d30d285d8c0cbc657e&key=9aff5afafa6fca8df00966effde47641adcb0a62d4f76873858abc27bbe3264ff19289b24b02d39c68e28fc35407956d43ab127b29fd873bafa9dc0052d0d9d9eae82bc904d34e465ba93c4d0b962e26f42819e31315514b0e64b017dc0c2ff9ed75df4559e8bf4a461c27f52213e11b62343f9721ba5f1807064e667827516a&ascene=1&uin=NDMwNDUwMzIw&devicetype=Windows+10+x64&version=62090529&lang=zh_CN&exportkey=Aao9AiiOUiwEZezV%2Bme0vWU%3D&pass_ticket=cZWLPtHkJxR3dB9tE1kdHlnJBXFOJBJTCDVbvoDAOcvKVBqjZPp%2BX1Wmq2Xb%2F9P9&wx_header=0)

         1. 物理层: 网线 , 海底光缆 , 在物质层面把各个电脑连接起来 , 物理层负责传输0和1的电路信号.

         2. 数据链路层:  

            1. 定义了一套协议来给0/1信号分组 , 以太网协议: 一组电信号是一个数据包，叫一个帧（frame），每个帧分成两个部分，标头（head）和数据（data），标头包含一些说明性的东西，比如说发送者、接收者和数据类型之类的。
            2. 每台电脑要往另外一台电脑发送数据，一堆0/1电路信号，封装成数据包，包含头和数据，头里包含了从哪儿来到哪儿去，必须从一台电脑的一个网卡，发送到另外一个电脑的一个网卡，所以以太网发送的数据包必须得指定，目标电脑的网卡的mac地址。(windows上，ipconfig /all，看看物理地址，就是mac地址，7C-67-A2-20-AB-5C).
            3. 通过以太网发个数据包，对局域网内的电脑，是广播出去的。每台电脑都从数据包里获取接收者的mac地址，跟自己的mac地址对比一下，如果一样，就说明这是发给自己的数据包。

         3. 网络层

            1. IP协议 , IP地址就可以让我们区分哪些电脑是一个子网的。IP地址有IPv4和IPv6两个版本，目前广泛使用的是IPv4，是32个二进制数字组成的，但是一般用4个十进制数字表示，范围从0.0.0.0到255.255.255.255之间。每台计算机，都会分配一个ip地址，ip地址的前24位（就是前面3个十进制数字），代表了网络，后8位（就是最后1个十进制数字），代表了主机。

            2. 要判断两个ip地址是不是一个子网的: 把两个ip地址和自己的子网掩码进行二进制的与运算，与运算之后，比较一下代表网络的那部分。如说ip地址是192.168.56.1，子网掩码是255.255.255.0.

            3. 如果要接受数据包的计算机不在子网内，那么就不能通过广播来发送数据包，需要通过路由来发送数据包。路由器负责将多个子网进行连接. 网络交换机是通过mac地址来寻址和传输数据包的；但是路由器是通过ip地址寻址和传输数据包的。网络交换机主要用在局域网的通信，一般你架设一个局域网，里面的电脑通信是通过数据链路层发送数据包，通过mac地址来广播的，广播的时候就是通过网络交换机这个设备来把数据广播到局域网内的其他机器上去的；路由器一般用来让你连入英特网。

               家里的路由器是包含了交换机和路由的两个功能的，如果是连接到局域网内的设备就把线插LAN那儿；如果是连接到英特网，就把线插在WAN那儿。

            4. 一个子网内的机器之间通信，就是在数据包里写上对方的mac地址，然后交换机广播出去ok了；但是如果是跨子网的通信，就是写上对方的ip地址，然后先通过mac地址广播到路由器，让路由器再根据另外一个子网的ip地址转换为mac地址，通过另外一个子网的交换机广播过去。

         4. 传输层

            1. 传输层，其实是建立某个主机的某个端口，到另外一个主机的某个端口的连接和通信的。
            2. udp和tcp都是传输层的协议，作用就是在数据包里加入端口号，可以通过端口号进行点对点的通信了。udp协议是不可靠的，发出去人家收到没有就不知道了；tcp协议是可靠的，要求三次握手，而且要求人家接收到数据必须回复你。
            3. 传输层的tcp协议，仅仅只是规定了一套基于端口的点对点的通信协议，包括如何建立连接，如何发送和读取消息，但是实际上如果你要基于tcp协议来开发，你一般是用socket，java socket网络编程.

         5. 应用层

            1. 通过传输层的tcp协议可以传输数据，但是人家收到数据之后，怎么来解释？比如说收到个邮件你怎么处理？收到个网页你怎么处理？类似这个意思，所以针对各种不同的应用，邮件、网页之类的，都是定义不同的应用层协议的。
            2. 针对各种不同的应用，邮件、网页之类的，都是定义不同的应用层协议的。最常见的，应用层的协议就是http协议，进行网络通信。

         6. DNS: 

            1. DNS地址是啥呢？Domain Name System。因为我们一般定位是通过ip地址+mac地址+端口号来定位一个通信目标的，但是如果在浏览器上输入一个www.baidu.com，咋整？这个时候是先把www.baidu.com发给DNS服务器，然后DNS服务器告诉你www.baidu.com对应的ip地址的。

            ![TCP_IP四层网络模型](C:\Users\guozh\Desktop\java\石杉\TCP_IP四层网络模型.jpg)

         7. 总结:

            1.  物理层：物理设备，传输0/1电路信号。 2、数据链路层：解析/组包电路信号，走以太网协议，封装对应带有mac地址的数据包。 3、网络层：通过IP再次对底层网络进行抽象，将网络划分为局域网，广域网等等。 4、传输层：TCP/UDP等协议作用层。 5、应用层：HTTP/STMP等协议作用层。 6、交换机：作用于数据链路层，作用是广播以太网数据包。 7、路由器(网关)：作用于网络层，连接多个子网。 8、ARP协议：作用于数据链路层，主要是通过广播的方式，拿到目标IP的对应mac地址，并缓存一段时间。 9、DNS协议：作用于应用层，主要是通过UDP的方式拿到域名对应的IP地址。 9、整个过程：数据包由应用层对应的协议产生，然后向下逐一封装，TCP报文 -> IP报文 -> 以太网报文。最后由交换机广播在整个子网内，如果目标mac地址不在同一子网内，会由路由器去一次次转发，最后目标子网的网关接收到，发现目标电脑的mac地址在自己的子网内，于是再通过交换机在自己的子网内广播，最终目标电脑接收到报文。

            2. 一个ip地址通过网关时如何知道下一次转向哪个网关?  

               通过网关的不是ip地址,是机器的广播,网关发送广播,是向局域网内的所有机器广播,以太网协议就是会让带有ip地址和网卡mac地址的信息只能被特定的机器获取到.网关不做具体广播到哪个网关的操作,它会向局域网内所有地址进行广播,而网关和普通的机器的差别就是,普通机器识别不是自己的,就不管了,网关识别到不是自己的,会再广播出去.

   2. 浏览器请求baidu的全流程是怎样的?

      1. DNS域名解析，通过UDP广播的方式拿到对应域名的IP。
      2. 应用层组装http的请求报文.
      3. 传输层组TCP报文(把应用层数据包给封装到tcp数据包中去，而且会加一个tcp头,包括接受者端口号(默认是80端口)和发送者端口号)
      4. 网络层组网络ip协议报文(ip头里加上接收者的ip地址和发送至的ip地址)
      5. 数据链路层组以太网协议报文(加以太网数据包的头，头里放了本机网卡mac地址，和网关的mac地址  , 和切割后数据包的序号) , 但是以太网数据包的限制是1500个字节，但是假设这个时候ip数据包都5000个字节了，那么需要将ip数据包切割一下 , ip头里包含了每个数据包的序号。
      6. 这4个以太网数据包都会通过交换机发到你的网关上，然后你的路由器是可以联通别的子网 , N多个网关转发之后，就会跑到百度的某台服务器，接收到4个以太网数据包。
      7. 百度服务器接收到4个以太网数据包以后，根据ip头的序号，把4个以太网数据包里的ip数据包给拼起来，就还原成一个完整的ip数据包了。接着就从ip数据包里面拿出来tcp数据包，再从tcp数据包里取出来http数据包，读取出来http数据包里的各种协议内容，接着就是做一些处理，然后再把响应结果封装成hhtp响应报文，封装在http数据包里，再一样的过程，封装tcp数据包，封装ip数据包，封装以太网数据包，接着通过网关给发回去。

   3. TCP三次握手流程图 , 为啥是三次不是两次或者四次?

      1. 三次握手

         1. 第一次握手，客户端发送连接请求报文，此时SYN=1、ACK=0，seq = x，接着客户端处于SYN_SENT状态，等待服务器响应。
         2. 第二次握手，服务端收到SYN=1的请求报文，需要返回一个确认报文，ack = x + 1，SYN=1，ACK = 1，seq = y，发送给客户端，自己处于SYN_RECV状态。
         3. 第三次握手，客户端收到了报文，将ack = y + 1，ACK = 1，seq = x + 1

      2. 为啥不是两次或者四次?

         1. 假设两次握手就ok了，要是客户端第一次握手过去，结果卡在某个地方了，没到服务端；完了客户端再次重试发送了第一次握手过去，服务端收到了，ok了。

            结果，尴尬的是，后来那个卡在哪儿的老的第一次握手发到了服务器，服务器直接就返回一个第二次握手，这个时候服务器开辟了资源准备客户端发送数据啥的，结果客户端根本就不会理睬这个发回去的二次握手，因为之前都通信过了 , 白白浪费了服务器的资源在等待。 

            但是如果是三次握手，那个二次握手发回去，客户端发现根本不对，就会发送个复位的报文过去，让服务器释放掉开辟的资源。

         2. 3次握手就够了，不需要4次或者5次浪费资源了。

      3. tcp断开连接的四次挥手

         1. 第一次挥手，客户端发送报文，FIN=1，此时进入FIN-WAIT-1状态
         2. 第二次挥手，服务端收到报文，这时候进入CLOSE_WATI状态，返回一个报文，ACK=1，ack=u+1。客户端收到这个报文之后，直接进入FIN-WAIT-2状态，此时客户端到服务端的连接就释放了。
         3. 第三次挥手，服务端发送连接释放报文，FIN=1，ack=u+1，服务端进入LAST-ACK状态
         4. 第四次挥手，客户端收到连接释放报文之后，发应答报文，ACK=1，ack=w+1，进入TIME_WAIT状态，等待2MSL的时间客户端进入CLOSED状态  (为了防止第四次挥手的消息超时，2MSL的时间可以处理超时重发) ，服务端收到报文之后就进入CLOSED状态。

      4. 为什么需要四次挥手才能断开连接?

         1. 因为全双工,发送方和接收方都需要FIN报文和ACK报文.

      5. 服务器中出现大量CLOSE_WAIT状态的原因?

         1. Client关闭socket连接,Server没有及时关闭连接,可能情况:1)缺少一些释放资源的代码; 2)处理请求的线程配置不合理.

      6. Socket的工作原理？Socket跟TCP IP之间是啥关系？

         1. Soceket属于传输层 , 是传输层协议(tcp协议)的一个编程规范 , 程序员一般都是面向socket来编程的. 直接用soceket封装tcp数据包 , 不走应用层封装数据包.
         2. 大体来说这个步骤，就是我们搞一个ServerSocket无限等待别人来连接你，然后某个机器要跟你连接，就在本地创建一个socket去连接你，然后建立连接之后，在服务器上，ServerSocket也会创建出来一个socket的。通过客户端的socket跟服务端的socket进行通信，我给你写数据，你读数据，你给我写数据，我读数据，就这个过程。

   4. HTTP协议的工作流程

      1. http就是一个协议, 规定了请求报文的格式 . http工作流程，发起个http，底层都是tcp、ip、以太网那块再走，一层一层包裹数据包。所以http的关键就是让你聊聊http请求和http响应的规范 , 其实请求的报文，就是请求头、请求方法、请求体，GET/POST.

      2. http 1.0、http 1.1、http 2.0具体有哪些区别

         1. http 1.0默认是短连接，就是浏览器每次请求都要重新建立一次tcp连接，完事儿了就释放tcp连接。效率低，不利于复杂网页的加载。

         2. http1.1：默认支持长连接keep-alive，浏览器打开一个网页之后，底层的tcp连接就保持着，不会立马断开，之后加载css、js之类的请求，都会基于这个tcp连接来走 , 大幅度的提升复杂网页的打开的速度，性能。http 1.1还支持host头，也就可以支持虚拟主机；而且对断点续传有支持。

            http的长短连接，本质上是TCP的socket连接在一次交互完成后是否进行关闭。

         3. http2.0：支持多路复用，基于一个tcp连接并行发送多个请求以及接收响应，解决了http 1.1对同一时间同一个域名的请求有限制的问题。二进制分帧，将传输数据拆分为更小的帧（数据包），frame（数据包，帧），提高了性能，实现低延迟高吞吐。

      3. HTTPS的工作原理,加密通信?

         1. 浏览器发送自身支持的加密规则，然后网站返回对应的证书 (网站地址,加密公钥,颁发机构) 回来。(证书被截取公钥被篡改也没有关系 , 因为是非对称加密, 在第二步中,服务器用私钥也是解不开这个经过被篡改的公钥加密的随机密码的,无从获取消息,连接建立不了) . 
         2. 浏览器校验证书后出现一把小锁，然后生成随机数，计算消息hash值，再用该随机数对消息进行加密，最后将随机数进行公钥加密，发送给网站。网站收到消息后，先对整体随机数进行私钥解密，再通过随机数解密消息，对比其hash值，确认未被篡改。 
         3. 网站再用随机数加密消息发送给浏览器确认，之后浏览器利用随机数解密确认以后，那么以后就用随机数进行加密后进行通信。
         4. 这个随机数是不能被第三方获取的，因为一开始是浏览器自己生成的，然后发送出去的时候已经用公钥加密了，没有私钥就解不出来。因此，这个随机密码就只会有浏览器和目标网站能拿到。

5. 进程通信,线程通信

   1. 进程间通信方式:　管道（pipe）、命名管道（fifo）、消息队列，共享内存（System V）
   2. 线程直接如何切换：时间片算法，cpu给每个线程一个时间片（比如5ms）来执行，时间片结束之后，就保存这个线程的状态在线程上下文，然后切换到下一个线程去执行，这就是所谓多线程并发执行的原理，就是多个线程来回来去切换，每个线程就一个时间片里执行。

6. 网络与IO相关

   1. nio , bio , aio的区别

      1. BIO同步阻塞: 一个客户端请求就要开始一个线程创建并且长期维持一个socket与客户端保持通信.如果客户端数量过大 , 服务端线程数数会多达几千/几万,导致服务器端崩溃.

         可愿意用一个线程池来优化，固定线程数量来处理请求，但是高并发请求的时候，还是可能会导致各种排队和延时，因为没那么多线程来处理。

      2. NIO同步非阻塞: Selector , Channel , Buffer

         1. 每一个客户端请求来都会建立一个对应的channel同时注册到selector , selector(多路复用器,一个线程) 会不断轮询注册的channel , 每一个获取一批有事件的channel , 然后从线程池请求一个工作线程来处理 , 工作线程和channel之间有个buffer , 两者通过buffer来读写数据 .  这个处理的过程中，工作线程要先读取数据，处理，再返回的，这是个同步的过程。
         2. 如果有1000个客户端 , 每秒有50个客户端来请求 , 那么这样服务端只用维护51个线程就行 . 而用BIO就得维护1000个线程.

         ![NIO原理图](C:\Users\guozh\Desktop\java\石杉\NIO原理图.jpg)

      3. AIO异步非阻塞 : 工作线程在读写数据的时候将操作交给系统内核来处理 , 等操作系统干完了来回调通知工作线程 . 

      4. 优劣分析：

         1. BIO：基于这种模型下的网络通信，一个请求就需要一个线程，因此不能承受大量客户端。 优化后的BIO：也是同样的网络模型，不过用线程池来作为了一个缓冲，但是问题依旧是每个请求都需要一个线程去处理，而且资源受限。一旦某些请求卡死，则线程池中线程无法释放会出现问题。 
         2. NIO：NIO其实有两个概念，一个是上面的多路复用模型称之为 no-block IO，还有一个是java里面的New IO库，一般都讲后面那个基于前面那个模型去实现的。对应的主要组件有selecter/buffer/channel。优点是可以通过多路复用模型管理大量的连接，缺点在于编程的复杂度以及java库本身的bug，所以才有了netty这个框架对New IO库进一步的封装优化。

      5. 文件的BIO / NIO / AIO

         1. BIO的这个同步阻塞，不是完全针对的网络通信模型去说的，针对的是磁盘文件的IO读写，FileInputStream，BIO，卡在那儿，直到你读写完成了才可以.
         2. NIO为啥是同步非阻塞？就是说通过NIO的FileChannel发起个文件IO操作，其实发起之后就返回了，你可以干别的事儿，这就是非阻塞，但是接下来你还得不断的去轮询操作系统，看IO操作完事儿了没有。

         3. AIO为啥是异步非阻塞？就是说通过AIO发起个文件IO操作之后，你立马就返回可以干别的事儿了，接下来你也不用管了，操作系统自己干完了IO之后，告诉你说ok了。同步就是自己还得主动去轮询操作系统，异步就是操作系统反过来通知你。

   2. Netty的架构原理图 , 他是如何体现Reactor架构思想的

      1. 架构原理图

         ![网络通信netty框架原理](C:\Users\guozh\Desktop\java\石杉\网络通信netty框架原理.jpg)

      2. Reactor架构思想 . [文章链接](https://juejin.im/post/6844903702550020109#heading-11)

         1. Reactor是反应堆的意思，Reactor模型，是指通过一个或多个输入同时传递给服务处理器的服务请求的**事件驱动处理模式**。 服务端程序处理传入多路请求，并将它们同步分派给请求对应的处理线程，Reactor模式也叫Dispatcher模式，即I/O多了复用统一监听事件，收到事件后分发(Dispatch给某进程)，是编写高性能网络服务器的必备技术之一。

            Reactor模型中有2个关键组成：

            - Reactor 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对IO事件做出反应。 它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人
            - Handlers 处理程序执行I/O事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。Reactor通过调度适当的处理程序来响应I/O事件，处理程序执行非阻塞操作

         2. Netty主要**基于主从Reactors多线程模型**（如下图）做了一定的修改，其中主从Reactor多线程模型有多个Reactor：MainReactor和SubReactor：

            - MainReactor负责客户端的连接请求，并将请求转交给SubReactor
            - SubReactor负责相应通道的IO读写请求
            - 非IO请求（具体逻辑处理）的任务则会直接写入队列，等待worker threads进行处理

   3. 

      

   

   

   

   

   

   

   

   

   1. threadlocal内存泄漏问题以及解决方案

      1. ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value永远无法回收，造成内存泄漏。 其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。 但是这些被动的预防措施并不能保证不会内存泄漏

   2. 

   3. 

      

   <h3 id="MQ相关">MQ相关</h3> 

   1. 几种MQ的选型: 

      1. https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/high-concurrency/why-mq.md

   2. 消息队列的高可用

      1. 非分布式的MQ保证高可用(RabbitMQ)

         1. 镜像集群模式
            1. 在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会**存在于多个实例上**，就是说，每个 RabbitMQ 节点都有这个 queue 的一个**完整镜像**，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上。
            2. 好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！第二，这么玩儿，不是分布式的，就**没有扩展性可言**了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并**没有办法线性扩展**你的 queue。

      2. 分布式MQ的高可用(Kafka)

         1. kafka是分布式的，数据并不是都集中在一台机器上，可以分多个机器保存。 kafka的topic的partition多台机器上都有，并且同样的partition机器中，会有一台被选举为leader，其他的为follower。数据的交互式通过leader这台机器交互的，如果leader这台机器宕机了，follow机器会被选举为leader，然后这个继续运行。
         2. **写数据**的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 
            自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。当然，这只是其中一种模式，还可以适当调整这个行为）
         3. **消费**的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

      3. 如何保证消息不被重复消费(保证消费时的幂等性)

         1. kafka消费端可能出现重复消费的问题：通过offset来记录数据的时序性，消费者会定期的返回数据处理到的具体位置offset到kafka，可能消费者处理了数据，但是还没来得及告诉给kafka，导致kafka以为数据没有消费。那么当消费者重启的时候，kafka就会把已经处理了的数据再次发给消费者，导致重复消费.
         2. 在消费者端保障幂等性:
            1. 可以将要消费的数据，在储存到数据库的时候，先保存在内存（比如Set）中，并且和set比较，如果内存中已经有了这个数据，说明已经处理过，那么不再处理。
            2. 通过数据库的主键唯一约束避免重复消费。

      4. 如何保障MQ数据不丢失

         1. RabbitMQ

            1. 生产者发送：可以开启 `confirm` 模式，在生产者那里设置开启 `confirm` 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 `ack` 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 `nack` 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

            2. MQ数据丢失 :

               **开启 RabbitMQ 的持久化**. RabbitMQ 自己挂了，**恢复之后会自动读取之前存储的数据恢复**

               1. 设置持久化有两个步骤：
                  - 创建 queue 的时候将其设置为持久化
                     这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。
                  - 第二个是发送消息的时候将消息的 `deliveryMode` 设置为 2
                     就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。
               2. 持久化可以跟生产者那边的 `confirm` 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 `ack` 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 `ack`，你也是可以自己重发的。

            3. 消费端消费:

               1. 你必须关闭 RabbitMQ 的自动 `ack`，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 `ack` 一把。如果你还没处理完，不就没有 `ack` 了 , 那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。

         2. Kafka

            1. 消费端
               1. 跟 RabbitMQ 差不多，大家都知道 Kafka 会自动提交 offset，那么只要**关闭自动提交** offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是**可能会有重复消费**，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。
            2. Kafka丢数据
               1. 一般是要求起码设置如下 4 个参数：
                  1. 给 topic 设置 `replication.factor` 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本 .
                  2. 在 Kafka 服务端设置 `min.insync.replicas` 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧 , , 才会去接收生产者的消息.
                  3. 在 producer 端设置 `acks=all`：这个是要求每条数据，必须是**写入所有 replica 之后，才能认为是写成功了**。
                  4. 在 producer 端设置 `retries=MAX`（很大很大很大的一个值，无限次重试的意思）：这个是**要求一旦写入失败，就无限重试**，卡在这里了。
               2. 我们生产环境就是按照上述要求配置的，这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。
            3. 生产者端
               1. 如果按照上述的思路设置了 `acks=all`，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。

      5. 保证MQ消息的顺序性

         1. RabbitMQ: 拆分多个 queue，每个 queue 一个 consumer，一个 queue 但是对应一个
            consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。
         2. Kafka: 生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。在消费者里可能会搞**多个线程来并发处理消息**造成数据混乱 , 可以取消息时再对key做一下hash分发到不同的内存队列里,每个队列用一个对应的线程进行消费.

      6. 如何处理消息积压

         1. 大量消息在 mq 里积压了几个小时了还没解决:
            1. 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。
            2. 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量(因为kafka的一个分区只能由一个消费者来消费)。
            3. 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，**消费之后不做耗时的处理**，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
            4. 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。(db能否扛住?)
            5. 等快速消费完积压数据之后，**得恢复原先部署的架构**，**重新**用原先的 consumer 机器来消费消息。
         2. mq 中的消息过期失效了
            1. 假设你用了RabbitMQ,并且设置了过期的时间TTL, 会导致大量的数据直接丢失. 这种只能在低峰期写临时程序将丢失的数据重新投递到MQ里补数据.
         3. mq都快写满了
            1. 临时写程序，接入数据来消费，**消费一个丢弃一个，都不要了**，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。

      7. 设计一个消息队列的思路

         1. 可伸缩: 设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，给 topic 增加 partition，然后做数据迁移，增加机器，
         2. 持久化: 落磁盘 , 顺序写.
         3. 可用性: 参考第二节. 分布式MQ的高可用(Kafka).
         4. 数据不丢失 : 参考第四节. 如何保障MQ数据不丢失.



<h3 id="其他">其他</h3> 

1. Sofa的的优势:

   1. SOFA 的优势就在于将模块化更进了一步，在一个 SOFA 应用中，应用中的每一个模块都含有各自的 Spring 上下文，模块之间的调用通过本地服务的方式来完成。这样，当应用需要拆分的时候，可以将整个模块连同它的 Spring 配置文件直接拆出去，所需要修改的只是将本地服务，改成远程服务（这在 SOFA 里面只是在服务上加上一行配置而已），非常方便。
   2. 健康检查能力
   3. 日志隔离
   4. Jar包隔离，利用SOFAArk实现，只要引入 SOFAArk 相关的依赖，就可以将 SOFA 中间件相关的类和应用相关的类的 ClassLoader 进行隔离，防止出现类冲突。当然，用户也可以基于 SOFAArk，将其他的中间件、第三方的依赖和应用的类进行隔离。
   5. SOFARPC有bolt、Rest、Dubbo 等协议；使用netty网络。注册中心上支持多注册中心，zookeeper等；支持点对点提供服务；支持泛化服务；增加了更多扩展功能；

2. Beta发布和蓝绿发布

   beta 发布是分组发布的一种特例形式，旨在控制项目上线的风险。对于某些风险高的项目，往往先发布少量服务器，观察较长一段时间，确认业务 OK 后，再发布剩下的服务器。与普通分组发布相比，beta 发布可以提前发现部分问题，如有问题只需要回滚少量服务器，对现有业务运转的影响小，但 beta 发布也有它的局限性：
   beta 发布靠发布的服务器数量来控制新产品代码流量，无法自由调控流量。
   beta 发布只有非常少量的流量，暴露问题的能力有限。
   如果涉及多个系统间交互，A 和 B 同时 beta 少量服务器，A 需要调用 B，无法控制 A 的新代码服务器一定会调到 B 的新代码服务器，存在新老代码交叉调用；一是增加了观察人员对业务验证的困难，二是需要考虑各种兼容性问题。
   所以，我们一直在积极探索如何让越趋庞大和复杂的系统代码变更能够又快又好的敏捷研发运维之路。在单元化架构能力达成之后，为这种探索带来了新的巨大的可能。单元化架构带来的这种新的发布能力，便是蓝绿发布模式。

   蓝绿发布 (Blue Green Deployment) 是一种平滑过渡的发布模式。蓝绿发布的操作模式上，首先依赖于能够将全站应用划分为对等的 A、B 两个单元，A 先发布新产品代码并引入少许用户流量，B 继续运行老产品代码；如果新代码 A 经线上运行观察没有迹象表明有问题，或者用户行为对 A 中的变化没有特别的反馈，那么逐步引入更多用户流量，直至所有用户都访问新产品。因此，蓝绿发布可以保证整体系统的稳定，在产品开放前期就可以发现、调整问题，以保证其影响面可控，这种能力为进行频繁的线上变更编织了一道强大的安全网，使得代码变更更加安全可靠。https://yuque.antfin-inc.com/emily.zy/yfcon6/fq5xbq
   蓝绿发布原理
   服务垂直划分：（RZ01、RZ02、RZ03、RZ04、RZ05、GZ00）
   再水平划分：每组UID对应的逻辑单元都切分为对等的A、B，比如RZ01A、RZ01B。RZ01A与RZ01B互为备份且共享同一套DB。
   当开启蓝绿模式时，zoneClient组件会调整路由计算策略，隔离A与B之间的调用，GZ00A只会访问RZXXA，而不会访问RZXXB。此时为封闭的部署单元。日常概率到a或b。
   A发布完成，观察一段时间，再发布B。

3. // Multimap
   Multimap<String,StudentScore> scoreMultimap = ArrayListMultimap.create(); 
   for(int i=10;i<20;i++){
               StudentScore studentScore=new StudentScore();
               studentScore.CourseId=1001+i;
               studentScore.score=100-i;
               scoreMultimap.put("peida",studentScore);
           }
   Collection<StudentScore> studentScore = scoreMultimap.get("peida");
   调用Multimap.get(key)会返回这个键对应的值的集合的视图（view），没有对应集合就返回空集合。

   Multimap也支持一系列强大的视图功能：
   　　1.asMap把自身Multimap<K, V>映射成Map<K, Collection<V>>视图。这个Map视图支持remove和修改操作，但是不支持put和putAll。严格地来讲，当你希望传入参数是不存在的key，而且你希望返回的是null而不是一个空的可修改的集合的时候就可以调用asMap().get(key)。（你可以强制转型asMap().get(key)的结果类型－对SetMultimap的结果转成Set，对ListMultimap的结果转成List型－但是直接把ListMultimap转成Map<K, List<V>>是不行的。）
   　　2.entries视图是把Multimap里所有的键值对以Collection<Map.Entry<K, V>>的形式展现。
   　　3.keySet视图是把Multimap的键集合作为视图
   　　4.keys视图返回的是个Multiset，这个Multiset是以不重复的键对应的个数作为视图。这个Multiset可以通过支持移除操作而不是添加操作来修改Multimap。
   　　5.values()视图能把Multimap里的所有值“平展”成一个Collection<V>。这个操作和Iterables.concat(multimap.asMap().values())很相似，只是它返回的是一个完整的Collection。

4. 手写实现,可重入锁和不可重入锁
   https://www.cnblogs.com/dj3839/p/6580765.html

5. servicemesh:
   由于：
   	•	RPC-client，它嵌在调用方进程里
   	•	RPC-server，是服务进程的基础
   往往会面临以下一些问题：
   	•	业务技术团队，仍需要花时间去学习、使用基础框架与各类工具，而不是全心全意将精力花在业务和产品上
   	•	client要维护m个版本， server要维护n个版本，兼容性要测试m*n个版本
   	•	如果要支持不同语言，往往要开发C-client，Python-client，go-client，Java-client多语言版本
   	•	每次“黑科技”的升级，都需要推动上下游进行升级，这个周期往往是以季度、半年、又甚至更久，整体效率极低
   思路是，将服务拆分成两个进程，解耦。
   	•	一个进程实现业务逻辑（不管是调用方，还是服务提供方），biz，即上图白色方块
   	•	一个进程实现底层技术体系，proxy，即上图蓝色方块
   负载均衡、监控告警、服务发现与治理、调用链…等诸多基础设施，都放到这一层实现。
   	•	biz和proxy共同诞生，共同消亡，互为本地部署，即上图虚线方框
   	•	biz和proxy之间，为本地通讯，即上图黑色箭头
   	•	所有biz之间的通讯，都通过proxy之间完成，proxy之间才存在远端连接，即上图红色箭头
   这样就实现了“业务的归业务，技术的归技术”，实现了充分解耦. 整个服务集群变成了网格状，这就是Service Mesh服务网格的由来。

6. Istio是ServiceMesh的产品化落地：
   	•	它帮助微服务之间建立连接，帮助研发团队更好的管理与监控微服务，并使得系统架构更加安全
   	•	它帮助微服务分层解耦，解耦后的proxy层能够更加专注于提供基础架构能力，例如：
   （1）服务发现(discovery)
   （2）负载均衡(load balancing)
   （3）故障恢复(failure recovery)
   （4）服务度量(metrics)
   （5）服务监控(monitoring)
   （6）A/B测试(A/B testing)
   （7）灰度发布(canary rollouts)
   （8）限流限速(rate limiting)
   （9）访问控制(access control)
   （10）身份认证(end-to-end authentication)
   Istio架构: 采用二层架构，五大模块，进行微服务ServiceMesh解耦：
   	•	数据平面(data plane)，主要负责高效转发
   （1）envoy模块：即proxy；
   	•	控制平面(control plane)，主要负责控制与应用
   （2）mixer模块：支持跨平台，标准化API的adapter；
   （3）pilot模块：控制与配置envoy的大部分策略；
   （4）citadel模块：安全相关；
   （5）galley模块：与底层平台（例如：K8S）配置解耦；
   https://juejin.im/post/6844903865620365326

7. Msgbroker: 推模式
   1.高可靠 , 消息不丢失
   2.可扩展 , Msgbroker基于注册中心confreg注册 , msg直接加机器就能感应到 . (生产者消费者也会注册在MsgBroker上)
   3.事务消息
   4.抗积压: 分库分表存储 , 自适应投递限流
   https://developer.alipay.com/article/6828

   绝大多数业务系统都在使用msgbroker作为异步化消息中间件(对应的金融云组件为DMS)，msgbroker也非常高效且稳定地履行着自己的职责。不过由于自身的实现特点，仍然有部分支付宝特殊业务场景的需求无法满足，例如：

   0. 消费者能力弱：目前msgbroker采用推模式把服务器收到的消息主动通过网络投递给消费者，消费者需要在10秒内反馈消费结果，服务器收到反馈之后决定是去重投还是投递成功删除数据库中的消息。如果消息量很大，尤其像双11这样尖刺明显的情况下，消费能力弱的系统将会出现大量线程池繁忙的错误，而消息中心会出现大量投递超时的现象，导致msgbroker积压很多消息从而不停地重试，最终影响整个生态的稳定性。
      0. 消费者消费耗时长：一些业务系统收到消息后，需要执行十分耗时的消息处理，由于msgbroker有10秒超时的限制，导致消费者需要为此做额外的工作（如消息本地入库、异步处理）。
      1. 不支持回溯消费：消费者消费消息成功后，msgbroker会把消息从数据库中删除；假如有业务系统逻辑存在bug，需要把消费成功的消息重新再消费一次，就做不到了。
      2. 削峰填谷支持：类似日志、安全等业务，每天要产生几十亿的消息，消费者允许消息少量丢失，并且需要中间件提供削峰填谷的能力，让消费者以固定的tps平稳消费，不会由于消息量突然暴增导致消费者崩溃的现象发生。
         基于上面的一些特殊需求，我们需要一个拉模式消息中间件，antq就应运而生了。

   AntQ: 拉模式
   1.支持消息积压
   2.支持回溯消息
   3.不支持事务
   4.单机故障会丢数据
   适用场景:
   	•	消息量大，成本低，牺牲一定高可靠性的场景
   	•	实时数据平台
   	•	订阅端处理时间不可控（消息中心要求订阅端10s内处理完）
   	•	商户数据中心
   	•	需要蓄洪
   	•	安全风控，大促时蓄洪，两小时后泄洪。
   	•	支持大数据实时计算，按照设定时间来消费消息（该场景只适用于自建集群）
   	•	kepler/galaxy/jstorm

8. DRM
   DRM(Distributed Resource Management)是一个分布式环境下 实时 动态的配置管理框架。为了帮助理解这几个关键词，可以从简到繁，跟其他一些配置管理方案进行对比。
   	•	说到配置，容易想到的是配置文件。配置文件通常在编译期就打到应用程序包内，或者部署时传入。里面的配置项值，在运行期一般不可改变，称为静态配置。
   	•	要实现动态性，可以选择方便运行期修改的存储方案，例如数据库。出于性能考虑，不可能在处理每笔业务请求的时候都读一次数据库查询配置，所以需要跟内存缓存结合起来使用。单机架构下，通过应用程序去修改数据库里的配置值，同时修改内存中的缓存值，可以保证内存缓存和数据库一致。这个方案只适用单机，如果是分布式环境，就无法保证所有服务器的缓存一致。
   	•	分布式环境下需要对上述方案做改进，每台应用服务器定时从数据库加载配置值到内存中。定时轮询的间隔需要权衡：设置长了，实时性差，缓存不一致时间长；设置短了，对数据库压力大。
   	•	DRM则专门针对这个业务场景，兼顾实时性和一致性，采用推拉结合的实现方案来动态管理配置。并封装了基于简单Java Bean和注解的客户端编程API，方便应用接入。
   DRM3的具体配置值并不通过配置中心推送，而是增加了一个数据存储系统zdrmdata，通过它存入数据库中。只通过配置中心推送一个特定格式的简短指令，应用接收到该指令后，知道配置项发生了变更，向zdrmdata发起http请求，读取真正的配置值。过程如下图①~⑤。

   其他辅助业务逻辑
   	•	定时心跳轮询：客户端每30秒向zdrmdata发一次请求，传入当前持有的所有数据项的版本号。如果有配置项版本号小于服务端的版本号，则再主动拉一次这个配置项。这个机制可以作为异常情况下的兜底措施。
   	•	查询订阅某个配置项的客户端列表：利用配置中心或 zdrmdata 维护的订阅关系，可以明确看到当前存活的所有的订阅者。结合下一条，可以掌握客户端的情况。
   	•	查询客户端当前内存值：客户监听特定端口，封装查询API。控制台向所有客户端发起查询请求，展示它们的当前状态。
   	•	临时修改单个客户端的内存值：客户端同时封装了设值API，控制台可以直接向其发起请求，临时修改内存值，通常用于beta验证。下次推送集群或者客户端重启之后，集群就会恢复成一致的值。

9. 项目:
   技术风险中台:
   提供了变更三板斧(可灰度,可监控,可回滚)流程化的能力 , 实现了对全站变更三板斧规范和风险管控从架构上的约束. 赋能全站Saas , Paas , Iaas共计1000+场景的变更三板斧能力.
   变更三板斧:
   变更可灰度：本质上就是根据不同的策略(根据目标用户、目标业务特性...)通过分阶段逐步扩大流量／影响面的方式进行验证；
   变更可监控：在变更分阶段执行的基础上通过统一的变更防御能力对风险做好评估；
   变更可回滚：在变更分阶段执行过程中发现问题时，具备数据版本的切换能力；
   流程图: (边画边讲变更单流转)

   技术亮点: 数据强一致性设计.自研状态机对变更单状态的强管控 , 用户定制化审批流程 , 执行流程. 变更无人值守能力
   架构布局:  一横一纵 (横:三板斧pipeline 纵:变更防御,变更风险管控切面)

   变更计划(建设中): 提前三天收集变更的需求 , 规范用户变更的计划性.
   灰度核心: 获取符合三板斧规范的分批.(比如,按环境分预发/灰度/生产,再按逻辑机房zone分,每个zone选10%的机器组成第一批,然后增加百分比至50%,最后推zone的批次)
   九州2.0(变更pipeline): 
   变更接入(统一和标准化的接入方案 , 蓝军风险评估能力,变更影响面),
   审批(业务定制化审批流程,转交,加签),
   执行(自研bom执行流,可插拔的原子执行能力; 批次执行,前后置校验,灰度引流 , 快速回滚).
   API总线(提供变更的标准数据获取、通用执行能力SPI以便于简化编程接口)
   错误码机制(建设中): 无人值守等级机制.
   消息中心:钉钉、钉群、邮件等功能，为运维变更业务提供了异步提醒能力
   智能答疑: 钉钉群答疑机器人: 日常的线上支持答疑及新用户的知识教导 , 智能答疑,智能答疑在本质上是需要建立起蚂蚁运维知识体系并通过AI的手段将这些知识透出给对应的用户。
   宕机迁移方案.

   防御能力
   	•	变更三板斧改造：在saas层，对参数中心、mng类应用、配置代码化等变更场景落地变更三板斧，同时接入变更核心，完成布防的先决条件。
   	•	变更准入防御：在变更前，通过对变更单的审核、灰度、互斥、窗口、黑名单等规则，判断变更是否可以执行，将一些不合规的变更阻断在执行之前，防范风险。
   	•	变更执行防御：在批次执行前，通过判定是否报备，是否符合灰度、是在变更窗口期等条件判断，以确保执行符合规范，避免风险。
   	•	变更监控防御：在批次执行后，通过对本批次变更涉及到的系统、服务、业务等指标进行监控，判定变更结果是否健康以阻断风险

   变更流程化 , 计划阶段 , 执行阶段(变更熔断)

   变更数据版本化的代理能力 . https://developer.alipay.com/article/69000386

10.