

任务:

1.石杉的架构课三季看完

2.力扣算法题 , 每天15道 , 先看慕课的算法课 , 小灰的算法书

3.简历中的项目 , 三板斧改造方案 , 中间件比如DRM

5.网上找面试题

6.DDD







<h3 id="分布式篇">分布式篇</h3> 

1. 如何设计一个高并发系统 (每秒上千个请求以上)

   1. **系统拆分**:  将一个大系统拆分为多个子系统 , 用分布式框架dubbo或者spring cloud来搞 , 每个系统对应一个数据库.

   2. **缓存 :**  大部分的高并发场景，都是**读多写少**，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存。毕竟 redis 轻轻松松单机几万的并发。

   3. **MQ:** 针对高并发的写场景 . 大量的写请求灌入 MQ 里进行削峰，排队慢慢玩儿，**后边系统消费后慢慢写**，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的 .

   4. **分库分表:** 请求量如果再高一些 ,可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表**拆分为多个表**，每个表的数据量保持少一点，提高 sql 跑的性能。

   5. **数据库的读写分离 :** 大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，**主库写**入，**从库读**取，搞一个读写分离。**读流量太多**的时候，还可以**加更多的从库**。

   6. **Elasticsearch**: 简称 es。es是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用
      es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。

   7. 之前搞过微服务架构，个人经历说下，阿里云ECS弹性伸缩，高峰特别是秒杀时，NGINX限流一个IP每秒1个，前端CDN静态化，还有秒杀前不要暴露真实秒杀地址，单机+cache，配置ECS感应流量，自动扩展到20-30台，单台扛几百用户单纯响应是没啥问题的（这里说的是单纯响应，就是说先确保不出现500或502这类错误），后端代码逻辑Redis防刷，需要同步调用的接口尽可能少（比如一般只走支付网关，拉起支付接口），redis+lua预热加减库存，如果需要限流redis队列排序限流等（比如队列里用户数控制最多50000），同步接口返回速度尽可能高（这里面需要JVM、各种SQL优化以及读写分离、分库分表），能走异步的尽量走异步，比如短信通知，购买成功加积分级别，抵用券等。

      忘了补充一点，事务尽可能的小，就是说都是小事务提交（不要把什么写日志，调接口也包在开启事务逻辑里面），还有乐观锁，悲观锁，间隙锁（特别是间隙锁，MySQL在RR隔离级别下产生的间隙锁要特别小心），快照读，当前读，mvcc这些一定要清楚认知和使用恰当，不然事务隔离级别下的锁竞争，平峰时快速普通SQL不光会跑到十几甚至几十秒，而且会造成MySQL线程数跑满，或者直接挂了

      ![设计一个高并发系统](C:\Users\guozh\Desktop\java\石杉\设计一个高并发系统.jpg)

      



1. 服务框架 , Dubbo , spring cloud , gRPC , Thrift . 

服务注册和发现 , 通信和序列化 , 负载均衡 , 扩展机制 , 请求重试 , 请求超时

2. spring cloud核心组件

   1. 注册中心Eureak
   2. 服务调用Feign
   3. 负载均衡Ribbon
   4. 网关Zuul / Gateway
      1. 灰度发布: 流量分发给灰度部署的机器
      2. 统一限流:
      3. 统一熔断:
      4. 统一鉴权:

3. Dubbo调用底层实现

   1. 消费者

      1. 动态代理:Proxy
      2. 负载均衡:Cluster , 故障转移
      3. 通信协议:Protocol , http/rmi/dubbo等协议
      4. 信息交换: Exchange , Request , Response
      5. 网络通信: Transport , 基于netty/mina实现
      6. 序列化: 封装好的请求序列化成二进制数组 , 通过netty/mina发送出去

   2. 生产者

      1. 反序列化
      2. 网络通信: Transport
      3. 信息交换: Exchange
      4. 通信协议: Protocol 
      5. 动态代理: Proxy

      ![Dubbo底层调用原理](C:\Users\guozh\Desktop\java\石杉\Dubbo底层调用原理.jpg)

   3. 网络通信netty

      1. 基于NIO实现的

      2. 服务提供者

         1. Acceptor线程通过Selector组件轮询ServerSocketChannel的网络事件  , 同时ServerSockerChannle会持续监听端口号 , 看有没有消费者netty来建立网络连接.
         2. 消费者通过netty框架与服务提供者的端口号和ServerSocketChannel建立连接 , 每个消费者建立一个SocketChannel对象 . netty会将建立好的连接SocketChannle分配给Processor线程 , 每一个Processor线程通过多路服用轮询组件Selector , 来不断轮询看这些SocketChannel对应的服务消费者有没有发请求过来. 轮询到有请求过来就会解析请求走后面的流程.
         3. 每个Processor可以支撑多个消费者的请求.
         4. 服务响应也是通过Processor线程 , 通过对应消费者的SockerChannel发响应发回到消费者的netty .

      3. 服务消费者

         1. 同提供者类似 ,也是对一个提供者建立一个SocketChannel连接, 一个Processor线程通过Selector轮询多个SocketChannel的网络事件 , 把响应值返回给消费者.

         ![网络通信netty框架原理](C:\Users\guozh\Desktop\java\石杉\网络通信netty框架原理.jpg)

4. 如何设计一个RPC框架

   1. 动态代理  
      1. 消费者和提供者都要实现某个框架的动态代理的, PRC框架的一切细节都在这个动态代理里面实现.调用动态代理的方法.
   2. 服务注册中心
      1. 服务注册,服务发现 . 或者 基于zookeeper .
   3. Cluster层 
      1. 从本地服务注册表根据负载均衡找到要调用的机器列表 .
      2. 负载均衡策略 . 
   4. 调用信息交给协议层 
      1. 协议
      2. 网络通信框架
      3. 序列化和反序列化

5. Springcloud底层原理

   1. 注册中心Eureka

      1. 服务注册与发现
         1. 服务注册表 , 二级缓存(ReadWrite缓存+ReadOnly缓存) , 后台有线程会定时将ReadWrite缓存同步给ReadOnly缓存 , 服务发现定时(每隔30s)拉取ReadOnly的缓存 . 
      2. 心跳与故障
         1. 服务注册机器会每30s发送一次心跳 , 服务注册表会记录心跳 , 后台有个心跳线程会定时检查,当发现一定时间内某个机器没有心跳 , 任务机器挂了 , 将该机器剔除服务注册表 , 同事会发指令ReadWrite缓存 , ReadWrite缓存会清空自己 , 然后定时同步线程也会清空ReadOnly缓存 . 当下次的服务发现时会去服务注册表拉取最新的数据更新到两个缓存中.

      ![Eureka注册中心原理](C:\Users\guozh\Desktop\java\石杉\Eureka注册中心原理.jpg)

   2. Ribbon

   3. Feign 

      1. 对一个接口打了一个注解 , 他会针对这个注解标注的接口生成动态代理 , 调用时底层生成http协议格式的请求 , 通过Ribbon 从本地的服务注册列表中根据负载均衡算法获选出一个机器 , 接着对机器发送http请求即可.

   4. Zuul

      1. 配置一下不同请求路径和服务的对应关系 , 把请求直接匹配到服务 , 基于Ribbon , 发请求到指定的机器上去.

6. Dubbo和Springcloud的优缺点

​	1.总结：dubbo优点：深度优化后，基于TCP的RPC调用更加轻量级，速度更快。 dubbo缺点：只是一		套RPC服务框架没有配套设施，需要自己再找其他的组件去做配合使用。 SpringCloud优点：开箱即用，和spring完美搭配，提供一整套分布式系统解决方案。 SpringCloud缺点：基于http请求，较慢。有些组件存在问题（springCloud config） 两者差异：最大的差异在对请求的处理上，一个基于TCP一个基于HTTP。一个是RPC服务框架，一个是分布式系统解决方案。

7. 服务注册中心比较

   1. Eureka集群架构

      1. peer2peer，每个注册中心服务的节点地位相等，会将每次心跳和更新请求同步到每一个节点上，因此并发高了之后，注册中心的内部流量会很大。注册列表的更新方式是通过客户端拉取

   2. Zookeeper集群

      1. master-follower，通过只对主节点进行写，然后由主节点同步到从节点后，主动向节点推送到各个服务节点。时效性较高 .  服务消费者可以去加监听服务列表, ZK会主动通知给消费者服务列表的变动.当有机器新增或者下线, ZK的leader节点先感知到然后同步给Follower节点,Follower节点主动通知服务消费者.

         ![ZooKeeper服务注册与发现原理](C:\Users\guozh\Desktop\java\石杉\ZooKeeper服务注册与发现原理.jpg)

   3. 一致性保障 CP or AP

      1. C:Consisitency(一致性)

         A:Availability(可用性) 

         P:Partition Tolerance(分区容错性) .

         CAP相关文章: https://juejin.im/post/6844903936718012430

         在分布式的环境下，网络无法做到100%可靠，有可能出现故障，因此分区是一个必须的选项，如果选择了CA而放弃了P，若发生分区现象，为了保证C，系统需要禁止写入，此时就与A发生冲突，如果是为了保证A，则会出现正常的分区可以写入数据，有故障的分区不能写入数据，则与C就冲突了。因此分布式系统理论上不可能选择CA架构，而必须选择CP或AP架构。

      2. zk: 基于cp，保证数据的顺序一致性，因此需要牺牲掉一些可用性，例如主节点宕机后，就不再可用（不提供读写服务），需要从从节点中再次选取出主节点后才会继续提供服务。

      3. Eureka：基于ap，保证节点的可用性，在某一些服务节点挂掉之后，其余节点可以继续提供服务，但是因为数据未能同步，所以其它节点提供的数据可能是不一致的, 会确保最终一致性。 这两者之间的差异，都是因为模式造成的，一个是中心化，一个是去中心化。

   4. 服务注册发现的时效性

      1. zk时效性好 , 秒级别可以感知

      2. Eureka , 默认配置比较糟糕 , 服务发现感知到要几十秒 , 甚至分钟级别.

         优化:  

         1. ReadOnly缓存和ReadWrite缓存的同步周期缩短(30s->3s) , eureka.server.responseCacheUpdateIntervalMs = 3000

         2. 服务发现拉取的周期缩短(30s->3s),

            eureka.client.registryFetchIntervalSeconds = 3

         3. 服务心跳上报周期缩短(30s->3s)

            eureka.client.leaseRenewalIntervalInseconds = 3

         4. 心跳检查周期缩短(60s->6s)

            eureka.server.evictionIntervalTimeMs=6000

         5. 心跳超时时间(超过这个时间判定为死亡.90s->9s)

            eureka.instance.leaseExpirationDurationInSeconds= 90

         6. 关闭eureka的自我保护机制(突然网络故障,一定比例机器没有发生心跳,会触发保护机制,保护服务注册表不会被修改 , 源码的bug较多)

            eureka.server.enableSelfPreservation: false

   5. 容量

      1. zk: 不适合大规模的服务实例 , 因为服务上下线的时候会瞬间推送数据通知到所有的其他服务实例 , 一旦达到几千服务实例时 , 会导致网络带宽被大量地占用.
      2. Eureka: 也很难支撑大规模的服务实例 , 因为每个节点收到数据通知都要同步给其他节点 , 相当于每次更新会落到集群的每个节点上 , 如果服务过多 , Eureka整个集群内部流量巨大.
      3. 实际生成部署,会采用比较高的配置的机器来做,8C16G, 16C32G的高配机器来做,基本可以做到每台机器每秒钟支撑几千请求.

   6. 部署上万服务实例 , 服务注册中心如何优化(自研注册中心)

      1. 服务注册表分片存储. 每台机器存储部分的服务注册表,机器不互相同步数据 , 将集群请求分散到多个节点.应对. (高并发)
      2. 每个机器都有自己的Slave机器做备份机器来保证(高可用).
      3. 通过主从节点都写成功了再返回ack(一致性).
      4. 服务消费者 通过代理层去指定的节点拉取部分注册信息，不用每次都拉取集群的全集。

      ![自研注册中心架构](C:\Users\guozh\Desktop\java\石杉\自研注册中心架构.jpg)

   7. 其他注册中心比较

      |       Feature        | Consul                                  | Zookeeper                      | Etcd                  | Eureka                           | SofaRegistry           |
      | :------------------: | :-------------------------------------- | ------------------------------ | --------------------- | -------------------------------- | ---------------------- |
      |     服务健康检查     | 定期healthcheck(http/tcp/script/docker) | 定期心跳保持会话(session) +TTL | 定期refresh(http)+TTL | 定期心跳+TTL;支持自定义healcheck | 定期连接心跳＋锻炼敏感 |
      |        一致性        | raft                                    | ZAB                            | raft                  | 最终一致性BASE                   | 最终一致性BASE         |
      |         cap          | cp                                      |                                |                       |                                  |                        |
      | 使用接口(多语言能力) | 支持http和dns                           | 客户端                         | http/grpc             | 客户端/http                      | 客户端(java)           |
      |      watch支持       | 全量/支持long polling                   | 支持                           | 支持long polling      | 不支持(client定期fetch)          | 支持(服务端推送)       |
      |         安全         | acl/https                               | acl                            | https支持(弱)         | -                                | acl                    |
      |   spring cloud集成   | 支持                                    | 支持                           | 支持                  | 支持                             | 支持                   |

   

8.网关

1. 网关的作用:

   1. 动态路由 , 负载均衡: 新开发某个服务 , 动态把请求路径和服务的映射关系加载到网关;服务增减机器,网关自动热感知.
   2. 灰度发布 . 可以调整流量比例到新代码的机器上.比如默认是50%的流量到新机器,如果新代码有问题,50%的服务就不可用了,可以通过网关来调整流量的比例 , 逐步扩大灰度比例 . 降低新代码上线的影响.
   3. 鉴权认证
   4. 接口性能监控 . 每个api接口的RT , QPS , 成功率等.
   5. 系统日志
   6. 限流熔断
   7. 数据缓存 . 某些接口的响应做缓存

2. 网关的技术选型

   1. Kong : 依托于Nginx实现，OpenResty，lua实现的模块，现成的一些插件，可以直接使用 . Nginx抗高并发的能力很强，少数几台机器部署一下，就可以抗很高的并发，精通Nginx源码，很难，c语言，很难从Nginx内核层面去做一些二次开发和源码定制
   2. Zuul : Spring cloud , 基于java开发,核心网关功能比较简单 , 但是比如灰度发布 , 限流 , 动态路由之类的都需要二次开发. 高并发能力不强.
   3. 自研网关: Java技术栈为主的大厂，很多其实用Java、Servlet、Netty来开发高并发、高性能的网关系统，自己可以把控一切

3. 动态路由的实现

   1. 动态路由实现: 可以使用第三方组件保存路由关系，然后在网关里面通过定时任务去定时刷新组件中保存的路由信息。 因此就可以基于mqsql去做路由关系的保存，然后通过后台管理系统去操作db，再由网关去定时查询db更新路由表，实现动态路由效果。 
   2. 代码实现: C:\Users\guozh\Desktop\java\石杉\代码2\zuul-gateway\src\main\java\com\zhss\demo\zuul\gateway 中

4. 网关抗住每秒10w的高并发访问 ,如何优化

   1. zuul集群部署  , 前面有一层Ngnix反向代理 , 前面再有一层LVS负载均衡层.

      LVS是Linux virtual 
      server的缩写，是一个高可用性、高性能的虚拟服务器集群系统。主要针对高可伸缩、高可用网络服务的需求，给出了基于IP层和基于内容请求分发的负载平衡调度解决方法，并在Linux内核中实现了这些方法，将一组服务器构成一个实现可伸缩的、高可用网络服务的虚拟服务器。

   2. zuul网关部署机器,部署8C16G , 每秒几千请求不是问题 . 10w请求要几十台网关机器

   3. 生产级的网关应该具备上面的几个特点和功能.需要二次开发. 动态路由/灰度发布/鉴权认证/限流熔断

5. 如何基于网关实现灰度发布

   1. 开发流程： 首先自己建一张表，存入具体uri以及是否灰度发布的一些信息，然后搞一张映射表。 启动个线程每个多少时间就去刷新数据写到concurrenthashmap里面。 接着搞一个filter继承ZuulFilter，重写里面几个函数，其中shouldFilter根据返回值去判断执不执行run。 因此再should里面遍历map去看这次请求是否有开启灰度发布，如果有就执行run里面的逻辑，就自定义一些分发逻辑，这里用的时通过version去判断和分发。 2、灰度发布流程 首先通过后台系统更改灰度发布标识，后台线程更新了map后，就会去执行根据version分发的策略，将少部分流量分发到new上，然后监控和对应的后台，如果没问题，就更改为current，全线上线，最后将灰度发布表示改回来。
   2. 代码实现:  C:\Users\guozh\Desktop\java\石杉\代码 3\zuul-gateway\src\main\java\com\zhss\demo\zuul\gateway 里面 GrayRelease*的三个文件.

6. 公司的网关mbgw的架构图

   ![公司网关架构图](C:\Users\guozh\Desktop\java\石杉\公司网关架构图.jpg)



9.分布系统实践问题

1. 各服务在生产环境如何部署

   1. 中小型公司，一般服务拆分大概在十几二十个，那么相对来说比较好部署。

      注册中心，4核8G的机器，可以抗住每秒大概1000左右的请求，那么部署两台，就完全足够了。另外部署两台还可以作为高可用的冗余，相关的优化参数可以调到很小，让服务的发现，服务注册，服务异常等等信息的时效性很高。 

      网关的话，4核8G的机器，也是差不多能抗1000左右，但是一般会部署3-4机器，保证高可用的同时也可以降低每个网关系统的压力，通常在网关之前还会用ngx的反向代理+LVS负载均衡。 

      数据库，16核32G的机器部署mysql，高峰期可以抗住三四千的请求。 

      以上是对应机器配置的相对经验值，如果要求对应的qps达到几千几万的话。需要一个个模块再次进行优化

   2. 服务的高峰QPS是多少? 压测工具最大QPS是多少

      1. 可以在代码里,家加一些metrics统计机制. 对核心接口,用AtomicLong统计一下每分钟的请求量,成功次数,失败次数,在内存里做一些计数 . 
      2. 统计每个接口的耗时RT , TP99 = 100ms (99%的接口请求耗时在100ms以内), TP95 也是同理. 
      3. 百度java压测工具 , 开源可用的 . 如果1000/s发送压测请求 , 然后800/s被处理 . 200/s的请求被阻塞,压测工具可以感知到.

   3. 如果访问量增加十倍 , 考虑过扩容方案么

      1. 网关直接多部署10倍的机器 . 改一下nginx里面的方向代理.
      2. 服务扩容 , 加机器 , 服务会自动注册 感知到.
      3. 升级成几百个服务实例 , eureka机器可以考虑升级成8C16G的机器 , 可以抗每秒上千请求 , 横向扩容eureka用处不大 , 因为每台机器都是要保存全部的注册列表.
      4. 数据库 , 每秒高峰期几千请求 , 可以考虑给单个数据库提高配置 , 32C128G机器 , 可以抗几千并发.

2. 生产环境的超时和重试参数

   1. Spring cloud项目第一次启动的时候 , 人家调用经常会出现timeout , 是因为第一次请求的时候会去初始化Ribbon组件 , 初始化组件比较耗时 , 比较容易导致超时. 通过配置参数让服务启动时组件就初始化.

      ribbon.eager-load.enabled:true

      zuul.ribbon.eager-load.enable:true

   2. 配置超时和重试参数:

      ribbon.ConnecTimeout: 1000

      ribbon.ReadTimeout: 1000

      ribbon.OkToRetryOnAllOperations: true

      ribbon.MaxAutoRetries: 1  (重试目标机器1次)

      ribbon.MaxAutoRetriesNextServer:1  (目标机器重试失败换一台机器重试一次)

   3. 服务重试 , 防止服务重复下单的问题 , 接口的幂等性

      1. 如果是插入类型的请求：可以通过db的唯一键去做，如果插入失败则说明已存在，直接丢弃或者其他逻辑。或者用redis(接口+请求参数)拼成一个唯一的key，检查这个key是否存在，如果存在就丢弃或者其他逻辑.

      2. 如果是更新类型的请求 : 可以将请求过程分为几个节点，在各个阶段进行对应的幂等性保证 , 例如老师讲的前后拦截器，执行逻辑前，检查redis唯一key的值，如果是1说明已被成功执行，直接不做处理了；如果是0说明有同样的请求在执行，但是未完成，这时可以直接执行也可以等一段时间再检查再执行。当请求处理过程中，增加必要的异常处理，如果异常就回滚不修改key的值；如果执行成功，检查key值是否已被修改为1，已被修改就回滚，如果不能回滚就需要执行一些数据恢复的措施。如果要求不允许第二个请求执行逻辑，就在进入方法的时候就不允许执行了，不过这样吞吐量会降低。 我的思路跟下面有位同学的思路一样，不过通过注解去标识需要保证幂等的设计感觉很棒。

         也可用通过给数据加独占锁(select * from table for update no wait) , 来保证改数据只被一个请求在修改.

3. 画一下系统链路图 , 说一下分布式架构存在的问题

   1. 分布式事务 , 核心链路保证数据一致性

      1. 两阶段提交方案 / XA方案:

         1. 事务管理器 , 先询问每一个系统是否能执行 , 如果都可以执行 , 再进入第二阶段一次每个系统去执行. 如果其中一个不 能执行 , 就取消事务的执行. 常见于单个系统跨多个库的分布式事务(现在分布式系统不允许这么做了) , 因为严重依赖与数据库层面来搞定复杂的事务,效率低,不适合高并发场景. 基于spring + JTA就能实现.

      2. TCC方案: Try/Confirm/Cancel

         1. Try阶段: 对各个服务的资源做检测以及对资源进行锁定或者预留
         2. Confirm阶段: 在各个服务中执行实际的操作
         3. Cancel阶段: 如果任务一个服务执行报错 , 就要进行补偿 , 就是执行已经成功的业务逻辑的回滚操作.
         4. 很少有人用,比较依赖自己写代码来回滚补偿 , 业务代码比较难维护. 比较适合的场景: 一致性要求太高了,比如资金类的场景 , 可以用TCC方案 , 自己编写大量的业务逻辑 , 自己判断一个事务中的各个环节是否ok , 不ok就执行补偿/回滚代码. 最好每个系统执行时间比较短.

      3. 本地消息表方案

         1. A系统在自己本地的一个事务里面操作同时 , 插入一条数据到消息表.
         2. 消息表有个后台不断轮询 , 去执行消息(调用系统B).
         3. 系统B自己需要保证幂等性 , 如果B处理成功了 ,返回成功 , 系统A更改消息表中的状态为已完成 , 继续之后的业务逻辑. 如果B处理异常或者超时 , A的后台线程会定时轮询未完成的消息来执行 , 知道系统B成功为止.
         4. 方案缺陷: 严重依赖于数据库的消息表来管理事务的 , 如果是高并发场景有问题,数据库扛不住.

      4. 可靠消息最终一致性方案

         1. 不要用本地消息表了 , 直接基于MQ来实现事务  , 比如阿里的RoceketMq(3.2.6版本之前的都有回调的接口);

         2. 过程:

            1. A系统先发送一个prepared消息到MQ , 如果这个prepared消息发送失败那么直接取消不执行了.

            2. 如果这个消息发送成功过了 , 那么接着执行本地事务 , 执行成功之后给MQ发送confirm消息. 如果执行失败了就告诉MQ回滚消息 . 

            3. 如果发送了确认消息 ,B系统会收到确认消息 , 然后执行本地事务.

            4. MQ会自动定时轮询所有prepared消息回调你的接口,询问A系统这个消息是不是本地事务失败了 , 没有发送确认消息 , 是继续重试还是回滚 ? 这里A系统可以查一下数据库看事务是否执行失败了, 如果回滚了 , 那么这里也回滚 , 如果没有回滚 , 那要重新发一次confirm消息.. 这个就是避免可能本地事务执行成功了 , 但confirm的消息发送失败了.

            5. 如果B系统执行的事务失败了怎么办? B系统自身需要具备一套失败重试的机制 , 进行失败重试 ; 如果没有的话B系统可以通过MQ的相关机制让MQ重新发送消息 ; 也可以通过ZK , A系统发完消息之后一直监听ZK上的一个值 , B如果失败了 , 通知ZK , 然后ZK反过来通知A系统 , A系统把confirm消息再发一遍. 在这里B系统一定要保证自己的幂等性.

               ![分布式事务-可靠消息最终一致性方案](C:\Users\guozh\Desktop\java\石杉\分布式事务-可靠消息最终一致性方案.jpg)

         3. 订单服务的可靠消息最终一致性方案(上述过程细化):

            整个订单服务可以分为两个链路 , 一个是核心链路(订单业务) , 一个是非核心链路(wms发货服务),整个流程:

            1. 先向RocketMQ发送half message . (为什么不把发送ma放在核心交易链路之后? 如果放在核心链路之后 , 有可能发送消息失败,这样导致后序操作无法进行.之前发半消息的话 , MQ会通过回调反复确认核心链路的状态. )
            2. MQ返回成功 , half message在MQ里面有持久化的记录.
            3. 调用核心链路.
            4. 核心链路如果失败 , 走失败的逻辑 : 调用支付服务进行退款 , 更改订单的状态为取消 , 给MQ发送rollback消息废弃掉刚刚half message消息.
            5. 核心链路成功 , 就给MQ发送commit message让消费者继续消费.
            6. 在half message等待期间,一直没有commit/rolback的消息 , MQ会有后台线程来轮询,走回调去查询状态.
            7. 消费者收到消息,消费完成后回复MQ一个ack , 如果消费失败了 , MQ会重新投递或者换一个机器投递消息.

         ![分布式事务-订单系统可靠消息最终一致性原理](C:\Users\guozh\Desktop\java\石杉\分布式事务-订单系统可靠消息最终一致性原理.jpg)

         

      5. 一般分布式事务常用的是TCC和可靠消息一致性这两种思路。一个要求强一致，一个要求最终一致。强一致主要用于核心模块，例如交易/订单等等。最终一致一般用于边缘模块例如库存，通过mq去通知，保证最终一致性，也可以业务解耦。

      6. TCC事务框架 , seata框架(阿里的),支持dubbo和spring cloud

         1. seata 的使用demo: 直接在github页面上下载：[https://github.com/seata/seata-samples](https://github.com/seata/seata-samples%EF%BC%8C%E5%BB%BA%E8%AE%AE%E8%BF%99%E7%A7%8D%E6%96%B9%E5%BC%8F%EF%BC%8C%E6%AF%94%E8%BE%83%E5%BF%AB%E4%B8%80%E7%82%B9%EF%BC%8Cgit) , 

         2. 然后先要下载一个seata-server到本地，在这里下载：[https://github.com/seata/seata/releases](https://github.com/seata/seata/releases%EF%BC%8C%E7%84%B6%E5%90%8E%E5%90%AF%E5%8A%A8%E8%B5%B7%E6%9D%A5%EF%BC%8C%E8%BF%99%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E4%B8%AD%E5%BF%83%EF%BC%8C%E8%B4%9F%E8%B4%A3%E7%BB%B4%E6%8A%A4%E6%AF%8F%E4%B8%80%E4%B8%AA%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E7%8A%B6%E6%80%81%EF%BC%8C%E8%A7%A6%E5%8F%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E6%8F%90%E4%BA%A4%E5%92%8C%E5%9B%9E%E6%BB%9A) , 然后启动起来，这是分布式事务管理中心，负责维护每一个分布式事务的状态，触发分布式事务的提交和回滚.

         3. seata-server.bat -h 127.0.0.1 -p 8091 -m file

            直接把Spring Cloud版本的例子运行起来，观察一下依赖、配置和代码，以后自己在系统里使用直接仿照即可，eureka、account、order、storage、business，依次运行起来，修改一些配置，比如说数据库连接配置

            但是任何一个服务报错之后，seata这个分布式事务的框架会感知到，自动触发所有服务之前做的数据库操作全部进行回滚

         4. seata框架的实现原理

            1. 在seata中存在以下角色： 
               1. Transaction Coordinator（TC）:协调器，单独的一个server。维护全局和分支事务的状态，驱动全局事务的提交或回滚。 
               2. Transaction Manager(TM)：全局事务的发起者，负责开始/提交/回滚一个全局事务。（对应订单服务）. 
               3. Resource Manager(RM)：管理分支事务（注册分支事务/状态/提交/回滚），并负责与TC通讯。
            2. 整个使用seata进行分布式事务管理的生命周期:
               1. TM向TC发起全局事务 , TC返回XID作为本次全局事务标识.
               2. XID通过链路向下传播 , RM将本地的事务注册到TC中表示为XID的全局事务中的一个分支事务.
               3. 当执行成功 , 后由TM向TC请求标识为XID的全局事务的提交. 当有一个服务失败时,TM会通过返回值感知到,然后告诉TC将XID的全局事务回滚掉. 由TC来驱动所有的分支事务进行提交/回滚.

            ![seata中tcc处理流程图](C:\Users\guozh\Desktop\java\石杉\seata中tcc处理流程图.png)

         5. TCC事务方案的性能瓶颈在哪里 , 能支撑高并发交易场景么

            1. 每个TM和RM要和TC进行频繁的网络通信 , 会带来系能的消耗 , 比如一个本地事务要耗时100ms , 引入分布式事务之后会耗时200ms
            2. TC(seata-server)中对事务日志和状态的存储 , 如果要支持高并发的话 ,TC也需要进行横向扩容 , 同时TC背后的db也要进行一些分库分表之类的优化.

      7. 可靠消息一致性方案 , 基于ActiveMQ或者RabbitMQ自己开发一下可靠消息服务, 收到一个消息后尝试投递到MQ上去 , 投递失败重试投递 , 当消费者消费成功后必须回调接口来通知处理成功 , 如果一段时间后生产者没有收到成功的消息,要重试投递消息到MQ. 

         也可以用RocketMQ直接提供了分布式事务的支持.

   2. 分布式锁 

      1. 当多个服务需要竞争一个单体资源时，可以考虑加上分布式锁。如果并发量高的话，可以考虑拆分掉那个单体资源，50个拆成5个10个资源，从而缩小锁的粒度，提高吞吐量。

      2. Redis最普通的分布式锁

         1. 最普通的实现方式，就是在 redis 里使用 `setnx` 命令创建一个 key，这样就算加锁。

            ```
            SET key my_random_value NX PX 30000
            ```

            执行这个命令就 ok。

            - `NX`：表示只有 `key` 不存在的时候才会设置成功。（如果此时 redis 中存在这个 key，那么设置失败，返回 `nil`）
            - `PX 30000`：意思是 30s 后锁自动释放。别人创建的时候如果发现已经有了就不能加锁了。

            释放锁就是删除 key ，但是一般可以用 `lua` 脚本删除，判断 value 一样才删除：

            ```
            -- 删除锁的时候，找到 key 对应的 value，跟自己传过去的 value 做比较，如果是一样的才删除。
            if redis.call("get",KEYS[1]) == ARGV[1] then
                return redis.call("del",KEYS[1])
            else
                return 0
            end
            ```

            ​	为啥要用 `random_value` 随机值呢？因为如果某个客户端A获取到了锁，但是阻塞了很长时间才执行完，比如说超过了 30s，此时可能redis已经自动释放锁了，此时可能别的客户端B已经获取到了这个锁，要是客户端A这个时候直接删除 key 的话就会把B加的锁给删掉会有问题，所以得用随机值加上面的 `lua` 脚本来释放锁。

            ​	这种分布式锁的实现不行的。因为如果是普通的 redis 单实例，那就是单点故障。或者是 redis 普通主从，那 redis  主从异步复制，如果主节点挂了（key 就没有了），key 还没同步到从节点，此时从节点切换为主节点，别人就可以 set key，从而拿到锁。

      3. 基于Redisson框架实现:

         1. 支持redis单实例 , redis哨兵 , redis cluster , redis master-slave等部署架构.

         2. 代码:

            ```java
            RLock lock = redisson.getLock("myLock");
            lock.lock();
            lock.unlock();
            ```

         3. 原理流程图

            ![分布式锁-基于Redisson实现原理图](C:\Users\guozh\Desktop\java\石杉\分布式锁-基于Redisson实现原理图.jpg)

            1. redisson根据hash节点选择一台机器, 发送一段lua脚本到redis上, 用lua脚本是将一堆逻辑封装在lua脚本中 , 保证这段逻辑的原子性. 

            2. lua脚本的逻辑: 先判断key是否已经存在 , 不存在就可以继续加锁 , 然后生成一个当前客户端的hash值为该客户端的id作为value(例如123343-234234-545-321-dcgaga:1) ,然后key-vaule的实行set到redis里数据结构如下  , 设置存活时间默认30s; 加锁成功.

               mylock:

               {

               ​	"123343-234234-545-321-dcgaga:1":1

               }

            3. 当客户端2要进来加锁时 , 也执行同样的一段lua脚本 , 先发现key已经存在 , 然后判断key对应的vaule是否包含了客户端2的id , 显然是不包含的 . 然后客户端2会获取到pttl mylock返回的一个数字 ,代表了myLock锁的剩余生存时间. 此时客户端2会进入一个while循环 , 不停尝试加锁.

            4. watch dog自动延期机制: 客户端1一旦加锁成功就会自动启动一个watchdog线程 , 每隔10s检查一下 , 如果客户端1还持有锁key , 那么就延长锁的生存时间.

            5. 可重入加锁机制:  lua脚本中先判断exits mylock , key已经存在的 , 然后再判断因为mylock的key的hash数据结构中包含客户端1的id , 此时就会执行可重入加锁的逻辑 , 会用:

               incrby mylock 123343-234234-545-321-dcgaga:1 1 

               通过这个指令堆客户端1的加锁次数累加1. 数据结构如下:

               mylock:

               {

               ​	"123343-234234-545-321-dcgaga:1":2

               }

            6. 释放锁机制: 执行lock.unlock() , 每次堆mylock数据结构中的那个加锁次数减1 . 如果发现加锁次数是0 , 说明这个客户端已经不再持有锁了 , 此时用del mylock 指令 , 从redis中删除这个key. 另外的客户端2就可以尝试加锁了.

            7. 缺点: 客户端1在redis master上写入了mylock对应的key-vaule , 但是还没等master-slave完成异步的复制 , master出现的宕机 , slave变成了master , 接着客户端2尝试mylock加锁时在新的redis master上完成了加锁 , 但客户端1也以为自己成功加了锁. 此时系统在业务语义上会出现问题 , 导致脏数据的产生 . 

               所以这就是redis的master-slave架构的主从异步复制导致的, 在master宕机时,可能导致多个客户端同事完成加锁.

      4. RedLock算法

         1. 就是基于redis集群来做的锁 , 假设有一个redis cluster , 有5组redis master-slave节点,然后执行一下步骤:
            1. 获取当前时间戳 , 单位时毫秒
            2. 尝试在每个master节点上加锁 , 过期时间较短 , 一般就几十毫秒.
            3. 尝试在大多数节点(n/2 +１)上建立锁，客户端计算建立好锁的时间 , 如果建立锁的时间小于超时时间 , 就算建立成功了.
            4. 要是锁建立失败了,就一次删除锁.
            5. 只要别人建立一把锁成功 , 其余节点也是不断轮询锁.
         2. 实际用的比较少 , 算法有争议 , 比如过期时间如何设置.

      5. zookeeper的实现

         1. zookeeper有哪些应用场景

            1. 分布式协调 :

               这个其实是 zookeeper 很经典的一个用法，简单来说，就好比，你 A 系统发送个请求到 mq，然后 B 系统消息消费之后处理了。那 A 系统如何知道 B 系统的处理结果？用 zookeeper 就可以实现分布式系统之间的协调工作。A 系统发送请求之后可以在 zookeeper 上**对某个节点的值注册个监听器**，一旦 B 系统处理完了就修改 zookeeper 那个节点的值，A 系统立马就可以收到通知，完美解决。

               ![zk的分布式协调实例图](C:\Users\guozh\Desktop\java\石杉\zk的分布式协调实例图.png)

            2. 分布式锁

               1. 系统A先去zk上获取锁 , 创建了一个临时节点 , 同时判断当前你创建成功的这个节点是不是第一个节点(最小节点) , 如果是 ,获取锁成功 , 临时节点如果创建成功了就属于系统A. (使用临时节点: 系统A挂了 , 就会和zk断开会话 , zk感知到之后就会把A创建的临时节点删除掉,然后通知后面系统来获取锁)

               2. 此时系统B也尝试在zk创建一个同名的临时节点 , 判断自己这个节点是不是最小节点 , 如果不是 , 说明别人已经加锁了 , 系统B加锁失败. 那就找到排在自己前面的节点来监听.

               3. 系统A处理完成释放锁 , 删除掉临时节点就可以.

               4. 一旦临时节点被删除 , zk就会去通知监听节点A的系统B来获取锁.

                  ![分布式锁-基于zookpeer来实现](C:\Users\guozh\Desktop\java\石杉\分布式锁-基于zookpeer来实现.jpg)

               5. demo代码 : https://gitee.com/shishan100/Java-Interview-Advanced/blob/master/docs/distributed-system/distributed-lock-redis-vs-zookeeper.md

               6. 其他zk文章: https://juejin.im/post/6850418115143335943

               7. 基于curator框架:

                  1. 客户端A先在目录下(/lock/product_1_stock)创建一个临时顺序节点00001 , 同事客户端A ,获取目录下的所有节点, 发现自己的节点是所有节点中序号最小的, 加锁成功.

                  2. 客户端B通过curator框架来获取锁 , 会在目录下创建一个临时顺序节点00002, 同目录下的临时节点一定是有顺序的 , 02节点会来看自己是否为目录的第一个节点 , 不是的话加锁失败 , 堆上一个节点加一个watch监听器.

                  3. 客户端A如果想再次加锁(可重入加锁) , 将原节点中的加锁累计次数加一 .

                  4. 客户端A想释放锁 , 将节点中的加锁次数减一 , 当加锁次数为0时, 就释放锁 , 删除临时节点A , 客户端B会收到通知上一个节点被删除 , 此时回来再次尝试加锁 , 加锁成功.

                     ![分布式锁-基于zookpeer的curator框架来实现](C:\Users\guozh\Desktop\java\石杉\分布式锁-基于zookpeer的curator框架来实现.jpg)

               8. zk分布式锁的羊群效应如何解决

                  1. 羊群效应：当几十个节点争抢同一把基于zk的锁时，如果都是监听第一个节点，那么当释放锁时，zk会同时反向通知所有客户端又来重新争抢。 影响：主要是多了很多没必要的请求，从而会加重网络的负载。 
                  2. 解决：就基于curator去做就好了，通过监听上一级节点，降低了争抢次数，还实现了公平锁。 redis：redis因为是客户端自己主动隔一段时间去尝试加锁，所以羊群效应影响不大，因为请求都错开了，而不是一群一拥而上。

               9. zk分布式锁的脑裂问题如果解决

                  1. 脑裂问题:  分布式系统，主控节点有一个Master，此时因为网络故障，导致其他人以为这个Master不可用了，其他节点出现了别的Master，导致集群里有2个Master同时在运行.
                  2. 问题出现：当客户端a与zk之间出现网络故障，zk感知不到客户端a的心跳，那么就会删除对应的临时节点，那么此时监听该临时节点的客户端b就会拿到锁，此时就出现问题了。 
                  3. 问题解决：网络问题是一个比较难解决的事情。修改curator框架源码,对整个父级上个锁标识，但是这样的话一旦宕机就完蛋，后续还需要加上更加复杂的协调控制操作。

            3. 元数据 / 配置信息管理 : https://juejin.im/post/6850418115143335943

            4. HA高可用性:

               这个应该是很常见的，比如 hadoop、hdfs、yarn 等很多大数据系统，都选择基于 zookeeper 来开发 HA 高可用机制，就是一个**重要进程一般会做主备**两个，主进程挂了立马通过 zookeeper 感知到切换到备用进程。

            ![zk的高可用场景](C:\Users\guozh\Desktop\java\石杉\zk的高可用场景.png)

      6. redis分布式锁和zk分布式锁对比

         1. redis锁需要自己不断尝试去获取锁 , 比较消耗性能; zk分布式锁只需要注册一个监听器即可 , 不需要不断轮询 .
         2. redis的客户端如果挂了 , 锁要等到超时时间过了才会释放 , 而zk因为创建的是临时节点 , 只要客户端挂了 , znode就会被zk删除,自动释放锁.
         3. redis集群是AP架构,主从同步是异步的 , 如果同步完成之前主宕机 , 会出现数据不一致的问题 ; zk集群是CP的 , 强一致性的 , 不会存在一致性问题.

      7. 分布式锁抗高并发

         1. 分段加锁 + 合并扣减

         2. 对某个商品下单，对一个分布式锁每秒突然有上万请求过来，都要进行加锁，此时怎么办呢？

            比如你的苹果库存有10000个，此时你在数据库中创建10个库存字段

            一个表里有10个库存字段，stock_01，stock_02，每个库存字段里放1000个库存

            此时这个库存的分布式锁，对应10个key，product_1_stock_01，product_1_stock_02

            请求过来之后，你从10个key随机选择一个key，去加锁就可以了，每秒过来1万个请求，此时他们会对10个库存分段key加锁，每个key就1000个请求，每台服务器就1000个请求而已

            万一说某个库存分段仅仅剩余10个库存了，此时我下订单要买20个苹果，合并扣减库存，你对product_1_stock_5，加锁了，此时查询对应的数据库中的库存，此时库存是10个，不够买20个苹果

            你可以尝试去锁product_1_stock_1，再查询他的库存可能有30个

            此时你就可以下订单，锁定库存的时候，就对product_1_stock_5锁定10个库存，对product_1_stock1锁定10个库存，锁定了20个库存

         3. 疑问: 合并扣减时 , 发现其他分段已经被人加锁了 ,怎么办? 这个时候就得等待别人释放锁，去获取那个锁分段 , 尝试获取其他锁超过一定时间没获取到就返回库存不足然后释放持有的锁.

         4. 库存服务 , 能不能不用分布式锁实现高并发的库存更新?

            1. 大厂一般不用分布式锁 , 采用nosql数据库里面的k-v存储类型(如tair , redis , mongdb) , 然后不查询 ,直接扣 , 扣到负数就回滚库存 , 返回提示给用户 . 然后将本次操作发送给mq , mq交给另外一个服务去慢慢修改关系型数据库里面的数据(异步同步数据库). 这个主要做好一致性保证方法以及两个库之间的数据同步.
            2. 比如nosql扣减库存,然后发消息队列 , 一致性怎么保证? 可以使用redis + lua脚本 , 进行扣减 , 成功后发送mq , 这样做成原子性的操作.

   3. 分布式session方案

      1. session 是啥？浏览器有个 cookie，在一段时间内这个 cookie 都存在，然后每次发请求过来都带上一个特殊的 `jsessionid cookie`，就根据这个东西，在服务端可以维护一个对应的 session 域，里面可以放点数据。

         一般的话只要你没关掉浏览器，cookie 还在，那么对应的那个 session 就在，但是如果 cookie 没了，session 也就没了。常见于什么购物车之类的东西，还有登录状态保存之类的。

      2. tomcat + redis

         1. 就是使用 session 的代码，跟以前一样，还是基于 tomcat 原生的 session 支持即可，然后就是用一个叫做 `Tomcat  RedisSessionManager` 的东西，让所有我们部署的 tomcat 都将 session 数据存储到 redis 即可。
         2. 会与 tomcat 容器重耦合，如果我要将 web 容器迁移成 jetty，难道还要重新把 jetty 都配置一遍？因为上面那种 tomcat + redis 的方式好用，但是会**严重依赖于web容器**，不好将代码移植到其他 web 容器上去，尤其是你要是换了技术栈咋整？比如换成了 spring cloud 或者是 spring boot 之类的呢？

      3. spring session + redis

         1. 配置代码:  https://gitee.com/shishan100/Java-Interview-Advanced/blob/master/docs/distributed-system/distributed-session.md
         2. 给 sping session 配置基于 redis 来存储 session 数据，然后配置了一个 spring session 
            的过滤器，这样的话，session 相关操作都会交给 spring session 来管了。接着在代码中，就用原生的 session 操作，就是直接基于 spring sesion 从 redis 中获取数据了。
         3. 相关文章: https://juejin.im/post/6844903869634478088

   4. 分库分表

      1. 为什么要进行分库分表

         1. 单表的数据量过大会影响sql性能 . 单表的数据不要过大 , 超过1000w就应该考虑拆分了. 保持每个表几百万的数据 , 这样sql跑的不会太慢.

         2. 一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。以及单个库磁盘会有很大压力.

            | #            | 分库分表前                   | 分库分表后                                   |
            | ------------ | ---------------------------- | -------------------------------------------- |
            | 并发支撑情况 | MySQL 单机部署，扛不住高并发 | MySQL从单机到多机，能承受的并发增加了多倍    |
            | 磁盘使用情况 | MySQL 单机磁盘容量几乎撑满   | 拆分为多个库，数据库服务器磁盘使用率大大降低 |
            | SQL 执行性能 | 单表数据量太大，SQL 越跑越慢 | 单表数据量减少，SQL 执行效率明显提升         |

      2. 分库分表的中间件

         1. Sharding-jdbc

            当当开源的，属于 client 层方案，目前已经更名为 [`ShardingSphere`](https://github.com/apache/incubator-shardingsphere)（后文所提到的 `Sharding-jdbc`，等同于 `ShardingSphere`）。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且截至 2019.4，已经推出到了 `4.0.0-RC1`  版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC  事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017  年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也**可以选择的方案**。

         2. Mycat

            基于 Cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 Sharding jdbc 来说，年轻一些，经历的锤炼少一些。

         3. 对比

            1. Sharding-jdbc 这种 client 层方案的**优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高**，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要**耦合** Sharding-jdbc 的依赖；
            2. Mycat 这种 proxy 层方案的**缺点在于需要部署**，自己运维一套中间件，运维成本高，但是**好处在于对于各个项目是透明的**，如果遇到升级之类的都是自己中间件那里搞就行了。

      3. 数据拆分

         1. 垂直拆分: 

            1. 就是**把一个有很多字段的表给拆分成多个表**，**或者是多个库上去**。一般来说，会**将较少的访问频率很高的字段放到一个表里去**，然后**将较多的访问频率很低的字段放到另外一个表里去**。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。
            2. 举例: 把一个大表拆开，订单表、订单支付表、订单商品表。一般在数据库表设计时就会考虑到.

         2. 水平拆分: 

            1. 把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。

               ![数据库的水平拆分](C:\Users\guozh\Desktop\java\石杉\数据库的水平拆分.png)

         3. 表层面的拆分:

            1. 就是分表，将一个表变成 N 个表，就是**让每个表的数据量控制在一定范围内**，保证 SQL 的性能。否则单表数据量越大，SQL 性能就越差。一般是 200 万行左右，不要太多，但是也得看具体你怎么操作，也可能是 500 万，或者是 100 万。你的SQL越复杂，就最好让单表行数越少。

         4. 进行时机:

            1. 垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；
            2. 水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；
            3. 分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都 ok 了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。

         5. 分库分表的方式

            1. range 分发，就是每个库一段连续的数据，这个一般是按比如**时间范围**来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。
            2. hash分发 , 是按照某个字段 hash 一下均匀分散，这个较为常用。根据你指定的某个字段值，比如说 userid，自动路由到对应的库上去，然后再自动路由到对应的表里去。好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。

         6. 评论区: MySQL自带的分区功能慎用，慎用，慎用；垂直分表结合微服务相对比较好搞，水平分表mycat太依赖运维配置了，关联查询不灵活，而且需要各种配置全局表和ER表，DDL甚至DML都比较麻烦，资源比较充裕还是可以考虑现在tidb之类的分布式数据库.

      4. 如何把系统不停机迁移到分库分表?

         1. 双写迁移方案

            1. 修改原来的系统 , 之前写数据的地方 , 同时写老库和新库. 新库就通过数据库中间件写入分库和分表.

            2. 然后将系统部署后 , 用后台数据迁移临时工具 跑起来读老库数据写新库 , 写的时候根据gmt_modified这类时间戳字段判断数据最后的修改时间 ,读出来的数据在新库里没有，或者是比新库的数据新才会写 . 

            3. 导完一轮之后 , 程序自动做一轮校验 对比数据 , 如果有不一样的 , 就针对不一样的从老库再次读出来然后写 , 反复循环 , 直到两个库每个表的数据都完全一直为止.

               ![数据库的双写迁移方案](C:\Users\guozh\Desktop\java\石杉\数据库的双写迁移方案.png)

      5. 如何设计可动态扩容的分库分表方案

         1. 原先的库和表的数量都不变 , 只是增加服务器的数量 , 比如32库32表 , 原来是4台服务器 , 每台机器装8个数据库 , 每个库有32张表 . 最多可以扩展到3台机器, 每个服务器装一个库, 每个库里有32张表. 这样扩容之后程序里直接改一下数据的地址就行.
         2. 步骤
            1. 设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 * 32 表，对于大部分公司来说，可能几年都够了。
            2. 路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表
            3. 扩容的时候，申请增加更多的数据库服务器，装好 mysql，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。
            4. 由 dba 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。
            5. 我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。
            6. 重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。

      6.  分库分表之后全局的id主键怎么生成

         1.  基于单库生成自增id : 单库的性能瓶颈,不适用于高并发.

         2. UUID : 

            1. 不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，作为主键长度不适合。
            2. 信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。
            3. 对MySQL索引不利：作为数据库主键，在InnoDB引擎下，UUID 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作（连续的 ID 可以产生部分顺序写），还有，由于在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 
               树节点到内存，在插入这条记录后会将整个节点写回磁盘，而且也会引起数据位置的频繁变动 ，性能下降明显。

         3. snowflake 算法

            1. snowflake 算法是 twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的  id，1 个 bit 是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id，12 bit 作为序列号。

               - 1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。
               - 41 bit：表示的是时间戳，单位是毫秒。41 bit 可以表示的数字多达 `2^41 - 1`，也就是可以标识 `2^41 - 1` 个毫秒值，换算成年就是表示69年的时间。
               - 10 bit：记录工作机器 id，代表的是这个服务最多可以部署在 2^10台机器上哪，也就是1024台机器。但是 10 bit 里 5 个 bit 代表机房 id，5 个 bit 代表机器 id。意思就是最多代表 `2^5`个机房（32个机房），每个机房里可以代表 `2^5` 个机器（32台机器）。
               - 12 bit：这个是用来记录同一个毫秒内产生的不同 id，12 bit 可以代表的最大正整数是 `2^12 - 1 = 4096`，也就是说可以用这个 12 bit 代表的数字来区分**同一个毫秒内**的 4096 个不同的 id。

               ```
               0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000
               ```

            2. 优点:

               1. 毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。
               2. 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。
               3. 可以根据自身业务特性分配bit位，非常灵活。

            3. 缺点:

               1. 强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。

                  时间回拨问题：由于机器的时间是动态的调整的，有可能会出现时间跑到之前几毫秒，如果这个时候获取到了这种时间，则会出现数据重复

               2. 机器id分配及回收问题：目前机器id需要每台机器不一样，这样的方式分配需要有方案进行处理，同时也要考虑，如果改机器宕机了，对应的workerId分配后的回收问题.

               3. 机器id上限：机器id是固定的bit，那么也就是对应的机器个数是有上限的，在有些业务场景下，需要所有机器共享同一个业务空间，那么10bit表示的1024台机器是不够的。这种场景可以把获取id功能单独作为一个系统独立出来.

         4. 改进方案1 , Leaf-segment方案: (参考:https://tech.meituan.com/2017/04/21/mt-leaf.html)

            1. 在使用数据库的方案上，做了如下改变 :

               1. 每次获取一个segment(step决定大小)号段的值。用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力。
               2. 各个业务不同的发号需求用biz_tag字段来区分，每个biz-tag的ID获取相互隔离，互不影响。如果以后有性能需求需要对数据库扩容，不需要上述描述的复杂的扩容操作，只需要对biz_tag分库分表就行。

               3. biz_tag用来区分业务，max_id表示该biz_tag目前所被分配的ID号段的最大值，step表示每次分配的号段长度。原来获取ID每次都需要写数据库，现在只需要把step设置得足够大，比如1000。那么只有当1000个号被消耗完了之后才会去重新读写一次数据库从max_id之后数字开始获取。读写数据库的频率从1减小到了1/step.

               4. 表设计:

                  ```sql
                  +-------------+--------------+------+-----+-------------------+-----------------------------+
                  | Field       | Type         | Null | Key | Default           | Extra                       |
                  +-------------+--------------+------+-----+-------------------+-----------------------------+
                  | biz_tag     | varchar(128) | NO   | PRI |                   |                             |
                  | max_id      | bigint(20)   | NO   |     | 1                 |                             |
                  | step        | int(11)      | NO   |     | NULL              |                             |
                  | desc        | varchar(256) | YES  |     | NULL              |                             |
                  | update_time | timestamp    | NO   |     | CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP |
                  +-------------+--------------+------+-----+-------------------+-----------------------------+
                  ```

            2. 优点:

               1. Leaf服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景。
               2. ID号码是趋势递增的8byte的64位数字，满足上述数据库存储的主键要求。
               3. 容灾性高：Leaf服务内部有号段缓存，即使DB宕机，短时间内Leaf仍能正常对外提供服务。
               4. 可以自定义max_id的大小，非常方便业务从原有的ID方式上迁移过来。

            3. 缺点:

               1. ID号码不够随机，能够泄露发号数量的信息，不太安全。容易被竞争对手算出一天的订单量.

               2. TP999数据波动大，当号段使用完之后还是会hang在更新数据库的I/O上，tg999数据会出现偶尔的尖刺。

                  这个可以通过双buffer优化 . Leaf服务内部有两个号段缓存区segment。当前号段已下发10%时，如果下一个号段未更新，则另启一个更新线程去更新下一个号段。当前号段全部下发完后，如果下个号段准备好了则切换到下个号段为当前segment接着下发，循环往复。详见: https://tech.meituan.com/2017/04/21/mt-leaf.html

               3. DB宕机会造成整个系统不可用。

         5. 改进方案二 : leaf - snowflake方案 (参考:https://tech.meituan.com/2017/04/21/mt-leaf.html)

            1. Leaf-snowflake方案完全沿用snowflake方案的bit位设计，即是“1+41+10+12”的方式组装ID号. 改进点: 

               1. 服务规模较大 , workId手动配置成本太高时: 

                  使用Zookeeper持久顺序节点的特性自动对snowflake节点配置wokerID. 

                  除了每次会去ZK拿数据以外，也会在本机文件系统上缓存一个workerID文件。当ZooKeeper出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。这样做到了对三方组件的弱依赖。一定程度上提高了SLA .

               2. 解决时钟回拨问题: 

                  1. 服务启动时先通过zookeeper的上的node记录的时间来校验是否发生了时间回拨.
                  2. 发现后 , 可以做一定期限的等待 , 等时钟自己追上 如果还是小于 , 抛异常/自动摘除本身节点 并报警.

      7. MySQL读写分离的原理 , 主从同步的延时问题

         主库写并发越高 , 从库延长越高 , 经验值: 主库写1000/s从库延长几ms,比如新增1000条数据  ; 主库2000/s , 从库延迟几十ms; 主库写并发达到4000/s,6000/s,8000/s,主库都快死了,从库延迟会有几秒.

         1. 读写分离: 基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。

         2. 主从复制原理:

            1. 主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 
               relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 
               日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的。

               ![mysql主从复制原理](C:\Users\guozh\Desktop\java\石杉\mysql主从复制原理.png)

         3. 主从复制数据丢失问题: 

            1. 如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。
            2. **半同步复制**，用来解决主库数据丢失问题: 也叫 `semi-sync` 复制，指的就是主库写入 binlog 日志之后，就会将**强制**此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到**至少一个从库**的 ack 之后才会认为写操作完成了。

         4. 主从复制的延时问题:

            1. 从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。所以这就是一个非常重要的点了，由于从库从主库拷贝日志以及串行执行 SQL 的特点，在高并发场景下，从库的数据一定会比主库慢一些，是**有延时**的。所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。

            2. 是这个么场景。有个同学是这样写代码逻辑的。先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了  2000/s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。

               我们通过 MySQL 命令：

               ```
               show status
               ```

               查看 `Seconds_Behind_Master`，可以看到从库复制主库的数据落后了几 ms。

            3. 解决方案:

               1. 分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。

               2. 打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。

                  所谓**并行复制**，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后**并行重放不同库的日志**，这是库级别的并行。

               3. 重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。

               4. 如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询**设置直连主库**。**不推荐**这种方法，你要是这么搞，读写分离的意义就丧失了。

   