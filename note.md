

任务:

1.石杉的架构课三季看完

2.力扣算法题 , 每天15道 , 先看慕课的算法课 , 小灰的算法书

3.简历中的项目 , 三板斧改造方案 , 中间件比如DRM

5.网上找面试题

6.DDD







<h3 id="分布式篇">分布式篇</h3> 

1. 服务框架 , Dubbo , spring cloud , gRPC , Thrift . 

服务注册和发现 , 通信和序列化 , 负载均衡 , 扩展机制 , 请求重试 , 请求超时

2. spring cloud核心组件

   1. 注册中心Eureak
   2. 服务调用Feign
   3. 负载均衡Ribbon
   4. 网关Zuul / Gateway
      1. 灰度发布: 流量分发给灰度部署的机器
      2. 统一限流:
      3. 统一熔断:
      4. 统一鉴权:

3. Dubbo调用底层实现

   1. 消费者

      1. 动态代理:Proxy
      2. 负载均衡:Cluster , 故障转移
      3. 通信协议:Protocol , http/rmi/dubbo等协议
      4. 信息交换: Exchange , Request , Response
      5. 网络通信: Transport , 基于netty/mina实现
      6. 序列化: 封装好的请求序列化成二进制数组 , 通过netty/mina发送出去

   2. 生产者

      1. 反序列化
      2. 网络通信: Transport
      3. 信息交换: Exchange
      4. 通信协议: Protocol 
      5. 动态代理: Proxy

      ![Dubbo底层调用原理](C:\Users\guozh\Desktop\java\石杉\Dubbo底层调用原理.jpg)

   3. 网络通信netty

      1. 基于NIO实现的

      2. 服务提供者

         1. Acceptor线程通过Selector组件轮询ServerSocketChannel的网络事件  , 同时ServerSockerChannle会持续监听端口号 , 看有没有消费者netty来建立网络连接.
         2. 消费者通过netty框架与服务提供者的端口号和ServerSocketChannel建立连接 , 每个消费者建立一个SocketChannel对象 . netty会将建立好的连接SocketChannle分配给Processor线程 , 每一个Processor线程通过多路服用轮询组件Selector , 来不断轮询看这些SocketChannel对应的服务消费者有没有发请求过来. 轮询到有请求过来就会解析请求走后面的流程.
         3. 每个Processor可以支撑多个消费者的请求.
         4. 服务响应也是通过Processor线程 , 通过对应消费者的SockerChannel发响应发回到消费者的netty .

      3. 服务消费者

         1. 同提供者类似 ,也是对一个提供者建立一个SocketChannel连接, 一个Processor线程通过Selector轮询多个SocketChannel的网络事件 , 把响应值返回给消费者.

         ![网络通信netty框架原理](C:\Users\guozh\Desktop\java\石杉\网络通信netty框架原理.jpg)

4. 如何设计一个RPC框架

   1. 动态代理  
      1. 消费者和提供者都要实现某个框架的动态代理的, PRC框架的一切细节都在这个动态代理里面实现.调用动态代理的方法.
   2. 服务注册中心
      1. 服务注册,服务发现 . 或者 基于zookeeper .
   3. Cluster层 
      1. 从本地服务注册表根据负载均衡找到要调用的机器列表 .
      2. 负载均衡策略 . 
   4. 调用信息交给协议层 
      1. 协议
      2. 网络通信框架
      3. 序列化和反序列化

5. Springcloud底层原理

   1. 注册中心Eureka

      1. 服务注册与发现
         1. 服务注册表 , 二级缓存(ReadWrite缓存+ReadOnly缓存) , 后台有线程会定时将ReadWrite缓存同步给ReadOnly缓存 , 服务发现定时(每隔30s)拉取ReadOnly的缓存 . 
      2. 心跳与故障
         1. 服务注册机器会每30s发送一次心跳 , 服务注册表会记录心跳 , 后台有个心跳线程会定时检查,当发现一定时间内某个机器没有心跳 , 任务机器挂了 , 将该机器剔除服务注册表 , 同事会发指令ReadWrite缓存 , ReadWrite缓存会清空自己 , 然后定时同步线程也会清空ReadOnly缓存 . 当下次的服务发现时会去服务注册表拉取最新的数据更新到两个缓存中.

      ![Eureka注册中心原理](C:\Users\guozh\Desktop\java\石杉\Eureka注册中心原理.jpg)

   2. Ribbon

   3. Feign 

      1. 对一个接口打了一个注解 , 他会针对这个注解标注的接口生成动态代理 , 调用时底层生成http协议格式的请求 , 通过Ribbon 从本地的服务注册列表中根据负载均衡算法获选出一个机器 , 接着对机器发送http请求即可.

   4. Zuul

      1. 配置一下不同请求路径和服务的对应关系 , 把请求直接匹配到服务 , 基于Ribbon , 发请求到指定的机器上去.

6. Dubbo和Springcloud的优缺点

​	1.总结：dubbo优点：深度优化后，基于TCP的RPC调用更加轻量级，速度更快。 dubbo缺点：只是一		套RPC服务框架没有配套设施，需要自己再找其他的组件去做配合使用。 SpringCloud优点：开箱即用，和spring完美搭配，提供一整套分布式系统解决方案。 SpringCloud缺点：基于http请求，较慢。有些组件存在问题（springCloud config） 两者差异：最大的差异在对请求的处理上，一个基于TCP一个基于HTTP。一个是RPC服务框架，一个是分布式系统解决方案。

7. 服务注册中心比较

   1. Eureka集群架构

      1. peer2peer，每个注册中心服务的节点地位相等，会将每次心跳和更新请求同步到每一个节点上，因此并发高了之后，注册中心的内部流量会很大。注册列表的更新方式是通过客户端拉取

   2. Zookeeper集群

      1. master-follower，通过只对主节点进行写，然后由主节点同步到从节点后，主动向节点推送到各个服务节点。时效性较高 .  服务消费者可以去加监听服务列表, ZK会主动通知给消费者服务列表的变动.当有机器新增或者下线, ZK的leader节点先感知到然后同步给Follower节点,Follower节点主动通知服务消费者.

         ![ZooKeeper服务注册与发现原理](C:\Users\guozh\Desktop\java\石杉\ZooKeeper服务注册与发现原理.jpg)

   3. 一致性保障 CP or AP

      1. C:Consisitency(一致性)

         A:Availability(可用性) 

         P:Partition Tolerance(分区容错性) .

         CAP相关文章: https://juejin.im/post/6844903936718012430

         在分布式的环境下，网络无法做到100%可靠，有可能出现故障，因此分区是一个必须的选项，如果选择了CA而放弃了P，若发生分区现象，为了保证C，系统需要禁止写入，此时就与A发生冲突，如果是为了保证A，则会出现正常的分区可以写入数据，有故障的分区不能写入数据，则与C就冲突了。因此分布式系统理论上不可能选择CA架构，而必须选择CP或AP架构。

      2. zk: 基于cp，保证数据的顺序一致性，因此需要牺牲掉一些可用性，例如主节点宕机后，就不再可用（不提供读写服务），需要从从节点中再次选取出主节点后才会继续提供服务。

      3. Eureka：基于ap，保证节点的可用性，在某一些服务节点挂掉之后，其余节点可以继续提供服务，但是因为数据未能同步，所以其它节点提供的数据可能是不一致的, 会确保最终一致性。 这两者之间的差异，都是因为模式造成的，一个是中心化，一个是去中心化。

   4. 服务注册发现的时效性

      1. zk时效性好 , 秒级别可以感知

      2. Eureka , 默认配置比较糟糕 , 服务发现感知到要几十秒 , 甚至分钟级别.

         优化:  

         1. ReadOnly缓存和ReadWrite缓存的同步周期缩短(30s->3s) , eureka.server.responseCacheUpdateIntervalMs = 3000

         2. 服务发现拉取的周期缩短(30s->3s),

            eureka.client.registryFetchIntervalSeconds = 3

         3. 服务心跳上报周期缩短(30s->3s)

            eureka.client.leaseRenewalIntervalInseconds = 3

         4. 心跳检查周期缩短(60s->6s)

            eureka.server.evictionIntervalTimeMs=6000

         5. 心跳超时时间(超过这个时间判定为死亡.90s->9s)

            eureka.instance.leaseExpirationDurationInSeconds= 90

         6. 关闭eureka的自我保护机制(突然网络故障,一定比例机器没有发生心跳,会触发保护机制,保护服务注册表不会被修改 , 源码的bug较多)

            eureka.server.enableSelfPreservation: false

   5. 容量

      1. zk: 不适合大规模的服务实例 , 因为服务上下线的时候会瞬间推送数据通知到所有的其他服务实例 , 一旦达到几千服务实例时 , 会导致网络带宽被大量地占用.
      2. Eureka: 也很难支撑大规模的服务实例 , 因为每个节点收到数据通知都要同步给其他节点 , 相当于每次更新会落到集群的每个节点上 , 如果服务过多 , Eureka整个集群内部流量巨大.
      3. 实际生成部署,会采用比较高的配置的机器来做,8C16G, 16C32G的高配机器来做,基本可以做到每台机器每秒钟支撑几千请求.

   6. 部署上万服务实例 , 服务注册中心如何优化(自研注册中心)

      1. 服务注册表分片存储. 每台机器存储部分的服务注册表,机器不互相同步数据 , 将集群请求分散到多个节点.应对. (高并发)
      2. 每个机器都有自己的Slave机器做备份机器来保证(高可用).
      3. 通过主从节点都写成功了再返回ack(一致性).
      4. 服务消费者 通过代理层去指定的节点拉取部分注册信息，不用每次都拉取集群的全集。

      ![自研注册中心架构](C:\Users\guozh\Desktop\java\石杉\自研注册中心架构.jpg)

   7. 其他注册中心比较

      |       Feature        | Consul                                  | Zookeeper                      | Etcd                  | Eureka                           | SofaRegistry           |
      | :------------------: | :-------------------------------------- | ------------------------------ | --------------------- | -------------------------------- | ---------------------- |
      |     服务健康检查     | 定期healthcheck(http/tcp/script/docker) | 定期心跳保持会话(session) +TTL | 定期refresh(http)+TTL | 定期心跳+TTL;支持自定义healcheck | 定期连接心跳＋锻炼敏感 |
      |        一致性        | raft                                    | ZAB                            | raft                  | 最终一致性BASE                   | 最终一致性BASE         |
      |         cap          | cp                                      |                                |                       |                                  |                        |
      | 使用接口(多语言能力) | 支持http和dns                           | 客户端                         | http/grpc             | 客户端/http                      | 客户端(java)           |
      |      watch支持       | 全量/支持long polling                   | 支持                           | 支持long polling      | 不支持(client定期fetch)          | 支持(服务端推送)       |
      |         安全         | acl/https                               | acl                            | https支持(弱)         | -                                | acl                    |
      |   spring cloud集成   | 支持                                    | 支持                           | 支持                  | 支持                             | 支持                   |

   

8.网关

1. 网关的作用:

   1. 动态路由 , 负载均衡: 新开发某个服务 , 动态把请求路径和服务的映射关系加载到网关;服务增减机器,网关自动热感知.
   2. 灰度发布 . 可以调整流量比例到新代码的机器上.比如默认是50%的流量到新机器,如果新代码有问题,50%的服务就不可用了,可以通过网关来调整流量的比例 , 逐步扩大灰度比例 . 降低新代码上线的影响.
   3. 鉴权认证
   4. 接口性能监控 . 每个api接口的RT , QPS , 成功率等.
   5. 系统日志
   6. 限流熔断
   7. 数据缓存 . 某些接口的响应做缓存

2. 网关的技术选型

   1. Kong : 依托于Nginx实现，OpenResty，lua实现的模块，现成的一些插件，可以直接使用 . Nginx抗高并发的能力很强，少数几台机器部署一下，就可以抗很高的并发，精通Nginx源码，很难，c语言，很难从Nginx内核层面去做一些二次开发和源码定制
   2. Zuul : Spring cloud , 基于java开发,核心网关功能比较简单 , 但是比如灰度发布 , 限流 , 动态路由之类的都需要二次开发. 高并发能力不强.
   3. 自研网关: Java技术栈为主的大厂，很多其实用Java、Servlet、Netty来开发高并发、高性能的网关系统，自己可以把控一切

3. 动态路由的实现

   1. 动态路由实现: 可以使用第三方组件保存路由关系，然后在网关里面通过定时任务去定时刷新组件中保存的路由信息。 因此就可以基于mqsql去做路由关系的保存，然后通过后台管理系统去操作db，再由网关去定时查询db更新路由表，实现动态路由效果。 
   2. 代码实现: C:\Users\guozh\Desktop\java\石杉\代码2\zuul-gateway\src\main\java\com\zhss\demo\zuul\gateway 中

4. 网关抗住每秒10w的高并发访问 ,如何优化

   1. zuul集群部署  , 前面有一层Ngnix反向代理 , 前面再有一层LVS负载均衡层.

      LVS是Linux virtual 
      server的缩写，是一个高可用性、高性能的虚拟服务器集群系统。主要针对高可伸缩、高可用网络服务的需求，给出了基于IP层和基于内容请求分发的负载平衡调度解决方法，并在Linux内核中实现了这些方法，将一组服务器构成一个实现可伸缩的、高可用网络服务的虚拟服务器。

   2. zuul网关部署机器,部署8C16G , 每秒几千请求不是问题 . 10w请求要几十台网关机器

   3. 生产级的网关应该具备上面的几个特点和功能.需要二次开发. 动态路由/灰度发布/鉴权认证/限流熔断

5. 如何基于网关实现灰度发布

   1.  开发流程： 首先自己建一张表，存入具体uri以及是否灰度发布的一些信息，然后搞一张映射表。 启动个线程每个多少时间就去刷新数据写到concurrenthashmap里面。 接着搞一个filter继承ZuulFilter，重写里面几个函数，其中shouldFilter根据返回值去判断执不执行run。 因此再should里面遍历map去看这次请求是否有开启灰度发布，如果有就执行run里面的逻辑，就自定义一些分发逻辑，这里用的时通过version去判断和分发。 2、灰度发布流程 首先通过后台系统更改灰度发布标识，后台线程更新了map后，就会去执行根据version分发的策略，将少部分流量分发到new上，然后监控和对应的后台，如果没问题，就更改为current，全线上线，最后将灰度发布表示改回来。
   2. 代码实现:  C:\Users\guozh\Desktop\java\石杉\代码 3\zuul-gateway\src\main\java\com\zhss\demo\zuul\gateway 里面 GrayRelease*的三个文件.

6. 公司的网关mbgw的架构图

   ![公司网关架构图](C:\Users\guozh\Desktop\java\石杉\公司网关架构图.jpg)



9.分布系统实践问题

1. 各服务在生产环境如何部署

   1. 中小型公司，一般服务拆分大概在十几二十个，那么相对来说比较好部署。

      注册中心，4核8G的机器，可以抗住每秒大概1000左右的请求，那么部署两台，就完全足够了。另外部署两台还可以作为高可用的冗余，相关的优化参数可以调到很小，让服务的发现，服务注册，服务异常等等信息的时效性很高。 

      网关的话，4核8G的机器，也是差不多能抗1000左右，但是一般会部署3-4机器，保证高可用的同时也可以降低每个网关系统的压力，通常在网关之前还会用ngx的反向代理+LVS负载均衡。 

      数据库，16核32G的机器部署mysql，高峰期可以抗住三四千的请求。 

      以上是对应机器配置的相对经验值，如果要求对应的qps达到几千几万的话。需要一个个模块再次进行优化

   2. 服务的高峰QPS是多少? 压测工具最大QPS是多少
      1. 可以在代码里,家加一些metrics统计机制. 对核心接口,用AtomicLong统计一下每分钟的请求量,成功次数,失败次数,在内存里做一些计数 . 
      2. 统计每个接口的耗时RT , TP99 = 100ms (99%的接口请求耗时在100ms以内), TP95 也是同理. 
      3. 百度java压测工具 , 开源可用的 . 如果1000/s发送压测请求 , 然后800/s被处理 . 200/s的请求被阻塞,压测工具可以感知到.
   3. 如果访问量增加十倍 , 考虑过扩容方案么
      1. 网关直接多部署10倍的机器 . 改一下nginx里面的方向代理.
      2. 服务扩容 , 加机器 , 服务会自动注册 感知到.
      3. 升级成几百个服务实例 , eureka机器可以考虑升级成8C16G的机器 , 可以抗每秒上千请求 , 横向扩容eureka用处不大 , 因为每台机器都是要保存全部的注册列表.
      4. 数据库 , 每秒高峰期几千请求 , 可以考虑给单个数据库提高配置 , 32C128G机器 , 可以抗几千并发.

2. 生产环境的超时和重试参数

   1. Spring cloud项目第一次启动的时候 , 人家调用经常会出现timeout , 是因为第一次请求的时候会去初始化Ribbon组件 , 初始化组件比较耗时 , 比较容易导致超时. 通过配置参数让服务启动时组件就初始化.

      ribbon.eager-load.enabled:true

      zuul.ribbon.eager-load.enable:true

   2. 配置超时和重试参数:

      ribbon.ConnecTimeout: 1000

      ribbon.ReadTimeout: 1000

      ribbon.OkToRetryOnAllOperations: true

      ribbon.MaxAutoRetries: 1  (重试目标机器1次)

      ribbon.MaxAutoRetriesNextServer:1  (目标机器重试失败换一台机器重试一次)

   3. 服务重试 , 防止服务重复下单的问题 , 接口的幂等性

      1. 如果是插入类型的请求：可以通过db的唯一键去做，如果插入失败则说明已存在，直接丢弃或者其他逻辑。或者用redis(接口+请求参数)拼成一个唯一的key，检查这个key是否存在，如果存在就丢弃或者其他逻辑.

      2. 如果是更新类型的请求 : 可以将请求过程分为几个节点，在各个阶段进行对应的幂等性保证 , 例如老师讲的前后拦截器，执行逻辑前，检查redis唯一key的值，如果是1说明已被成功执行，直接不做处理了；如果是0说明有同样的请求在执行，但是未完成，这时可以直接执行也可以等一段时间再检查再执行。当请求处理过程中，增加必要的异常处理，如果异常就回滚不修改key的值；如果执行成功，检查key值是否已被修改为1，已被修改就回滚，如果不能回滚就需要执行一些数据恢复的措施。如果要求不允许第二个请求执行逻辑，就在进入方法的时候就不允许执行了，不过这样吞吐量会降低。 我的思路跟下面有位同学的思路一样，不过通过注解去标识需要保证幂等的设计感觉很棒。

         也可用通过给数据加独占锁(select * from table for update no wait) , 来保证改数据只被一个请求在修改.

3. 画一下系统链路图 , 说一下分布式架构存在的问题

   1. 分布式事务 , 核心链路保证数据一致性

      1. 两阶段提交方案 / XA方案:

         1. 事务管理器 , 先询问每一个系统是否能执行 , 如果都可以执行 , 再进入第二阶段一次每个系统去执行. 如果其中一个不 能执行 , 就取消事务的执行. 常见于单个系统跨多个库的分布式事务(现在分布式系统不允许这么做了) , 因为严重依赖与数据库层面来搞定复杂的事务,效率低,不适合高并发场景. 基于spring + JTA就能实现.

      2. TCC方案: Try/Confirm/Cancel

         1.  Try阶段: 对各个服务的资源做检测以及对资源进行锁定或者预留
         2. Confirm阶段: 在各个服务中执行实际的操作
         3. Cancel阶段: 如果任务一个服务执行报错 , 就要进行补偿 , 就是执行已经成功的业务逻辑的回滚操作.
         4. 很少有人用,比较依赖自己写代码来回滚补偿 , 业务代码比较难维护. 比较适合的场景: 一致性要求太高了,比如资金类的场景 , 可以用TCC方案 , 自己编写大量的业务逻辑 , 自己判断一个事务中的各个环节是否ok , 不ok就执行补偿/回滚代码. 最好每个系统执行时间比较短.

      3. 本地消息表方案

         1.  A系统在自己本地的一个事务里面操作同时 , 插入一条数据到消息表.
         2. 消息表有个后台不断轮询 , 去执行消息(调用系统B).
         3. 系统B自己需要保证幂等性 , 如果B处理成功了 ,返回成功 , 系统A更改消息表中的状态为已完成 , 继续之后的业务逻辑. 如果B处理异常或者超时 , A的后台线程会定时轮询未完成的消息来执行 , 知道系统B成功为止.
         4. 方案缺陷: 严重依赖于数据库的消息表来管理事务的 , 如果是高并发场景有问题,数据库扛不住.

      4. 可靠消息最终一致性方案

         1. 不要用本地消息表了 , 直接基于MQ来实现事务  , 比如阿里的RoceketMq(3.2.6版本之前的都有回调的接口);

         2. 过程:

            1. A系统先发送一个prepared消息到MQ , 如果这个prepared消息发送失败那么直接取消不执行了.

            2. 如果这个消息发送成功过了 , 那么接着执行本地事务 , 执行成功之后给MQ发送confirm消息. 如果执行失败了就告诉MQ回滚消息 . 

            3. 如果发送了确认消息 ,B系统会收到确认消息 , 然后执行本地事务.

            4. MQ会自动定时轮询所有prepared消息回调你的接口,询问A系统这个消息是不是本地事务失败了 , 没有发送确认消息 , 是继续重试还是回滚 ? 这里A系统可以查一下数据库看事务是否执行失败了, 如果回滚了 , 那么这里也回滚 , 如果没有回滚 , 那要重新发一次confirm消息.. 这个就是避免可能本地事务执行成功了 , 但confirm的消息发送失败了.

            5. 如果B系统执行的事务失败了怎么办? B系统自身需要具备一套失败重试的机制 , 进行失败重试 ; 如果没有的话B系统可以通过MQ的相关机制让MQ重新发送消息 ; 也可以通过ZK , A系统发完消息之后一直监听ZK上的一个值 , B如果失败了 , 通知ZK , 然后ZK反过来通知A系统 , A系统把confirm消息再发一遍. 在这里B系统一定要保证自己的幂等性.

               ![分布式事务-可靠消息最终一致性方案](C:\Users\guozh\Desktop\java\石杉\分布式事务-可靠消息最终一致性方案.jpg)

         3. 订单服务的可靠消息最终一致性方案(上述过程细化):

            整个订单服务可以分为两个链路 , 一个是核心链路(订单业务) , 一个是非核心链路(wms发货服务),整个流程:

            1. 先向RocketMQ发送half message . (为什么不把发送ma放在核心交易链路之后? 如果放在核心链路之后 , 有可能发送消息失败,这样导致后序操作无法进行.之前发半消息的话 , MQ会通过回调反复确认核心链路的状态. )
            2. MQ返回成功 , half message在MQ里面有持久化的记录.
            3. 调用核心链路.
            4. 核心链路如果失败 , 走失败的逻辑 : 调用支付服务进行退款 , 更改订单的状态为取消 , 给MQ发送rollback消息废弃掉刚刚half message消息.
            5. 核心链路成功 , 就给MQ发送commit message让消费者继续消费.
            6. 在half message等待期间,一直没有commit/rolback的消息 , MQ会有后台线程来轮询,走回调去查询状态.
            7. 消费者收到消息,消费完成后回复MQ一个ack , 如果消费失败了 , MQ会重新投递或者换一个机器投递消息.

         ![分布式事务-订单系统可靠消息最终一致性原理](C:\Users\guozh\Desktop\java\石杉\分布式事务-订单系统可靠消息最终一致性原理.jpg)

         

      5.  一般分布式事务常用的是TCC和可靠消息一致性这两种思路。一个要求强一致，一个要求最终一致。强一致主要用于核心模块，例如交易/订单等等。最终一致一般用于边缘模块例如库存，通过mq去通知，保证最终一致性，也可以业务解耦。

      6. TCC事务框架 , seata框架(阿里的),支持dubbo和spring cloud

         1. seata 的使用demo: 直接在github页面上下载：[https://github.com/seata/seata-samples](https://github.com/seata/seata-samples%EF%BC%8C%E5%BB%BA%E8%AE%AE%E8%BF%99%E7%A7%8D%E6%96%B9%E5%BC%8F%EF%BC%8C%E6%AF%94%E8%BE%83%E5%BF%AB%E4%B8%80%E7%82%B9%EF%BC%8Cgit) , 

         2. 然后先要下载一个seata-server到本地，在这里下载：[https://github.com/seata/seata/releases](https://github.com/seata/seata/releases%EF%BC%8C%E7%84%B6%E5%90%8E%E5%90%AF%E5%8A%A8%E8%B5%B7%E6%9D%A5%EF%BC%8C%E8%BF%99%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E4%B8%AD%E5%BF%83%EF%BC%8C%E8%B4%9F%E8%B4%A3%E7%BB%B4%E6%8A%A4%E6%AF%8F%E4%B8%80%E4%B8%AA%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E7%8A%B6%E6%80%81%EF%BC%8C%E8%A7%A6%E5%8F%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E6%8F%90%E4%BA%A4%E5%92%8C%E5%9B%9E%E6%BB%9A) , 然后启动起来，这是分布式事务管理中心，负责维护每一个分布式事务的状态，触发分布式事务的提交和回滚.

         3. seata-server.bat -h 127.0.0.1 -p 8091 -m file

            直接把Spring Cloud版本的例子运行起来，观察一下依赖、配置和代码，以后自己在系统里使用直接仿照即可，eureka、account、order、storage、business，依次运行起来，修改一些配置，比如说数据库连接配置

            但是任何一个服务报错之后，seata这个分布式事务的框架会感知到，自动触发所有服务之前做的数据库操作全部进行回滚

         4. seata框架的实现原理

            1. 在seata中存在以下角色： 

               1. Transaction Coordinator（TC）:协调器，单独的一个server。维护全局和分支事务的状态，驱动全局事务的提交或回滚。 

               2. Transaction Manager(TM)：全局事务的发起者，负责开始/提交/回滚一个全局事务。（对应订单服务）. 

               3. Resource Manager(RM)：管理分支事务（注册分支事务/状态/提交/回滚），并负责与TC通讯。

            2. 整个使用seata进行分布式事务管理的生命周期:

               1. TM向TC发起全局事务 , TC返回XID作为本次全局事务标识.
               2. XID通过链路向下传播 , RM将本地的事务注册到TC中表示为XID的全局事务中的一个分支事务.
               3. 当执行成功 , 后由TM向TC请求标识为XID的全局事务的提交. 当有一个服务失败时,TM会通过返回值感知到,然后告诉TC将XID的全局事务回滚掉. 由TC来驱动所有的分支事务进行提交/回滚.

            ![seata中tcc处理流程图](C:\Users\guozh\Desktop\java\石杉\seata中tcc处理流程图.png)

         5. TCC事务方案的性能瓶颈在哪里 , 能支撑高并发交易场景么

            1. 每个TM和RM要和TC进行频繁的网络通信 , 会带来系能的消耗 , 比如一个本地事务要耗时100ms , 引入分布式事务之后会耗时200ms
            2. TC(seata-server)中对事务日志和状态的存储 , 如果要支持高并发的话 ,TC也需要进行横向扩容 , 同时TC背后的db也要进行一些分库分表之类的优化.

      7. 可靠消息一致性方案 , 基于ActiveMQ或者RabbitMQ自己开发一下可靠消息服务, 收到一个消息后尝试投递到MQ上去 , 投递失败重试投递 , 当消费者消费成功后必须回调接口来通知处理成功 , 如果一段时间后生产者没有收到成功的消息,要重试投递消息到MQ. 

         也可以用RocketMQ直接提供了分布式事务的支持.

   2. 分布式锁 

      1. 当多个服务需要竞争一个单体资源时，可以考虑加上分布式锁。如果并发量高的话，可以考虑拆分掉那个单体资源，50个拆成5个10个资源，从而缩小锁的粒度，提高吞吐量。

      2. 基于Redisson框架实现:

         1. 支持redis单实例 , redis哨兵 , redis cluster , redis master-slave等部署架构.

         2. 代码:

            ```java
            RLock lock = redisson.getLock("myLock");
            lock.lock();
            lock.unlock();
            ```

         3. 原理流程图

            ![分布式锁-基于Redisson实现原理图](C:\Users\guozh\Desktop\java\石杉\分布式锁-基于Redisson实现原理图.jpg)

            1. redisson根据hash节点选择一台机器, 发送一段lua脚本到redis上, 用lua脚本是将一堆逻辑封装在lua脚本中 , 保证这段逻辑的原子性. 

            2. lua脚本的逻辑: 先判断key是否已经存在 , 不存在就可以继续加锁 , 然后生成一个当前客户端的hash值为该客户端的id作为value(例如123343-234234-545-321-dcgaga:1) ,然后key-vaule的实行set到redis里数据结构如下  , 设置存活时间默认30s; 加锁成功.

               mylock:

               {

               ​	"123343-234234-545-321-dcgaga:1":1

               }

            3. 当客户端2要进来加锁时 , 也执行同样的一段lua脚本 , 先发现key已经存在 , 然后判断key对应的vaule是否包含了客户端2的id , 显然是不包含的 . 然后客户端2会获取到pttl mylock返回的一个数字 ,代表了myLock锁的剩余生存时间. 此时客户端2会进入一个while循环 , 不停尝试加锁.

            4. watch dog自动延期机制: 客户端1一旦加锁成功就会自动启动一个watchdog线程 , 每隔10s检查一下 , 如果客户端1还持有锁key , 那么就延长锁的生存时间.

            5. 可重入加锁机制:  lua脚本中先判断exits mylock , key已经存在的 , 然后再判断因为mylock的key的hash数据结构中包含客户端1的id , 此时就会执行可重入加锁的逻辑 , 会用:

               incrby mylock 123343-234234-545-321-dcgaga:1 1 

               通过这个指令堆客户端1的加锁次数累加1. 数据结构如下:

               mylock:

               {

               ​	"123343-234234-545-321-dcgaga:1":2

               }

            6. 释放锁机制: 执行lock.unlock() , 每次堆mylock数据结构中的那个加锁次数减1 . 如果发现加锁次数是0 , 说明这个客户端已经不再持有锁了 , 此时用del mylock 指令 , 从redis中删除这个key. 另外的客户端2就可以尝试加锁了.

            7. 缺点: 客户端1在redis master上写入了mylock对应的key-vaule , 但是还没等master-slave完成异步的复制 , master出现的宕机 , slave变成了master , 接着客户端2尝试mylock加锁时在新的redis master上完成了加锁 , 但客户端1也以为自己成功加了锁. 此时系统在业务语义上会出现问题 , 导致脏数据的产生 . 

               所以这就是redis的master-slave架构的主从异步复制导致的, 在master宕机时,可能导致多个客户端同事完成加锁.

      3. 

