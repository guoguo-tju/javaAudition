

任务:

1.石杉的架构课三季看完

2.力扣算法题 , 每天15道 , 先看慕课的算法课 , 小灰的算法书

3.简历中的项目 , 三板斧改造方案 , 中间件比如DRM

5.网上找面试题

6.DDD

7.spring源码

8.设计秒杀系统

9.service mesh









<h3 id="分布式篇">分布式篇</h3> 

1. 如何设计一个高并发系统 (每秒上千个请求以上

   1. **系统拆分**:  将一个大系统拆分为多个子系统 , 用分布式框架dubbo或者spring cloud来搞 , 每个系统对应一个数据库.

   2. **缓存 :**  大部分的高并发场景，都是**读多写少**，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存。毕竟 redis 轻轻松松单机几万的并发。

   3. **MQ:** 针对高并发的写场景 . 大量的写请求灌入 MQ 里进行削峰，排队慢慢玩儿，**后边系统消费后慢慢写**，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的 .

   4. **分库分表:** 请求量如果再高一些 ,可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表**拆分为多个表**，每个表的数据量保持少一点，提高 sql 跑的性能。

   5. **数据库的读写分离 :** 大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，**主库写**入，**从库读**取，搞一个读写分离。**读流量太多**的时候，还可以**加更多的从库**。

   6. **Elasticsearch**: 简称 es。es是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用
      es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。

   7. 之前搞过微服务架构，个人经历说下，阿里云ECS弹性伸缩，高峰特别是秒杀时，NGINX限流一个IP每秒1个，前端CDN静态化，还有秒杀前不要暴露真实秒杀地址，单机+cache，配置ECS感应流量，自动扩展到20-30台，单台扛几百用户单纯响应是没啥问题的（这里说的是单纯响应，就是说先确保不出现500或502这类错误），后端代码逻辑Redis防刷，需要同步调用的接口尽可能少（比如一般只走支付网关，拉起支付接口），redis+lua预热加减库存，如果需要限流redis队列排序限流等（比如队列里用户数控制最多50000），同步接口返回速度尽可能高（这里面需要JVM、各种SQL优化以及读写分离、分库分表），能走异步的尽量走异步，比如短信通知，购买成功加积分级别，抵用券等。

      忘了补充一点，事务尽可能的小，就是说都是小事务提交（不要把什么写日志，调接口也包在开启事务逻辑里面），还有乐观锁，悲观锁，间隙锁（特别是间隙锁，MySQL在RR隔离级别下产生的间隙锁要特别小心），快照读，当前读，mvcc这些一定要清楚认知和使用恰当，不然事务隔离级别下的锁竞争，平峰时快速普通SQL不光会跑到十几甚至几十秒，而且会造成MySQL线程数跑满，或者直接挂了

      ![设计一个高并发系统](C:\Users\guozh\Desktop\java\石杉\设计一个高并发系统.jpg)

      



1. 服务框架 , Dubbo , spring cloud , gRPC , Thrift . 

服务注册和发现 , 通信和序列化 , 负载均衡 , 扩展机制 , 请求重试 , 请求超时

2. spring cloud核心组件

   1. 注册中心Eureak
   2. 服务调用Feign
   3. 负载均衡Ribbon
   4. 网关Zuul / Gateway
      1. 灰度发布: 流量分发给灰度部署的机器
      2. 统一限流:
      3. 统一熔断:
      4. 统一鉴权:

3. Dubbo调用底层实现

   1. 消费者

      1. 动态代理:Proxy 
         1. 动态代理策略 : 默认使用 javassist 动态字节码生成，创建代理类。但是可以通过 spi 扩展机制配置自己的动态代理策略。
      2. 负载均衡:Cluster , 故障转移
         1. random loadbalance: 
            1. 默认情况下，dubbo 是 random load balance ，即**随机**调用实现负载均衡，可以对 provider 不同实例**设置不同的权重**，会按照权重来负载均衡，权重越大分配流量越高，一般就用这个默认的就可以了。
         2. consistanthash loadbalance
            1. 一致性 Hash 算法，相同参数的请求一定分发到一个 provider 上去，provider 挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大。**如果你需要的不是随机负载均衡**，是要一类请求都到一个节点，那就走这个一致性 Hash 策略。
      3. 通信协议:Protocol , http/rmi/dubbo等协议
         1. dubbo 协议 :  **默认**就是走 dubbo 协议，单一长连接，进行的是 NIO 异步通信，基于 hessian 作为序列化协议。使用的场景是：传输数据量小（每次请求在 100kb 以内），但是并发量很高。
         2. rmi 协议: 走 Java 二进制序列化，多个短连接，适合消费者和提供者数量差不多的情况，适用于文件的传输，一般较少用。
         3. hessian 协议: 走 hessian 序列化协议，多个短连接，适用于提供者数量比消费者数量还多的情况，适用于文件的传输，一般较少用。
         4. http 协议 : 走 json 序列化。
         5. webservice : 走 SOAP 文本序列化。
      4. 信息交换: Exchange , Request , Response
      5. 网络通信: Transport , 基于netty/mina实现
      6. 序列化: 封装好的请求序列化成二进制数组 , 通过netty/mina发送出去
         1. dubbo支持的序列化协议: dubbo 支持 hession、Java 二进制序列化、json、SOAP 文本序列化多种序列化协议。但是 hessian 是其默认的序列化协议。

   2. 生产者

      1. 反序列化
      2. 网络通信: Transport
      3. 信息交换: Exchange
      4. 通信协议: Protocol 
      5. 动态代理: Proxy

      ![Dubbo底层调用原理](C:\Users\guozh\Desktop\java\石杉\Dubbo底层调用原理.jpg)

   3. dubbo集群容错策略

      1. #### failover cluster 模式

         1. 失败自动切换，自动重试其他机器，**默认**就是这个，常见于读操作。

      2. #### failfast cluster 模式

         1. 一次调用失败就立即失败，常见于非幂等性的写操作，比如新增一条记录（调用失败就立即失败）

      3. #### failsafe cluster 模式

         1. 出现异常时忽略掉，常用于不重要的接口调用，比如记录日志。

      4. #### failback cluster 模式

         1. 失败了后台自动记录请求，然后定时重发，比较适合于写消息队列这种。

      5. #### forking cluster 模式

         1. **并行调用**多个 provider，只要一个成功就立即返回。常用于实时性要求比较高的读操作，但是会浪费更多的服务资源，可通过 `forks="2"` 来设置最大并行数。

   4. Dubbo的SPI机制

      1. SPI是啥?

         1. spi，简单来说，就是 `service provider interface`，说白了是什么意思呢，比如你有个接口，现在这个接口有 3 个实现类，那么在系统运行的时候对这个接口到底选择哪个实现类呢？这就需要 spi 了，需要**根据指定的配置**或者是**默认的配置**，去**找到对应的实现类**加载进来，然后用这个实现类的实例对象。
         2. spi 经典的思想体现，大家平时都在用，比如说 jdbc。Java 定义了一套 jdbc 的接口，但是 Java 并没有提供 jdbc 的实现类。但是实际上项目跑的时候，要使用 jdbc 接口的哪些实现类呢？一般来说，我们要**根据自己使用的数据库**，比如 mysql，你就将 `mysql-jdbc-connector.jar` 引入进来；oracle，你就将 `oracle-jdbc-connector.jar` 引入进来。

      2. dubbo 也用了 spi 思想，不过没有用 jdk 的 spi 机制，是自己实现的一套 spi 机制。

         ```
         Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();
         ```

         Protocol 接口，在系统运行的时候，，dubbo 会判断一下应该选用这个 Protocol 接口的哪个实现类来实例化对象来使用。它会去找一个你配置的 Protocol，将你配置的 Protocol 实现类，加载到 jvm 中来，然后实例化对象，就用你的那个 Protocol 实现类就可以了。

         实例代码: https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/distributed-system/dubbo-spi.md

         ![dubbo的spi机制](C:\Users\guozh\Desktop\java\石杉\dubbo的spi机制.png)

   5. Dubbo的服务治理,服务降级 , 失败重试,超时机制

      1. 服务治理

         1. 调用链路自动生成
         2. 服务访问压力以及时长统计
         3. 调用链路失败监控和报警 , 接口的可用率
         4. 服务分层（避免循环依赖）

      2. 服务降级

         1. 比如说服务 A 调用服务 B，结果服务 B 挂掉了，服务 A 重试几次调用服务 B，还是不行，那么直接降级，走一个备用的逻辑，给用户返回响应.
         2. 实例代码: https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/distributed-system/dubbo-service-management.md

      3. 失败重试和超时机制

         1. 通过timeout 和 retries两个配置

         2. ```
            <dubbo:reference id="xxxx" interface="xx" check="true" async="false" retries="3" timeout="2000"/>
            ```

   6. 网络通信netty

      1. 基于NIO实现的

      2. 服务提供者

         1. Acceptor线程通过Selector组件轮询ServerSocketChannel的网络事件  , 同时ServerSockerChannle会持续监听端口号 , 看有没有消费者netty来建立网络连接.
         2. 消费者通过netty框架与服务提供者的端口号和ServerSocketChannel建立连接 , 每个消费者建立一个SocketChannel对象 . netty会将建立好的连接SocketChannle分配给Processor线程 , 每一个Processor线程通过多路服用轮询组件Selector , 来不断轮询看这些SocketChannel对应的服务消费者有没有发请求过来. 轮询到有请求过来就会解析请求走后面的流程.
         3. 每个Processor可以支撑多个消费者的请求.
         4. 服务响应也是通过Processor线程 , 通过对应消费者的SockerChannel发响应发回到消费者的netty .

      3. 服务消费者

         1. 同提供者类似 ,也是对一个提供者建立一个SocketChannel连接, 一个Processor线程通过Selector轮询多个SocketChannel的网络事件 , 把响应值返回给消费者.

         ![网络通信netty框架原理](C:\Users\guozh\Desktop\java\石杉\网络通信netty框架原理.jpg)

4. 如何设计一个RPC框架

   1. 动态代理  
      1. 消费者和提供者都要实现某个框架的动态代理的, PRC框架的一切细节都在这个动态代理里面实现.调用动态代理的方法.
   2. 服务注册中心
      1. 服务注册,服务发现 . 或者 基于zookeeper .
   3. Cluster层 
      1. 从本地服务注册表根据负载均衡找到要调用的机器列表 .
      2. 负载均衡策略 . 
   4. 调用信息交给协议层 
      1. 协议
      2. 网络通信框架
      3. 序列化和反序列化
   5. 我给大家说个最简单的回答思路：
      - 上来你的服务就得去注册中心注册吧，你是不是得有个注册中心，保留各个服务的信息，可以用 zookeeper 来做，对吧。
      - 然后你的消费者需要去注册中心拿对应的服务信息吧，对吧，而且每个服务可能会存在于多台机器上。
      - 接着你就该发起一次请求了，咋发起？当然是基于动态代理了，你面向接口获取到一个动态代理，这个动态代理就是接口在本地的一个代理，然后这个代理会找到服务对应的机器地址。
      - 然后找哪个机器发送请求？那肯定得有个负载均衡算法了，比如最简单的可以随机轮询是不是。
      - 接着找到一台机器，就可以跟它发送请求了，第一个问题咋发送？你可以说用 netty 了，nio 方式；第二个问题发送啥格式数据？你可以说用 hessian 序列化协议了，或者是别的，对吧。然后请求过去了。
      - 服务器那边一样的，需要针对你自己的服务生成一个动态代理，监听某个网络端口了，然后代理你本地的服务代码。接收到请求的时候，就调用对应的服务代码，对吧。

5. Springcloud底层原理

   1. 注册中心Eureka

      1. 服务注册与发现
         1. 服务注册表 , 二级缓存(ReadWrite缓存+ReadOnly缓存) , 后台有线程会定时将ReadWrite缓存同步给ReadOnly缓存 , 服务发现定时(每隔30s)拉取ReadOnly的缓存 . 
      2. 心跳与故障
         1. 服务注册机器会每30s发送一次心跳 , 服务注册表会记录心跳 , 后台有个心跳线程会定时检查,当发现一定时间内某个机器没有心跳 , 任务机器挂了 , 将该机器剔除服务注册表 , 同事会发指令ReadWrite缓存 , ReadWrite缓存会清空自己 , 然后定时同步线程也会清空ReadOnly缓存 . 当下次的服务发现时会去服务注册表拉取最新的数据更新到两个缓存中.

      ![Eureka注册中心原理](C:\Users\guozh\Desktop\java\石杉\Eureka注册中心原理.jpg)

   2. Ribbon

   3. Feign 

      1. 对一个接口打了一个注解 , 他会针对这个注解标注的接口生成动态代理 , 调用时底层生成http协议格式的请求 , 通过Ribbon 从本地的服务注册列表中根据负载均衡算法获选出一个机器 , 接着对机器发送http请求即可.

   4. Zuul

      1. 配置一下不同请求路径和服务的对应关系 , 把请求直接匹配到服务 , 基于Ribbon , 发请求到指定的机器上去.

6. Dubbo和Springcloud的优缺点

​	1.总结：dubbo优点：深度优化后，基于TCP的RPC调用更加轻量级，速度更快。 dubbo缺点：只是一		套RPC服务框架没有配套设施，需要自己再找其他的组件去做配合使用。 SpringCloud优点：开箱即用，和spring完美搭配，提供一整套分布式系统解决方案。 SpringCloud缺点：基于http请求，较慢。有些组件存在问题（springCloud config） 两者差异：最大的差异在对请求的处理上，一个基于TCP一个基于HTTP。一个是RPC服务框架，一个是分布式系统解决方案。

7. 服务注册中心比较

   1. Eureka集群架构

      1. peer2peer，每个注册中心服务的节点地位相等，会将每次心跳和更新请求同步到每一个节点上，因此并发高了之后，注册中心的内部流量会很大。注册列表的更新方式是通过客户端拉取

   2. Zookeeper集群

      1. master-follower，通过只对主节点进行写，然后由主节点同步到从节点后，主动向节点推送到各个服务节点。时效性较高 .  服务消费者可以去加监听服务列表, ZK会主动通知给消费者服务列表的变动.当有机器新增或者下线, ZK的leader节点先感知到然后同步给Follower节点,Follower节点主动通知服务消费者.

         ![ZooKeeper服务注册与发现原理](C:\Users\guozh\Desktop\java\石杉\ZooKeeper服务注册与发现原理.jpg)

   3. 一致性保障 CP or AP

      1. C:Consisitency(一致性)

         A:Availability(可用性) 

         P:Partition Tolerance(分区容错性) .

         CAP相关文章: https://juejin.im/post/6844903936718012430

         在分布式的环境下，网络无法做到100%可靠，有可能出现故障，因此分区是一个必须的选项，如果选择了CA而放弃了P，若发生分区现象，为了保证C，系统需要禁止写入，此时就与A发生冲突，如果是为了保证A，则会出现正常的分区可以写入数据，有故障的分区不能写入数据，则与C就冲突了。因此分布式系统理论上不可能选择CA架构，而必须选择CP或AP架构。

      2. zk: 基于cp，保证数据的顺序一致性，因此需要牺牲掉一些可用性，例如主节点宕机后，就不再可用（不提供读写服务），需要从从节点中再次选取出主节点后才会继续提供服务。

      3. Eureka：基于ap，保证节点的可用性，在某一些服务节点挂掉之后，其余节点可以继续提供服务，但是因为数据未能同步，所以其它节点提供的数据可能是不一致的, 会确保最终一致性。 这两者之间的差异，都是因为模式造成的，一个是中心化，一个是去中心化。

   4. 服务注册发现的时效性

      1. zk时效性好 , 秒级别可以感知

      2. Eureka , 默认配置比较糟糕 , 服务发现感知到要几十秒 , 甚至分钟级别.

         优化:  

         1. ReadOnly缓存和ReadWrite缓存的同步周期缩短(30s->3s) , eureka.server.responseCacheUpdateIntervalMs = 3000

         2. 服务发现拉取的周期缩短(30s->3s),

            eureka.client.registryFetchIntervalSeconds = 3

         3. 服务心跳上报周期缩短(30s->3s)

            eureka.client.leaseRenewalIntervalInseconds = 3

         4. 心跳检查周期缩短(60s->6s)

            eureka.server.evictionIntervalTimeMs=6000

         5. 心跳超时时间(超过这个时间判定为死亡.90s->9s)

            eureka.instance.leaseExpirationDurationInSeconds= 90

         6. 关闭eureka的自我保护机制(突然网络故障,一定比例机器没有发生心跳,会触发保护机制,保护服务注册表不会被修改 , 源码的bug较多)

            eureka.server.enableSelfPreservation: false

   5. 容量

      1. zk: 不适合大规模的服务实例 , 因为服务上下线的时候会瞬间推送数据通知到所有的其他服务实例 , 一旦达到几千服务实例时 , 会导致网络带宽被大量地占用.
      2. Eureka: 也很难支撑大规模的服务实例 , 因为每个节点收到数据通知都要同步给其他节点 , 相当于每次更新会落到集群的每个节点上 , 如果服务过多 , Eureka整个集群内部流量巨大.
      3. 实际生成部署,会采用比较高的配置的机器来做,8C16G, 16C32G的高配机器来做,基本可以做到每台机器每秒钟支撑几千请求.

   6. 部署上万服务实例 , 服务注册中心如何优化(自研注册中心)

      1. 服务注册表分片存储. 每台机器存储部分的服务注册表,机器不互相同步数据 , 将集群请求分散到多个节点.应对. (高并发)
      2. 每个机器都有自己的Slave机器做备份机器来保证(高可用).
      3. 通过主从节点都写成功了再返回ack(一致性).
      4. 服务消费者 通过代理层去指定的节点拉取部分注册信息，不用每次都拉取集群的全集。

      ![自研注册中心架构](C:\Users\guozh\Desktop\java\石杉\自研注册中心架构.jpg)

   7. 其他注册中心比较

      |       Feature        | Consul                                  | Zookeeper                      | Etcd                  | Eureka                           | SofaRegistry           |
      | :------------------: | :-------------------------------------- | ------------------------------ | --------------------- | -------------------------------- | ---------------------- |
      |     服务健康检查     | 定期healthcheck(http/tcp/script/docker) | 定期心跳保持会话(session) +TTL | 定期refresh(http)+TTL | 定期心跳+TTL;支持自定义healcheck | 定期连接心跳＋锻炼敏感 |
      |        一致性        | raft                                    | ZAB                            | raft                  | 最终一致性BASE                   | 最终一致性BASE         |
      |         cap          | cp                                      |                                |                       |                                  |                        |
      | 使用接口(多语言能力) | 支持http和dns                           | 客户端                         | http/grpc             | 客户端/http                      | 客户端(java)           |
      |      watch支持       | 全量/支持long polling                   | 支持                           | 支持long polling      | 不支持(client定期fetch)          | 支持(服务端推送)       |
      |         安全         | acl/https                               | acl                            | https支持(弱)         | -                                | acl                    |
      |   spring cloud集成   | 支持                                    | 支持                           | 支持                  | 支持                             | 支持                   |

   

8.网关

1. 网关的作用:

   1. 动态路由 , 负载均衡: 新开发某个服务 , 动态把请求路径和服务的映射关系加载到网关;服务增减机器,网关自动热感知.
   2. 灰度发布 . 可以调整流量比例到新代码的机器上.比如默认是50%的流量到新机器,如果新代码有问题,50%的服务就不可用了,可以通过网关来调整流量的比例 , 逐步扩大灰度比例 . 降低新代码上线的影响.
   3. 鉴权认证
   4. 接口性能监控 . 每个api接口的RT , QPS , 成功率等.
   5. 系统日志
   6. 限流熔断
   7. 数据缓存 . 某些接口的响应做缓存

2. 网关的技术选型

   1. Kong : 依托于Nginx实现，OpenResty，lua实现的模块，现成的一些插件，可以直接使用 . Nginx抗高并发的能力很强，少数几台机器部署一下，就可以抗很高的并发，精通Nginx源码，很难，c语言，很难从Nginx内核层面去做一些二次开发和源码定制
   2. Zuul : Spring cloud , 基于java开发,核心网关功能比较简单 , 但是比如灰度发布 , 限流 , 动态路由之类的都需要二次开发. 高并发能力不强.
   3. 自研网关: Java技术栈为主的大厂，很多其实用Java、Servlet、Netty来开发高并发、高性能的网关系统，自己可以把控一切

3. 动态路由的实现

   1. 动态路由实现: 可以使用第三方组件保存路由关系，然后在网关里面通过定时任务去定时刷新组件中保存的路由信息。 因此就可以基于mqsql去做路由关系的保存，然后通过后台管理系统去操作db，再由网关去定时查询db更新路由表，实现动态路由效果。 
   2. 代码实现: C:\Users\guozh\Desktop\java\石杉\代码2\zuul-gateway\src\main\java\com\zhss\demo\zuul\gateway 中

4. 网关抗住每秒10w的高并发访问 ,如何优化

   1. zuul集群部署  , 前面有一层Ngnix反向代理 , 前面再有一层LVS负载均衡层.

      LVS是Linux virtual 
      server的缩写，是一个高可用性、高性能的虚拟服务器集群系统。主要针对高可伸缩、高可用网络服务的需求，给出了基于IP层和基于内容请求分发的负载平衡调度解决方法，并在Linux内核中实现了这些方法，将一组服务器构成一个实现可伸缩的、高可用网络服务的虚拟服务器。

   2. zuul网关部署机器,部署8C16G , 每秒几千请求不是问题 . 10w请求要几十台网关机器

   3. 生产级的网关应该具备上面的几个特点和功能.需要二次开发. 动态路由/灰度发布/鉴权认证/限流熔断

5. 如何基于网关实现灰度发布

   1. 开发流程： 首先自己建一张表，存入具体uri以及是否灰度发布的一些信息，然后搞一张映射表。 启动个线程每个多少时间就去刷新数据写到concurrenthashmap里面。 接着搞一个filter继承ZuulFilter，重写里面几个函数，其中shouldFilter根据返回值去判断执不执行run。 因此再should里面遍历map去看这次请求是否有开启灰度发布，如果有就执行run里面的逻辑，就自定义一些分发逻辑，这里用的时通过version去判断和分发。 2、灰度发布流程 首先通过后台系统更改灰度发布标识，后台线程更新了map后，就会去执行根据version分发的策略，将少部分流量分发到new上，然后监控和对应的后台，如果没问题，就更改为current，全线上线，最后将灰度发布表示改回来。
   2. 代码实现:  C:\Users\guozh\Desktop\java\石杉\代码 3\zuul-gateway\src\main\java\com\zhss\demo\zuul\gateway 里面 GrayRelease*的三个文件.

6. 公司的网关mbgw的架构图

   ![公司网关架构图](C:\Users\guozh\Desktop\java\石杉\公司网关架构图.jpg)



9.分布系统实践问题

1. 各服务在生产环境如何部署

   1. 中小型公司，一般服务拆分大概在十几二十个，那么相对来说比较好部署。

      注册中心，4核8G的机器，可以抗住每秒大概1000左右的请求，那么部署两台，就完全足够了。另外部署两台还可以作为高可用的冗余，相关的优化参数可以调到很小，让服务的发现，服务注册，服务异常等等信息的时效性很高。 

      网关的话，4核8G的机器，也是差不多能抗1000左右，但是一般会部署3-4机器，保证高可用的同时也可以降低每个网关系统的压力，通常在网关之前还会用ngx的反向代理+LVS负载均衡。 

      数据库，16核32G的机器部署mysql，高峰期可以抗住三四千的请求。 

      以上是对应机器配置的相对经验值，如果要求对应的qps达到几千几万的话。需要一个个模块再次进行优化

   2. 服务的高峰QPS是多少? 压测工具最大QPS是多少

      1. 可以在代码里,家加一些metrics统计机制. 对核心接口,用AtomicLong统计一下每分钟的请求量,成功次数,失败次数,在内存里做一些计数 . 
      2. 统计每个接口的耗时RT , TP99 = 100ms (99%的接口请求耗时在100ms以内), TP95 也是同理. 
      3. 百度java压测工具 , 开源可用的 . 如果1000/s发送压测请求 , 然后800/s被处理 . 200/s的请求被阻塞,压测工具可以感知到.

   3. 如果访问量增加十倍 , 考虑过扩容方案么

      1. 网关直接多部署10倍的机器 . 改一下nginx里面的方向代理.
      2. 服务扩容 , 加机器 , 服务会自动注册 感知到.
      3. 升级成几百个服务实例 , eureka机器可以考虑升级成8C16G的机器 , 可以抗每秒上千请求 , 横向扩容eureka用处不大 , 因为每台机器都是要保存全部的注册列表.
      4. 数据库 , 每秒高峰期几千请求 , 可以考虑给单个数据库提高配置 , 32C128G机器 , 可以抗几千并发.

2. 生产环境的超时和重试参数

   1. Spring cloud项目第一次启动的时候 , 人家调用经常会出现timeout , 是因为第一次请求的时候会去初始化Ribbon组件 , 初始化组件比较耗时 , 比较容易导致超时. 通过配置参数让服务启动时组件就初始化.

      ribbon.eager-load.enabled:true

      zuul.ribbon.eager-load.enable:true

   2. 配置超时和重试参数:

      ribbon.ConnecTimeout: 1000

      ribbon.ReadTimeout: 1000

      ribbon.OkToRetryOnAllOperations: true

      ribbon.MaxAutoRetries: 1  (重试目标机器1次)

      ribbon.MaxAutoRetriesNextServer:1  (目标机器重试失败换一台机器重试一次)

   3. 服务重试 , 防止服务重复下单的问题 , 接口的幂等性

      1. 如果是插入类型的请求：可以通过db的唯一键去做，如果插入失败则说明已存在，直接丢弃或者其他逻辑。或者用redis(接口+请求参数)拼成一个唯一的key，检查这个key是否存在，如果存在就丢弃或者其他逻辑.

      2. 如果是更新类型的请求 : 可以将请求过程分为几个节点，在各个阶段进行对应的幂等性保证 , 例如老师讲的前后拦截器，执行逻辑前，检查redis唯一key的值，如果是1说明已被成功执行，直接不做处理了；如果是0说明有同样的请求在执行，但是未完成，这时可以直接执行也可以等一段时间再检查再执行。当请求处理过程中，增加必要的异常处理，如果异常就回滚不修改key的值；如果执行成功，检查key值是否已被修改为1，已被修改就回滚，如果不能回滚就需要执行一些数据恢复的措施。如果要求不允许第二个请求执行逻辑，就在进入方法的时候就不允许执行了，不过这样吞吐量会降低。 我的思路跟下面有位同学的思路一样，不过通过注解去标识需要保证幂等的设计感觉很棒。

         也可用通过给数据加独占锁(select * from table for update no wait) , 来保证改数据只被一个请求在修改.

3. 分布式服务接口请求的顺序性如何保证？

   1. 个人建议是，你们从业务逻辑上设计的这个系统最好是不需要这种顺序性的保证，因为一旦引入顺序性保障，比如使用**分布式锁**，会**导致系统复杂度上升**，而且会带来**效率低下**，热点数据压力过大等问题。
   2. 方案:
      1. 首先你得用 dubbo 的一致性 hash 负载均衡策略，将比如某一个订单 id 对应的请求都给分发到某个机器上去，接着就是在那个机器上，因为可能还是多线程并发执行的，你可能得立即将某个订单 id 对应的请求扔一个**内存队列**里去，强制排队，这样来确保他们的顺序性。 https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/distributed-system/distributed-system-request-sequence.md
      2. 1.HASH分发，将需要保证顺序的请求打到同一台服务器上。 2.引入消息队列 3.分布式锁，请求携带标识，序列号等。
      3. 接入服务可以用redis毫秒级或版本号有序列表排序，系统根据有序列表中的数据，顺序性消费

4. 画一下系统链路图 , 说一下分布式架构存在的问题

   1. 分布式事务 , 核心链路保证数据一致性

      1. 两阶段提交方案 / XA方案:

         1. 事务管理器 , 先询问每一个系统是否能执行 , 如果都可以执行 , 再进入第二阶段一次每个系统去执行. 如果其中一个不 能执行 , 就取消事务的执行. 常见于单个系统跨多个库的分布式事务(现在分布式系统不允许这么做了) , 因为严重依赖与数据库层面来搞定复杂的事务,效率低,不适合高并发场景. 基于spring + JTA就能实现.

      2. TCC方案: Try/Confirm/Cancel

         1. Try阶段: 对各个服务的资源做检测以及对资源进行锁定或者预留
         2. Confirm阶段: 在各个服务中执行实际的操作
         3. Cancel阶段: 如果任务一个服务执行报错 , 就要进行补偿 , 就是执行已经成功的业务逻辑的回滚操作.
         4. 很少有人用,比较依赖自己写代码来回滚补偿 , 业务代码比较难维护. 比较适合的场景: 一致性要求太高了,比如资金类的场景 , 可以用TCC方案 , 自己编写大量的业务逻辑 , 自己判断一个事务中的各个环节是否ok , 不ok就执行补偿/回滚代码. 最好每个系统执行时间比较短.

      3. 本地消息表方案

         1. A系统在自己本地的一个事务里面操作同时 , 插入一条数据到消息表.
         2. 消息表有个后台不断轮询 , 去执行消息(调用系统B).
         3. 系统B自己需要保证幂等性 , 如果B处理成功了 ,返回成功 , 系统A更改消息表中的状态为已完成 , 继续之后的业务逻辑. 如果B处理异常或者超时 , A的后台线程会定时轮询未完成的消息来执行 , 知道系统B成功为止.
         4. 方案缺陷: 严重依赖于数据库的消息表来管理事务的 , 如果是高并发场景有问题,数据库扛不住.

      4. 可靠消息最终一致性方案

         1. 不要用本地消息表了 , 直接基于MQ来实现事务  , 比如阿里的RoceketMq(3.2.6版本之前的都有回调的接口);

         2. 过程:

            1. A系统先发送一个prepared消息到MQ , 如果这个prepared消息发送失败那么直接取消不执行了.

            2. 如果这个消息发送成功过了 , 那么接着执行本地事务 , 执行成功之后给MQ发送confirm消息. 如果执行失败了就告诉MQ回滚消息 . 

            3. 如果发送了确认消息 ,B系统会收到确认消息 , 然后执行本地事务.

            4. MQ会自动定时轮询所有prepared消息回调你的接口,询问A系统这个消息是不是本地事务失败了 , 没有发送确认消息 , 是继续重试还是回滚 ? 这里A系统可以查一下数据库看事务是否执行失败了, 如果回滚了 , 那么这里也回滚 , 如果没有回滚 , 那要重新发一次confirm消息.. 这个就是避免可能本地事务执行成功了 , 但confirm的消息发送失败了.

            5. 如果B系统执行的事务失败了怎么办? B系统自身需要具备一套失败重试的机制 , 进行失败重试 ; 如果没有的话B系统可以通过MQ的相关机制让MQ重新发送消息 ; 也可以通过ZK , A系统发完消息之后一直监听ZK上的一个值 , B如果失败了 , 通知ZK , 然后ZK反过来通知A系统 , A系统把confirm消息再发一遍. 在这里B系统一定要保证自己的幂等性.

               ![分布式事务-可靠消息最终一致性方案](C:\Users\guozh\Desktop\java\石杉\分布式事务-可靠消息最终一致性方案.jpg)

         3. 订单服务的可靠消息最终一致性方案(上述过程细化):

            整个订单服务可以分为两个链路 , 一个是核心链路(订单业务) , 一个是非核心链路(wms发货服务),整个流程:

            1. 先向RocketMQ发送half message . (为什么不把发送ma放在核心交易链路之后? 如果放在核心链路之后 , 有可能发送消息失败,这样导致后序操作无法进行.之前发半消息的话 , MQ会通过回调反复确认核心链路的状态. )
            2. MQ返回成功 , half message在MQ里面有持久化的记录.
            3. 调用核心链路.
            4. 核心链路如果失败 , 走失败的逻辑 : 调用支付服务进行退款 , 更改订单的状态为取消 , 给MQ发送rollback消息废弃掉刚刚half message消息.
            5. 核心链路成功 , 就给MQ发送commit message让消费者继续消费.
            6. 在half message等待期间,一直没有commit/rolback的消息 , MQ会有后台线程来轮询,走回调去查询状态.
            7. 消费者收到消息,消费完成后回复MQ一个ack , 如果消费失败了 , MQ会重新投递或者换一个机器投递消息.

         ![分布式事务-订单系统可靠消息最终一致性原理](C:\Users\guozh\Desktop\java\石杉\分布式事务-订单系统可靠消息最终一致性原理.jpg)

         

      5. 一般分布式事务常用的是TCC和可靠消息一致性这两种思路。一个要求强一致，一个要求最终一致。强一致主要用于核心模块，例如交易/订单等等。最终一致一般用于边缘模块例如库存，通过mq去通知，保证最终一致性，也可以业务解耦。

      6. TCC事务框架 , seata框架(阿里的),支持dubbo和spring cloud

         1. seata 的使用demo: 直接在github页面上下载：[https://github.com/seata/seata-samples](https://github.com/seata/seata-samples%EF%BC%8C%E5%BB%BA%E8%AE%AE%E8%BF%99%E7%A7%8D%E6%96%B9%E5%BC%8F%EF%BC%8C%E6%AF%94%E8%BE%83%E5%BF%AB%E4%B8%80%E7%82%B9%EF%BC%8Cgit) , 

         2. 然后先要下载一个seata-server到本地，在这里下载：[https://github.com/seata/seata/releases](https://github.com/seata/seata/releases%EF%BC%8C%E7%84%B6%E5%90%8E%E5%90%AF%E5%8A%A8%E8%B5%B7%E6%9D%A5%EF%BC%8C%E8%BF%99%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%E4%B8%AD%E5%BF%83%EF%BC%8C%E8%B4%9F%E8%B4%A3%E7%BB%B4%E6%8A%A4%E6%AF%8F%E4%B8%80%E4%B8%AA%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E7%8A%B6%E6%80%81%EF%BC%8C%E8%A7%A6%E5%8F%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E6%8F%90%E4%BA%A4%E5%92%8C%E5%9B%9E%E6%BB%9A) , 然后启动起来，这是分布式事务管理中心，负责维护每一个分布式事务的状态，触发分布式事务的提交和回滚.

         3. seata-server.bat -h 127.0.0.1 -p 8091 -m file

            直接把Spring Cloud版本的例子运行起来，观察一下依赖、配置和代码，以后自己在系统里使用直接仿照即可，eureka、account、order、storage、business，依次运行起来，修改一些配置，比如说数据库连接配置

            但是任何一个服务报错之后，seata这个分布式事务的框架会感知到，自动触发所有服务之前做的数据库操作全部进行回滚

         4. seata框架的实现原理

            1. 在seata中存在以下角色： 
               1. Transaction Coordinator（TC）:协调器，单独的一个server。维护全局和分支事务的状态，驱动全局事务的提交或回滚。 
               2. Transaction Manager(TM)：全局事务的发起者，负责开始/提交/回滚一个全局事务。（对应订单服务）. 
               3. Resource Manager(RM)：管理分支事务（注册分支事务/状态/提交/回滚），并负责与TC通讯。
            2. 整个使用seata进行分布式事务管理的生命周期:
               1. TM向TC发起全局事务 , TC返回XID作为本次全局事务标识.
               2. XID通过链路向下传播 , RM将本地的事务注册到TC中表示为XID的全局事务中的一个分支事务.
               3. 当执行成功 , 后由TM向TC请求标识为XID的全局事务的提交. 当有一个服务失败时,TM会通过返回值感知到,然后告诉TC将XID的全局事务回滚掉. 由TC来驱动所有的分支事务进行提交/回滚.

            ![seata中tcc处理流程图](C:\Users\guozh\Desktop\java\石杉\seata中tcc处理流程图.png)

         5. TCC事务方案的性能瓶颈在哪里 , 能支撑高并发交易场景么

            1. 每个TM和RM要和TC进行频繁的网络通信 , 会带来系能的消耗 , 比如一个本地事务要耗时100ms , 引入分布式事务之后会耗时200ms
            2. TC(seata-server)中对事务日志和状态的存储 , 如果要支持高并发的话 ,TC也需要进行横向扩容 , 同时TC背后的db也要进行一些分库分表之类的优化.

      7. 可靠消息一致性方案 , 基于ActiveMQ或者RabbitMQ自己开发一下可靠消息服务, 收到一个消息后尝试投递到MQ上去 , 投递失败重试投递 , 当消费者消费成功后必须回调接口来通知处理成功 , 如果一段时间后生产者没有收到成功的消息,要重试投递消息到MQ. 

         也可以用RocketMQ直接提供了分布式事务的支持.

   2. 分布式锁 

      1. 当多个服务需要竞争一个单体资源时，可以考虑加上分布式锁。如果并发量高的话，可以考虑拆分掉那个单体资源，50个拆成5个10个资源，从而缩小锁的粒度，提高吞吐量。

      2. Redis最普通的分布式锁

         1. 最普通的实现方式，就是在 redis 里使用 `setnx` 命令创建一个 key，这样就算加锁。

            ```
            SET key my_random_value NX PX 30000
            ```

            执行这个命令就 ok。

            - `NX`：表示只有 `key` 不存在的时候才会设置成功。（如果此时 redis 中存在这个 key，那么设置失败，返回 `nil`）
            - `PX 30000`：意思是 30s 后锁自动释放。别人创建的时候如果发现已经有了就不能加锁了。

            释放锁就是删除 key ，但是一般可以用 `lua` 脚本删除，判断 value 一样才删除：

            ```
            -- 删除锁的时候，找到 key 对应的 value，跟自己传过去的 value 做比较，如果是一样的才删除。
            if redis.call("get",KEYS[1]) == ARGV[1] then
                return redis.call("del",KEYS[1])
            else
                return 0
            end
            ```

            ​	为啥要用 `random_value` 随机值呢？因为如果某个客户端A获取到了锁，但是阻塞了很长时间才执行完，比如说超过了 30s，此时可能redis已经自动释放锁了，此时可能别的客户端B已经获取到了这个锁，要是客户端A这个时候直接删除 key 的话就会把B加的锁给删掉会有问题，所以得用随机值加上面的 `lua` 脚本来释放锁。

            ​	这种分布式锁的实现不行的。因为如果是普通的 redis 单实例，那就是单点故障。或者是 redis 普通主从，那 redis  主从异步复制，如果主节点挂了（key 就没有了），key 还没同步到从节点，此时从节点切换为主节点，别人就可以 set key，从而拿到锁。

      3. 基于Redisson框架实现:

         1. 支持redis单实例 , redis哨兵 , redis cluster , redis master-slave等部署架构.

         2. 代码:

            ```java
            RLock lock = redisson.getLock("myLock");
            lock.lock();
            lock.unlock();
            ```

         3. 原理流程图

            ![分布式锁-基于Redisson实现原理图](C:\Users\guozh\Desktop\java\石杉\分布式锁-基于Redisson实现原理图.jpg)

            1. redisson根据hash节点选择一台机器, 发送一段lua脚本到redis上, 用lua脚本是将一堆逻辑封装在lua脚本中 , 保证这段逻辑的原子性. 

            2. lua脚本的逻辑: 先判断key是否已经存在 , 不存在就可以继续加锁 , 然后生成一个当前客户端的hash值为该客户端的id作为value(例如123343-234234-545-321-dcgaga:1) ,然后key-vaule的实行set到redis里数据结构如下  , 设置存活时间默认30s; 加锁成功.

               mylock:

               {

               ​	"123343-234234-545-321-dcgaga:1":1

               }

            3. 当客户端2要进来加锁时 , 也执行同样的一段lua脚本 , 先发现key已经存在 , 然后判断key对应的vaule是否包含了客户端2的id , 显然是不包含的 . 然后客户端2会获取到pttl mylock返回的一个数字 ,代表了myLock锁的剩余生存时间. 此时客户端2会进入一个while循环 , 不停尝试加锁.

            4. watch dog自动延期机制: 客户端1一旦加锁成功就会自动启动一个watchdog线程 , 每隔10s检查一下 , 如果客户端1还持有锁key , 那么就延长锁的生存时间.

            5. 可重入加锁机制:  lua脚本中先判断exits mylock , key已经存在的 , 然后再判断因为mylock的key的hash数据结构中包含客户端1的id , 此时就会执行可重入加锁的逻辑 , 会用:

               incrby mylock 123343-234234-545-321-dcgaga:1 1 

               通过这个指令堆客户端1的加锁次数累加1. 数据结构如下:

               mylock:

               {

               ​	"123343-234234-545-321-dcgaga:1":2

               }

            6. 释放锁机制: 执行lock.unlock() , 每次堆mylock数据结构中的那个加锁次数减1 . 如果发现加锁次数是0 , 说明这个客户端已经不再持有锁了 , 此时用del mylock 指令 , 从redis中删除这个key. 另外的客户端2就可以尝试加锁了.

            7. 缺点: 客户端1在redis master上写入了mylock对应的key-vaule , 但是还没等master-slave完成异步的复制 , master出现的宕机 , slave变成了master , 接着客户端2尝试mylock加锁时在新的redis master上完成了加锁 , 但客户端1也以为自己成功加了锁. 此时系统在业务语义上会出现问题 , 导致脏数据的产生 . 

               所以这就是redis的master-slave架构的主从异步复制导致的, 在master宕机时,可能导致多个客户端同事完成加锁.

      4. RedLock算法

         1. 就是基于redis集群来做的锁 , 假设有一个redis cluster , 有5组redis master-slave节点,然后执行一下步骤:
            1. 获取当前时间戳 , 单位时毫秒
            2. 尝试在每个master节点上加锁 , 过期时间较短 , 一般就几十毫秒.
            3. 尝试在大多数节点(n/2 +１)上建立锁，客户端计算建立好锁的时间 , 如果建立锁的时间小于超时时间 , 就算建立成功了.
            4. 要是锁建立失败了,就一次删除锁.
            5. 只要别人建立一把锁成功 , 其余节点也是不断轮询锁.
         2. 实际用的比较少 , 算法有争议 , 比如过期时间如何设置.

      5. zookeeper的实现

         1. zookeeper有哪些应用场景

            1. 分布式协调 :

               这个其实是 zookeeper 很经典的一个用法，简单来说，就好比，你 A 系统发送个请求到 mq，然后 B 系统消息消费之后处理了。那 A 系统如何知道 B 系统的处理结果？用 zookeeper 就可以实现分布式系统之间的协调工作。A 系统发送请求之后可以在 zookeeper 上**对某个节点的值注册个监听器**，一旦 B 系统处理完了就修改 zookeeper 那个节点的值，A 系统立马就可以收到通知，完美解决。

               ![zk的分布式协调实例图](C:\Users\guozh\Desktop\java\石杉\zk的分布式协调实例图.png)

            2. 分布式锁

               1. 系统A先去zk上获取锁 , 创建了一个临时节点 , 同时判断当前你创建成功的这个节点是不是第一个节点(最小节点) , 如果是 ,获取锁成功 , 临时节点如果创建成功了就属于系统A. (使用临时节点: 系统A挂了 , 就会和zk断开会话 , zk感知到之后就会把A创建的临时节点删除掉,然后通知后面系统来获取锁)

               2. 此时系统B也尝试在zk创建一个同名的临时节点 , 判断自己这个节点是不是最小节点 , 如果不是 , 说明别人已经加锁了 , 系统B加锁失败. 那就找到排在自己前面的节点来监听.

               3. 系统A处理完成释放锁 , 删除掉临时节点就可以.

               4. 一旦临时节点被删除 , zk就会去通知监听节点A的系统B来获取锁.

                  ![分布式锁-基于zookpeer来实现](C:\Users\guozh\Desktop\java\石杉\分布式锁-基于zookpeer来实现.jpg)

               5. demo代码 : https://gitee.com/shishan100/Java-Interview-Advanced/blob/master/docs/distributed-system/distributed-lock-redis-vs-zookeeper.md

               6. 其他zk文章: https://juejin.im/post/6850418115143335943

               7. 基于curator框架:

                  1. 客户端A先在目录下(/lock/product_1_stock)创建一个临时顺序节点00001 , 同事客户端A ,获取目录下的所有节点, 发现自己的节点是所有节点中序号最小的, 加锁成功.

                  2. 客户端B通过curator框架来获取锁 , 会在目录下创建一个临时顺序节点00002, 同目录下的临时节点一定是有顺序的 , 02节点会来看自己是否为目录的第一个节点 , 不是的话加锁失败 , 堆上一个节点加一个watch监听器.

                  3. 客户端A如果想再次加锁(可重入加锁) , 将原节点中的加锁累计次数加一 .

                  4. 客户端A想释放锁 , 将节点中的加锁次数减一 , 当加锁次数为0时, 就释放锁 , 删除临时节点A , 客户端B会收到通知上一个节点被删除 , 此时回来再次尝试加锁 , 加锁成功.

                     ![分布式锁-基于zookpeer的curator框架来实现](C:\Users\guozh\Desktop\java\石杉\分布式锁-基于zookpeer的curator框架来实现.jpg)

               8. zk分布式锁的羊群效应如何解决

                  1. 羊群效应：当几十个节点争抢同一把基于zk的锁时，如果都是监听第一个节点，那么当释放锁时，zk会同时反向通知所有客户端又来重新争抢。 影响：主要是多了很多没必要的请求，从而会加重网络的负载。 
                  2. 解决：就基于curator去做就好了，通过监听上一级节点，降低了争抢次数，还实现了公平锁。 redis：redis因为是客户端自己主动隔一段时间去尝试加锁，所以羊群效应影响不大，因为请求都错开了，而不是一群一拥而上。

               9. zk分布式锁的脑裂问题如果解决

                  1. 脑裂问题:  分布式系统，主控节点有一个Master，此时因为网络故障，导致其他人以为这个Master不可用了，其他节点出现了别的Master，导致集群里有2个Master同时在运行.
                  2. 问题出现：当客户端a与zk之间出现网络故障，zk感知不到客户端a的心跳，那么就会删除对应的临时节点，那么此时监听该临时节点的客户端b就会拿到锁，此时就出现问题了。 
                  3. 问题解决：网络问题是一个比较难解决的事情。修改curator框架源码,对整个父级上个锁标识，但是这样的话一旦宕机就完蛋，后续还需要加上更加复杂的协调控制操作。

            3. 元数据 / 配置信息管理 : https://juejin.im/post/6850418115143335943

            4. HA高可用性:

               这个应该是很常见的，比如 hadoop、hdfs、yarn 等很多大数据系统，都选择基于 zookeeper 来开发 HA 高可用机制，就是一个**重要进程一般会做主备**两个，主进程挂了立马通过 zookeeper 感知到切换到备用进程。

            ![zk的高可用场景](C:\Users\guozh\Desktop\java\石杉\zk的高可用场景.png)

      6. redis分布式锁和zk分布式锁对比

         1. redis锁需要自己不断尝试去获取锁 , 比较消耗性能; zk分布式锁只需要注册一个监听器即可 , 不需要不断轮询 .
         2. redis的客户端如果挂了 , 锁要等到超时时间过了才会释放 , 而zk因为创建的是临时节点 , 只要客户端挂了 , znode就会被zk删除,自动释放锁.
         3. redis集群是AP架构,主从同步是异步的 , 如果同步完成之前主宕机 , 会出现数据不一致的问题 ; zk集群是CP的 , 强一致性的 , 不会存在一致性问题.

      7. 分布式锁抗高并发

         1. 分段加锁 + 合并扣减

         2. 对某个商品下单，对一个分布式锁每秒突然有上万请求过来，都要进行加锁，此时怎么办呢？

            比如你的苹果库存有10000个，此时你在数据库中创建10个库存字段

            一个表里有10个库存字段，stock_01，stock_02，每个库存字段里放1000个库存

            此时这个库存的分布式锁，对应10个key，product_1_stock_01，product_1_stock_02

            请求过来之后，你从10个key随机选择一个key，去加锁就可以了，每秒过来1万个请求，此时他们会对10个库存分段key加锁，每个key就1000个请求，每台服务器就1000个请求而已

            万一说某个库存分段仅仅剩余10个库存了，此时我下订单要买20个苹果，合并扣减库存，你对product_1_stock_5，加锁了，此时查询对应的数据库中的库存，此时库存是10个，不够买20个苹果

            你可以尝试去锁product_1_stock_1，再查询他的库存可能有30个

            此时你就可以下订单，锁定库存的时候，就对product_1_stock_5锁定10个库存，对product_1_stock1锁定10个库存，锁定了20个库存

         3. 疑问: 合并扣减时 , 发现其他分段已经被人加锁了 ,怎么办? 这个时候就得等待别人释放锁，去获取那个锁分段 , 尝试获取其他锁超过一定时间没获取到就返回库存不足然后释放持有的锁.

         4. 库存服务 , 能不能不用分布式锁实现高并发的库存更新?

            1. 大厂一般不用分布式锁 , 采用nosql数据库里面的k-v存储类型(如tair , redis , mongdb) , 然后不查询 ,直接扣 , 扣到负数就回滚库存 , 返回提示给用户 . 然后将本次操作发送给mq , mq交给另外一个服务去慢慢修改关系型数据库里面的数据(异步同步数据库). 这个主要做好一致性保证方法以及两个库之间的数据同步.
            2. 比如nosql扣减库存,然后发消息队列 , 一致性怎么保证? 可以使用redis + lua脚本 , 进行扣减 , 成功后发送mq , 这样做成原子性的操作.

   3. 分布式session方案

      1. session 是啥？浏览器有个 cookie，在一段时间内这个 cookie 都存在，然后每次发请求过来都带上一个特殊的 `jsessionid cookie`，就根据这个东西，在服务端可以维护一个对应的 session 域，里面可以放点数据。

         一般的话只要你没关掉浏览器，cookie 还在，那么对应的那个 session 就在，但是如果 cookie 没了，session 也就没了。常见于什么购物车之类的东西，还有登录状态保存之类的。

      2. tomcat + redis

         1. 就是使用 session 的代码，跟以前一样，还是基于 tomcat 原生的 session 支持即可，然后就是用一个叫做 `Tomcat  RedisSessionManager` 的东西，让所有我们部署的 tomcat 都将 session 数据存储到 redis 即可。
         2. 会与 tomcat 容器重耦合，如果我要将 web 容器迁移成 jetty，难道还要重新把 jetty 都配置一遍？因为上面那种 tomcat + redis 的方式好用，但是会**严重依赖于web容器**，不好将代码移植到其他 web 容器上去，尤其是你要是换了技术栈咋整？比如换成了 spring cloud 或者是 spring boot 之类的呢？

      3. spring session + redis

         1. 配置代码:  https://gitee.com/shishan100/Java-Interview-Advanced/blob/master/docs/distributed-system/distributed-session.md
         2. 给 sping session 配置基于 redis 来存储 session 数据，然后配置了一个 spring session 
            的过滤器，这样的话，session 相关操作都会交给 spring session 来管了。接着在代码中，就用原生的 session 操作，就是直接基于 spring sesion 从 redis 中获取数据了。
         3. 相关文章: https://juejin.im/post/6844903869634478088

   4. 分库分表

      1. 为什么要进行分库分表

         1. 单表的数据量过大会影响sql性能 . 单表的数据不要过大 , 超过1000w就应该考虑拆分了. 保持每个表几百万的数据 , 这样sql跑的不会太慢.

         2. 一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。以及单个库磁盘会有很大压力.

            | #            | 分库分表前                   | 分库分表后                                   |
            | ------------ | ---------------------------- | -------------------------------------------- |
            | 并发支撑情况 | MySQL 单机部署，扛不住高并发 | MySQL从单机到多机，能承受的并发增加了多倍    |
            | 磁盘使用情况 | MySQL 单机磁盘容量几乎撑满   | 拆分为多个库，数据库服务器磁盘使用率大大降低 |
            | SQL 执行性能 | 单表数据量太大，SQL 越跑越慢 | 单表数据量减少，SQL 执行效率明显提升         |

      2. 分库分表的中间件

         1. Sharding-jdbc

            当当开源的，属于 client 层方案，目前已经更名为 [`ShardingSphere`](https://github.com/apache/incubator-shardingsphere)（后文所提到的 `Sharding-jdbc`，等同于 `ShardingSphere`）。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且截至 2019.4，已经推出到了 `4.0.0-RC1`  版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC  事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017  年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也**可以选择的方案**。

         2. Mycat

            基于 Cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 Sharding jdbc 来说，年轻一些，经历的锤炼少一些。

         3. 对比

            1. Sharding-jdbc 这种 client 层方案的**优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高**，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要**耦合** Sharding-jdbc 的依赖；
            2. Mycat 这种 proxy 层方案的**缺点在于需要部署**，自己运维一套中间件，运维成本高，但是**好处在于对于各个项目是透明的**，如果遇到升级之类的都是自己中间件那里搞就行了。

      3. 数据拆分

         1. 垂直拆分: 

            1. 就是**把一个有很多字段的表给拆分成多个表**，**或者是多个库上去**。一般来说，会**将较少的访问频率很高的字段放到一个表里去**，然后**将较多的访问频率很低的字段放到另外一个表里去**。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。
            2. 举例: 把一个大表拆开，订单表、订单支付表、订单商品表。一般在数据库表设计时就会考虑到.

         2. 水平拆分: 

            1. 把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。

               ![数据库的水平拆分](C:\Users\guozh\Desktop\java\石杉\数据库的水平拆分.png)

         3. 表层面的拆分:

            1. 就是分表，将一个表变成 N 个表，就是**让每个表的数据量控制在一定范围内**，保证 SQL 的性能。否则单表数据量越大，SQL 性能就越差。一般是 200 万行左右，不要太多，但是也得看具体你怎么操作，也可能是 500 万，或者是 100 万。你的SQL越复杂，就最好让单表行数越少。

         4. 进行时机:

            1. 垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；
            2. 水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；
            3. 分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都 ok 了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。

         5. 分库分表的方式

            1. range 分发，就是每个库一段连续的数据，这个一般是按比如**时间范围**来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。
            2. hash分发 , 是按照某个字段 hash 一下均匀分散，这个较为常用。根据你指定的某个字段值，比如说 userid，自动路由到对应的库上去，然后再自动路由到对应的表里去。好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。

         6. 评论区: MySQL自带的分区功能慎用，慎用，慎用；垂直分表结合微服务相对比较好搞，水平分表mycat太依赖运维配置了，关联查询不灵活，而且需要各种配置全局表和ER表，DDL甚至DML都比较麻烦，资源比较充裕还是可以考虑现在tidb之类的分布式数据库.

      4. 如何把系统不停机迁移到分库分表?

         1. 双写迁移方案

            1. 修改原来的系统 , 之前写数据的地方 , 同时写老库和新库. 新库就通过数据库中间件写入分库和分表.

            2. 然后将系统部署后 , 用后台数据迁移临时工具 跑起来读老库数据写新库 , 写的时候根据gmt_modified这类时间戳字段判断数据最后的修改时间 ,读出来的数据在新库里没有，或者是比新库的数据新才会写 . 

            3. 导完一轮之后 , 程序自动做一轮校验 对比数据 , 如果有不一样的 , 就针对不一样的从老库再次读出来然后写 , 反复循环 , 直到两个库每个表的数据都完全一直为止.

               ![数据库的双写迁移方案](C:\Users\guozh\Desktop\java\石杉\数据库的双写迁移方案.png)

      5. 如何设计可动态扩容的分库分表方案

         1. 原先的库和表的数量都不变 , 只是增加服务器的数量 , 比如32库32表 , 原来是4台服务器 , 每台机器装8个数据库 , 每个库有32张表 . 最多可以扩展到3台机器, 每个服务器装一个库, 每个库里有32张表. 这样扩容之后程序里直接改一下数据的地址就行.
         2. 步骤
            1. 设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 * 32 表，对于大部分公司来说，可能几年都够了。
            2. 路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表
            3. 扩容的时候，申请增加更多的数据库服务器，装好 mysql，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。
            4. 由 dba 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。
            5. 我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。
            6. 重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。

      6.  分库分表之后全局的id主键怎么生成

         1.  基于单库生成自增id : 单库的性能瓶颈,不适用于高并发.

         2. UUID : 

            1. 不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，作为主键长度不适合。
            2. 信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。
            3. 对MySQL索引不利：作为数据库主键，在InnoDB引擎下，UUID 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作（连续的 ID 可以产生部分顺序写），还有，由于在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 
               树节点到内存，在插入这条记录后会将整个节点写回磁盘，而且也会引起数据位置的频繁变动 ，性能下降明显。

         3. snowflake 算法

            1. snowflake 算法是 twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的  id，1 个 bit 是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id，12 bit 作为序列号。

               - 1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。
               - 41 bit：表示的是时间戳，单位是毫秒。41 bit 可以表示的数字多达 `2^41 - 1`，也就是可以标识 `2^41 - 1` 个毫秒值，换算成年就是表示69年的时间。
               - 10 bit：记录工作机器 id，代表的是这个服务最多可以部署在 2^10台机器上哪，也就是1024台机器。但是 10 bit 里 5 个 bit 代表机房 id，5 个 bit 代表机器 id。意思就是最多代表 `2^5`个机房（32个机房），每个机房里可以代表 `2^5` 个机器（32台机器）。
               - 12 bit：这个是用来记录同一个毫秒内产生的不同 id，12 bit 可以代表的最大正整数是 `2^12 - 1 = 4096`，也就是说可以用这个 12 bit 代表的数字来区分**同一个毫秒内**的 4096 个不同的 id。

               ```
               0 | 0001100 10100010 10111110 10001001 01011100 00 | 10001 | 1 1001 | 0000 00000000
               ```

            2. 优点:

               1. 毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。
               2. 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。
               3. 可以根据自身业务特性分配bit位，非常灵活。

            3. 缺点:

               1. 强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。

                  时间回拨问题：由于机器的时间是动态的调整的，有可能会出现时间跑到之前几毫秒，如果这个时候获取到了这种时间，则会出现数据重复

               2. 机器id分配及回收问题：目前机器id需要每台机器不一样，这样的方式分配需要有方案进行处理，同时也要考虑，如果改机器宕机了，对应的workerId分配后的回收问题.

               3. 机器id上限：机器id是固定的bit，那么也就是对应的机器个数是有上限的，在有些业务场景下，需要所有机器共享同一个业务空间，那么10bit表示的1024台机器是不够的。这种场景可以把获取id功能单独作为一个系统独立出来.

         4. 改进方案1 , Leaf-segment方案: (参考:https://tech.meituan.com/2017/04/21/mt-leaf.html)

            1. 在使用数据库的方案上，做了如下改变 :

               1. 每次获取一个segment(step决定大小)号段的值。用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力。
               2. 各个业务不同的发号需求用biz_tag字段来区分，每个biz-tag的ID获取相互隔离，互不影响。如果以后有性能需求需要对数据库扩容，不需要上述描述的复杂的扩容操作，只需要对biz_tag分库分表就行。

               3. biz_tag用来区分业务，max_id表示该biz_tag目前所被分配的ID号段的最大值，step表示每次分配的号段长度。原来获取ID每次都需要写数据库，现在只需要把step设置得足够大，比如1000。那么只有当1000个号被消耗完了之后才会去重新读写一次数据库从max_id之后数字开始获取。读写数据库的频率从1减小到了1/step.

               4. 表设计:

                  ```sql
                  +-------------+--------------+------+-----+-------------------+-----------------------------+
                  | Field       | Type         | Null | Key | Default           | Extra                       |
                  +-------------+--------------+------+-----+-------------------+-----------------------------+
                  | biz_tag     | varchar(128) | NO   | PRI |                   |                             |
                  | max_id      | bigint(20)   | NO   |     | 1                 |                             |
                  | step        | int(11)      | NO   |     | NULL              |                             |
                  | desc        | varchar(256) | YES  |     | NULL              |                             |
                  | update_time | timestamp    | NO   |     | CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP |
                  +-------------+--------------+------+-----+-------------------+-----------------------------+
                  ```

            2. 优点:

               1. Leaf服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景。
               2. ID号码是趋势递增的8byte的64位数字，满足上述数据库存储的主键要求。
               3. 容灾性高：Leaf服务内部有号段缓存，即使DB宕机，短时间内Leaf仍能正常对外提供服务。
               4. 可以自定义max_id的大小，非常方便业务从原有的ID方式上迁移过来。

            3. 缺点:

               1. ID号码不够随机，能够泄露发号数量的信息，不太安全。容易被竞争对手算出一天的订单量.

               2. TP999数据波动大，当号段使用完之后还是会hang在更新数据库的I/O上，tg999数据会出现偶尔的尖刺。

                  这个可以通过双buffer优化 . Leaf服务内部有两个号段缓存区segment。当前号段已下发10%时，如果下一个号段未更新，则另启一个更新线程去更新下一个号段。当前号段全部下发完后，如果下个号段准备好了则切换到下个号段为当前segment接着下发，循环往复。详见: https://tech.meituan.com/2017/04/21/mt-leaf.html

               3. DB宕机会造成整个系统不可用。

         5. 改进方案二 : leaf - snowflake方案 (参考:https://tech.meituan.com/2017/04/21/mt-leaf.html)

            1. Leaf-snowflake方案完全沿用snowflake方案的bit位设计，即是“1+41+10+12”的方式组装ID号. 改进点: 

               1. 服务规模较大 , workId手动配置成本太高时: 

                  使用Zookeeper持久顺序节点的特性自动对snowflake节点配置wokerID. 

                  除了每次会去ZK拿数据以外，也会在本机文件系统上缓存一个workerID文件。当ZooKeeper出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。这样做到了对三方组件的弱依赖。一定程度上提高了SLA .

               2. 解决时钟回拨问题: 

                  1. 服务启动时先通过zookeeper的上的node记录的时间来校验是否发生了时间回拨.
                  2. 发现后 , 可以做一定期限的等待 , 等时钟自己追上 如果还是小于 , 抛异常/自动摘除本身节点 并报警.

      7. MySQL读写分离的原理 , 主从同步的延时问题

         主库写并发越高 , 从库延长越高 , 经验值: 主库写1000/s从库延长几ms,比如新增1000条数据  ; 主库2000/s , 从库延迟几十ms; 主库写并发达到4000/s,6000/s,8000/s,主库都快死了,从库延迟会有几秒.

         1. 读写分离: 基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。

         2. 主从复制原理:

            1. 主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 
               relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 
               日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的。

               ![mysql主从复制原理](C:\Users\guozh\Desktop\java\石杉\mysql主从复制原理.png)

         3. 主从复制数据丢失问题: 

            1. 如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。
            2. **半同步复制**，用来解决主库数据丢失问题: 也叫 `semi-sync` 复制，指的就是主库写入 binlog 日志之后，就会将**强制**此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到**至少一个从库**的 ack 之后才会认为写操作完成了。

         4. 主从复制的延时问题:

            1. 从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。所以这就是一个非常重要的点了，由于从库从主库拷贝日志以及串行执行 SQL 的特点，在高并发场景下，从库的数据一定会比主库慢一些，是**有延时**的。所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。

            2. 是这个么场景。有个同学是这样写代码逻辑的。先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了  2000/s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。

               我们通过 MySQL 命令：

               ```
               show status
               ```

               查看 `Seconds_Behind_Master`，可以看到从库复制主库的数据落后了几 ms。

            3. 解决方案:

               1. 分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。

               2. 打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。

                  所谓**并行复制**，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后**并行重放不同库的日志**，这是库级别的并行。

               3. 重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。

               4. 如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询**设置直连主库**。**不推荐**这种方法，你要是这么搞，读写分离的意义就丧失了。

   5. 设计一个高可用系统

      ​	HA? 主备切换.

      1. 一些概念	

         1. 资源隔离: 系统里某一块东西故障了 , 不会耗尽系统所有的资源 , 比如线程资源.
         2. 限流: 高并发流量进来 , 比如100w/s , 我只让10w/s进来 , 其他流量都拒绝
         3. 熔断: 系统后端一些依赖挂了 ,比如mysql挂了 , 每次请求都报错,就熔断 , 后续请求过来直接不接收了 , 拒绝访问 , 10min之后再尝试看看mysql恢复了没.
         4. 降级: mysql挂了 , 系统发现了 , 自动降级 , 从内存里存的少量数据 , 继续提供服务.

      2. Hystrix:

         1. 设计原则
            1. 阻止任何一个依赖服务耗尽所有的资源，比如 tomcat 中的所有线程资源。
            2. 避免请求排队和积压，采用限流和 `fail fast` 来控制故障。
            3. 提供 fallback 降级机制来应对故障。
            4. 使用资源隔离技术，比如 `bulkhead`（舱壁隔离技术）、`swimlane`（泳道技术）、`circuit breaker`（断路技术）来限制任何一个依赖服务的故障的影响。
            5. 通过近实时的统计/监控/报警功能，来提高故障发现的速度。
            6. 通过近实时的属性和配置**热修改**功能，来提高故障处理和恢复的速度。
            7. 保护依赖服务调用的所有故障情况，而不仅仅只是网络故障情况。
         2. Hystrix是如何实现他的目标的
            1. 通过HystrixCommand或者HystrixObservableCommand 来封装对外部依赖的访问请求 , 这个访问请求一般对运行在独立的线程中. 
            2. 为每一个依赖服务维护一个独立的线程池 , 或者是semaphore , 当线程池已满时 , 直接拒绝对这个服务的调用.
            3. 对于超出我们设定阈值的服务调用 , 直接进行超时 , 不允许其耗费过长时间阻塞住. 这个超时时间默认是99.5%的访问时间 , 但是一般我们可以自己设置一下.
            4. 对依赖服务的调用的成功次数 , 失败次数 , 拒绝次数 , 超时次数 , 进行统计.
            5. 如果对一个依赖服务的调用失败次数超过了一定的阈值 , 自动进行熔断 , 在一定时间内对该服务的调用直接降级 , 一段时间后再自动尝试恢复.
            6. 当一个服务调用出现失败 , 被拒绝 , 超时 , 短路等异常情况时 , 自动调用fallback降级机制.
            7. 对属性和配置的修改提供近实时的支持.

      3. 大型电商网站系统详情页的架构

         1. 大型电商网站商品详情页的系统设计中，当商品数据发生变更时，会将变更消息压入 MQ 消息队列中。**缓存服务**从消息队列中消费这条消息时，感知到有数据发生变更，便通过调用数据服务接口，获取变更后的数据，然后将整合好的数据推送至  redis 中。Nginx 本地缓存的数据是有一定的时间期限的，比如说 10 分钟，当数据过期之后，它就会从 redis  获取到最新的缓存数据，并且缓存到自己本地。

            用户浏览网页时，动态将 Nginx 本地数据渲染到本地 html 模板并返回给用户。

            虽然没有直接返回 html 页面那么快，但是因为数据在本地缓存，所以也很快，其实耗费的也就是动态渲染一个 html 页面的性能。如果 html模板发生了变更，不需要将所有的页面重新静态化，也不需要发送请求，没有网络请求的开销，直接将数据渲染进最新的 html 页面模板后响应即可。

            ![大型电商网站详情页架构](C:\Users\guozh\Desktop\java\石杉\大型电商网站详情页架构.png)

         2. 如果系统访问量很高，Nginx 本地缓存过期失效了，redis 中的缓存也被 LRU  算法给清理掉了，那么会有较高的访问量，从缓存服务调用商品服务。但如果此时商品服务的接口发生故障，调用出现了延时，缓存服务全部的线程都被这个调用商品服务接口给耗尽了，每个线程去调用商品服务接口的时候，都会卡住很长时间，后面大量的请求过来都会卡在那儿，此时缓存服务没有足够的线程去调用其它一些服务的接口，从而导致整个大量的商品详情页无法正常显示。

            这其实就是一个商品接口服务故障导致缓存服务资源耗尽的现象。

      4. 资源隔离

         1. 利用线程池实现资源隔离

            1. 对某一个依赖服务的全部请求 , 全部隔离到线程池内 , 对商品服务的每次调用请求都封装在一个command里面. 每次该服务的调用请求都是使用线程池内的线程去执行的 , 线程池内线程的个数决定了请求最大会消耗的线程数. 

               缓存服务默认的商品服务线程大小是 10 个，最多就只有 10 个线程去调用商品服务的接口。即使商品服务接口故障了，最多就只有 10 个线程会 hang 死在调用商品服务接口的路上，缓存服务的 tomcat 内其它的线程还是可以用来调用其它的服务，干其它的事情。

            2. 利用 HystrixCommand 获取单条数据

            3. 利用 HystrixObservableCommand 批量获取数据

               1. 示例代码: https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/high-availability/hystrix-thread-pool-isolation.md

         2. 利用信号量实现资源隔离

            1. 信号量的资源隔离只是起到一个开关的作用，比如，服务 A 的信号量大小为 10，那么就是说它同时只允许有 10 个 tomcat 线程来访问服务 A，其它的请求都会被拒绝，从而达到资源隔离和限流保护的作用。
            2. 线程池隔离和信号量隔离的区别
               1. 线程池隔离技术，是用 Hystrix 自己的线程去执行调用 , 控制的是tomcat线程的执行；而信号量隔离技术，是直接让 tomcat 线程去调用依赖服务。信号量隔离，只是一道关卡，信号量有多少，就允许多少个 tomcat 线程通过它，然后去执行。
               2. 使用场景:
                  1. **线程池技术**，适合绝大多数场景，比如说我们对依赖服务的网络请求的调用和访问、需要对调用的 timeout 进行控制（捕捉 timeout 超时异常）。
                  2. **信号量技术**，适合说你的访问不是对外部依赖的访问，而是对内部的一些比较复杂的业务逻辑的访问，并且系统内部的代码，其实不涉及任何的网络请求，那么只要做信号量的普通限流就可以了，因为不需要去捕获 timeout 类似的问题。
            3. 信号量隔离的实例: https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/high-availability/hystrix-semphore-isolation.md

         3. 细粒度的配置

            1. 指定了 HystrixCommand.run() 的资源隔离策略：`THREAD` or `SEMAPHORE`，一种基于线程池，一种基于信号量。

               ```java
               // to use thread isolation
               HystrixCommandProperties.Setter().withExecutionIsolationStrategy(ExecutionIsolationStrategy.THREAD)
               
               // to use semaphore isolation
               HystrixCommandProperties.Setter().withExecutionIsolationStrategy(ExecutionIsolationStrategy.SEMAPHORE)
               ```

            2. command key & command group & command thread pool

               1. **command key** ，代表了一类 command，一般来说，代表了底层的依赖服务的一个接口。

               2. **command group** ，代表了某一个底层的依赖服务，一个依赖服务可能会暴露出来多个接口，每个接口就是一个 command key。command 
                  group 在逻辑上去组织起来一堆 command key 的调用、统计信息、成功次数、timeout 
                  超时次数、失败次数等，可以看到某一个服务整体的一些访问情况。一般来说，根据一个服务区划分出一个线程池，command key 默认都是属于同一个线程池的。

               3. **command thread pool** , command group 对应了一个服务，而这个服务暴露出来的几个接口，访问量很不一样，差异非常之大。你可能就希望在这个服务 command 
                  group 内部，包含的对应多个接口的 command key，做一些细粒度的资源隔离。就是说，对同一个服务的不同接口，使用不同的线程池。如果你的 command key 要用自己的线程池，可以定义自己的 thread pool key .

                  

                  ```java
                  private static final Setter cachedSetter = Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey("ExampleGroup"))
                                                              .andCommandKey(HystrixCommandKey.Factory.asKey("HelloWorld"))
                                                                  .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey("HelloWorldPool"));
                  ```

            3. coreSize

               1. 设置线程池的大小，默认是 10。一般来说，用这个默认的 10 个线程大小就够了。

                  ```java 
                  HystrixThreadPoolProperties.Setter().withCoreSize(int value);
                  ```

            4. queueSizeRejectionThreshold

               1. 如果说线程池中的 10 个线程都在工作中，没有空闲的线程来做其它的事情，此时再有请求过来，会先进入队列积压。如果说队列积压满了，再有请求过来，就直接 reject，拒绝请求，执行 fallback 降级的逻辑，快速返回。这个参数可以热修改，控制队列的最大大小。

               ```java
               HystrixThreadPoolProperties.Setter().withQueueSizeRejectionThreshold(int value);
               ```

            5. maxConcurrentRequests

               1. 设置使用 SEMAPHORE 隔离策略的时候允许访问的最大并发量，超过这个最大并发量，请求直接被 reject。默认值是 10，尽量设置的小一些，因为一旦设置的太大，而且有延时发生，可能瞬间导致 tomcat 本身的线程资源被占满。

               ```java
               HystrixCommandProperties.Setter().withExecutionIsolationSemaphoreMaxConcurrentRequests(int value);
               ```

      5. Hystrix执行时内部原理(8大执行步骤)

         1. 创建command.

            ```java
            // 创建 HystrixCommand
            HystrixCommand hystrixCommand = new HystrixCommand(arg1, arg2);
            
            // 创建 HystrixObservableCommand
            HystrixObservableCommand hystrixObservableCommand = new HystrixObservableCommand(arg1, arg2);
            ```

         2. 调用command执行方法

         3. 检查是否开启缓存

            1. 如果这个 command 开启了请求缓存 Request Cache，而且这个调用的结果在缓存中存在，那么直接从缓存中返回结果。否则，继续往后的步骤。

         4. 检查是否开启了断路器

            1. 检查这个 command 对应的依赖服务是否开启了断路器。如果断路器被打开了，那么 Hystrix 就不会执行这个 command，而是直接去执行 fallback 降级机制，返回降级结果。

         5. 检查线程池/队列/信号量是否已满

            1. 如果这个 command 线程池和队列已满，或者 semaphore 信号量已满，那么也不会执行 command，而是直接去调用 fallback 降级机制，同时发送 reject 信息给断路器统计。

         6. 执行command

            1. 调用 HystrixObservableCommand 对象的 construct() 方法(获取多条结果)，或者 HystrixCommand 的 run() 方法来实际执行这个 command(获取单挑结果)。
            2. 如果是采用线程池方式，并且 HystrixCommand.run() 或者 HystrixObservableCommand.construct() 的执行时间超过了 timeout 时长的话，那么 command 所在的线程会抛出一个 TimeoutException，这时会执行 fallback 降级机制，不会去管 run() 或 construct()返回的值了。另一种情况，如果 command 执行出错抛出了其它异常，那么也会走 fallback 降级。这两种情况下，Hystrix 都会发送异常事件给断路器统计。

         7. 短路健康检查

            1. Hystrix 会把每一个依赖服务的调用成功、失败、Reject、Timeout 等事件发送给 circuit breaker  断路器。断路器就会对这些事件的次数进行统计，根据异常事件发生的比例来决定是否要进行断路（熔断）。如果打开了断路器，那么在接下来一段时间内，会直接断路，返回降级结果。

               如果在之后，断路器尝试执行 command，调用没有出错，返回了正常结果，那么 Hystrix 就会把断路器关闭。

         8. 调用fallback降级机制

            1. 在以下几种情况中，Hystrix 会调用 fallback 降级机制。
               - 断路器处于打开状态；
               - 线程池/队列/semaphore满了；
               - command 执行超时；
               - run() 或者 construct() 抛出异常。
            2. 一般在降级机制中，都建议给出一些默认的返回值，比如静态的一些代码逻辑，或者从内存中的缓存中提取一些数据，在这里尽量不要再进行网络请求了。

            ![Hystrix的8个执行步骤](C:\Users\guozh\Desktop\java\石杉\Hystrix的8个执行步骤.jpg)

      6. request cache缓存技术

         1. 首先，有一个概念，叫做 Request Context 请求上下文，一般来说，在一个 web 应用中，如果我们用到了  Hystrix，我们会在一个 filter  里面，对每一个请求都施加一个请求上下文。就是说，每一次请求，就是一次请求上下文。然后在这次请求上下文中，我们会去执行 N 多代码，调用 N  多依赖服务，有的依赖服务可能还会调用好几次。
         2. 在一次请求上下文中，如果有多个  command，参数都是一样的，调用的接口也是一样的，而结果可以认为也是一样的。那么这个时候，我们可以让第一个 command  执行返回的结果缓存在内存中，然后这个请求上下文后续的其它对这个依赖的调用全部从内存中取出缓存结果就可以了。这样的话，好处在于不用在一次请求上下文中反复多次执行一样的 command，**避免重复执行网络请求，提升整个请求的性能**。
         3. 举个栗子。比如说我们在一次请求上下文中，请求获取 productId 为 1 的数据，第一次缓存中没有，那么会从商品服务中获取数据，返回最新数据结果，同时将数据缓存在内存中。后续同一次请求上下文中，如果还有获取 productId 为 1 的数据的请求，直接从缓存中取就好了。
         4. 实例demo : https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/high-availability/hystrix-request-cache.md

      7. fallback降级机制

         1. Hystrix 出现以下四种情况，都会去调用 fallback 降级机制：
            - 断路器处于打开的状态。
            - 资源池已满（线程池+队列 / 信号量）。
            - Hystrix 调用各种接口，或者访问外部依赖，比如 MySQL、Redis、Zookeeper、Kafka 等等，出现了任何异常的情况。
            - 访问外部依赖的时候，访问时间过长，报了 TimeoutException 异常。
         2. 两种经典的降级机制
            1. 纯内存数据
               在降级逻辑中，你可以在内存中维护一个 ehcache，作为一个纯内存的基于 LRU 自动清理的缓存，让数据放在缓存内。如果说外部依赖有异常，fallback 这里直接尝试从 ehcache 中获取数据。
            2. 默认值
               fallback 降级逻辑中，也可以直接返回一个默认值。
         3. 示例代码:
            1. 在 `HystrixCommand`，降级逻辑的书写，是通过实现 getFallback() 接口；而在 `HystrixObservableCommand` 中，则是实现 resumeWithFallback() 方法。
            2. demo : https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/high-availability/hystrix-fallback.md

      8. 断路器配置

         1. Enable	

            1. 控制是否允许断路器工作，包括跟踪依赖服务调用的健康状况，以及对异常情况过多时是否允许触发断路。默认值是 `true`。

               ```java
               HystrixCommandProperties.Setter()
                   .withCircuitBreakerEnabled(boolean)
               ```

         2.  RequestVolumeThreshold

            1. 表示在滑动窗口中，至少有多少个请求，才可能触发断路。Hystrix 经过断路器的流量超过了一定的阈值，才有可能触发断路。比如说，要求在 10s 内经过断路器的流量必须达到 20 个，而实际经过断路器的流量才 10 个，那么根本不会去判断要不要断路。

               ```java
               HystrixCommandProperties.Setter()
                   .withCircuitBreakerRequestVolumeThreshold(int)
               ```

         3. ErrorThresholdPercentage

            1. 表示异常比例达到多少，才会触发断路，默认值是 50(%)。如果断路器统计到的异常调用的占比超过了一定的阈值，比如说在 10s 内，经过断路器的流量达到了 30 个，同时其中异常访问的数量也达到了一定的比例，比如 60% 的请求都是异常（报错 / 超时 / reject），就会开启断路。

               ```java
               HystrixCommandProperties.Setter()
                   .withCircuitBreakerErrorThresholdPercentage(int)
               ```

         4. SleepWindowInMilliseconds

            1. 断路开启，也就是由 close 转换到 open 状态（close -> open）。那么之后在 `SleepWindowInMilliseconds` 时间内，所有经过该断路器的请求全部都会被断路，不调用后端服务，直接走 fallback 降级机制。

               而在该参数时间过后，断路器会变为 `half-open` 半开闭状态，尝试让一条请求经过断路器，看能不能正常调用。如果调用成功了，那么就自动恢复，断路器转为 close 状态。

               ```java
               HystrixCommandProperties.Setter()
                   .withCircuitBreakerSleepWindowInMilliseconds(int)
               ```

         5. 示例demo: https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/high-availability/hystrix-circuit-breaker.md

      9. 限流

         1. Hystrix 通过判断线程池或者信号量是否已满，超出容量的请求，直接 Reject 走降级，从而达到限流的作用。
         2. 限流是限制对后端的服务的访问量，比如说你对 MySQL、Redis、Zookeeper 以及其它各种后端中间件的资源的访问的限制，其实是为了避免过大的流量直接打死后端的服务。

      10. 超时设置

          1. 般来说，在调用依赖服务的接口的时候，比较常见的一个问题就是**超时**。超时是在一个复杂的分布式系统中，导致系统不稳定，或者系统抖动。出现大量超时，线程资源会被 hang 死，从而导致吞吐量大幅度下降，甚至服务崩溃。

          2. `TimeoutMilliseconds` 默认值是 1000，也就是 1000ms。

             ```java
             HystrixCommandProperties.Setter()
                 ..withExecutionTimeoutInMilliseconds(int)
             ```

          3. TimeoutEnabled 这个参数用于控制是否要打开 timeout 机制，默认值是 true。

             ```java
             HystrixCommandProperties.Setter()
                 .withExecutionTimeoutEnabled(boolean)
             ```

6. 









<h3 id="第三季">第三季</h3> 

1. HashMap相关

   1. hashmap的底层数据结构

      1. 数组+链表 / 数组+红黑树

   2. hash算法和寻址算法如何优化的

      1. hash算法优化:  (h = key.hashCode()) ^ (h >>> 16);
         1. 先将原hash值右移16位 , 然后与原hash值做异或运算. 让原来hash的高低16位进行了异或 , 让新hash的低16位同时保持了老hash的高低16位的特征. 
         2. 因为后序与(n-1)做&运算 , n-1一般不会太大,高16位都会是0 , 主要是低16位做运算 , 高16位没有参与到整个算法中. 所以新hash的低16位保留了高低16位的特征会避免一些hash冲突.
      2. 寻址算法优化:  hash & (n - 1) 代替 hash % n
         1. hash值与n(数组长度) - 1 做与&运算 . 取模运算性能较差, 并且还要考虑对负数进行额外处理 , 当数组长度是2的n次方时 , hash&(n-1)与hash对n取模效果是等价的 , &运算二进制运算性能更高 .
         2. 在初始化时 , 如果数组的长度输入其他数字，它初始化的时候会调用一个roundUpToPowerOf2方法，就是把它调整为2的幂 . 

   3. 为什么数组容量会是2的倍数，以及扩容为什么是扩成两倍

      1. 可以减少碰撞几率，2的倍数 -1 得到值所有位都是1，和计算值相与后能保证结果单一，如果位上的0越多，碰撞概率越大 举个例子。。 比如容量是2的4次方 减1就是 1111. 那么计算值1110过来和他相与， 结果是1110，另一个计算值1111和他相与结果仍是1111 各自结果不一样 不会碰撞 如果容量不是2的4次方 比如15 减1就是1110. 那么计算值1110过来和他相与， 结果是1110，另一个计算值1111和他相与结果是1110 跟前一个一样 发生碰撞了.

   4. 如何解决hash碰撞问题

      1. HashMap在hash碰撞的时候会形成链表，当链表长度超过8，并且当前数组长度大于64的时候才会转化为红黑树结构。这样做的原因是红黑树的查询复杂度是log（n），而链表的复杂度是O(n)。而当HashMap的红黑树的元素小于6时重新转化为链表结构。

         并不是链表的长度超过了默认的阈值8时，就一定转树状结构，还要判断数组的长度是否已经经过了扩容。MIN_TREEIFY_CAPACITY的值是64，就是说如果你的数组没有经过扩容操作的情况下，如果链表长度已经超过8了， 此时不转树状结构，而是进行数组扩容，数组扩容时会重新散列，将链表的节点均匀的分布，查询效率对比转树状结构也要好.

      2.  问题1：本节题目是：你知道HashMap是如何解决hash碰撞问题的吗？但是通篇好像没讲如何解决hash碰撞。个人理解，没有完美的方法完全解决hash碰撞，jdk是通过上节讲的key哈希值的高16与低16位的抑或的结果来降低hash碰撞的概率。 

      3. 问题2：jdk为什么要选择在链表长度大于8且数组长度大于64的时候转为红黑树，而在红黑树元素小于6时重新回归链表，这里面为什么时8和6呢？不是12，16等其他数字？

         长度为8时树化 长度为6时链表化；hash随机算法足够好(碰撞概率低)，就会遵从泊松分布，达到长度8的概率是 0.00000006 (百万分之六源码里的数据)；当节点的个数小于等于 6 时，红黑树会自动转化成链表，主要还是考虑红黑树的空间成本问题，当节点个数小于等于 6 时，遍历链表也很快，所以红黑树会重新变成链表

      4. 问题3:为什么不直接用红黑树就可以了，还要转化为链表再转化成红黑树呢？

         红黑树得每次增加去除元素都比较复杂,伴随着整个树得左旋右旋还有元素得重新排列,因此,它得出现是为了针对某种特殊情况下得一种优雅得操作.是一种兜底得操作.理论上讲,链表长度超过8得情况发生得概率不超过百万分之六.小概率事件得发生意味着某种错误操作得出现,所以这种情况还会继续发生,为了应对以后要到来得这种恶劣得情况才会转化成红黑树,这个玩意儿其实并不好,理想情况下不发生哈希碰撞得才是最完美得.

   5. HashMap如何进行扩容

      1. 首先是扩容的时机：是在put的最后一步来判断要不要扩容的 , 扩容阈值是数组容量*负载因子 , 2倍扩容，0.75阈值 . 
      2. 扩容过程中涉及rehash操作: 
         1. 如果该桶单元只有一个数据 , 直接 e.hash & (newCap -1 ) 重新计算新桶的位置 .
         2. 如果该桶单元是一个链表 , 每个元素 (e.hash & oldCap) == 0 判断在新桶中的位置是在原位置还是原位置+oldCap 链表的顺序不变 , 会分成两部分 , 一部分在新桶中的原位置 , 另一部分放在新桶中的原位置+oldCap , 可以看到这里并不是避免了定位的与运算 , 而是避免了链表数据进入新桶多次的hash冲突 , 
         3. 如果桶单元是一个红黑树 , (e.hash & oldCap) == 0与桶单元是链表逻辑类似，判断在新桶中的位置是原位置，还是原位置+oldCap，红黑树顺序不变 , 同时将根节点放到桶单元中会判断树中数据长度，小于等于6转换成链表。与链表的原理一致，只是多了转换成链表的判断。

   6. HashMap扩容时的线程安全问题

      1. jdk1.8之前 , 链表才有用头插思路(新增的节点放在头部 ,  这么设计考虑新增的节点会有更大概率被用到) , 但是头插在hashmap扩容(扩容时机: hashmap中元素个数 >= 容量 * 扩容因子)的时候 , 高并发情况下 , 链表在transfer的时候会形成环 , 造成死循环 . jdk1.8之后链表采用尾插法 , 同时在扩容的时候 , 将通过 e.hash & oldCap == 0将链表分为两个部分 , 一分部留在原位置 , 另一部分整体迁移到原位置+oldCap , 这样保留了原来的顺序 , 避免了resize时候的hash碰撞 , 解决了死循环问题.

2. 并发编程

   1. synchoronized关键字原理.

      1. synchronized底层的原理是跟jvm指令和monitor有关系的。每个对象内部都有一个monitor，monitor里面有一个计数器，从0开始的。如果一个线程想对一个对象加锁，就得先获取这个对象关联的monitor的lock锁。如果这个线程想获取monitor的锁，就先判断monitor的计数器是不是为0，如果为0，说明没人获取锁，这个线程就可以获取锁，执行monitorenter指令就是对monitor计数器加1  ; 如果不为0，说明已经有其他线程已经获取了锁，判断该线程是不是已经持有锁的线程 , 如果是支持重入monitor计数器加1 , 如果不是 , 这个线程就必须阻塞等待 . 当线程出synchronized代码片段，执行monitorexit指令就是对monitor计数器减1 .

      2.  synchronized一般会用来做同步控制，已经配合wait/notify做线程间通讯。该关键字在编译成class文件后可以看到对应的语句是monitorEnter与monitorExit，实际上是对应到了OS的互斥量。而1.6之前这个关键字性能不佳，所以在1.6之后引入了一系列的优化，包括偏向锁，轻量级锁，以及自适应自旋锁等等，其实核心理念都是根据当前的并发程度去尽量避免直接用到OS的互斥量去完成同步操作，因为这样会导致线程在用户态与内核态之间来回切换，比较重。

      3. syn底层，除了enter和exit，还有一个变量记录当前持有锁的线程名 ? 偏向锁的时候有，markword中存储了一个指针，指向当前偏向的线程 . 

      4. synchronized保证原子性,可见性,有序性

         1. 底层原理(保证原子性)

            1. java对象都是分为对象头和实例变量两块的，其中实例变量就是大家平时看到的对象里的那些变量数据。然后对象头包含了两块东西，一个是Mark Word（包含hashCode、锁数据、GC数据，等等），另一个是Class Metadata Address（包含了指向类的元数据的指针）.在Mark Word里就有一个指针，是指向了这个对象实例关联的monitor的地址，这个monitor实际上是c++实现的一个ObjectMonitor对象，里面包含了一个owner指针，指向了持有锁的线程 , 还有一个entrylist，想要加锁的线程全部先进入这个entrylist等待获取机会尝试加锁，实际有机会加锁的线程 .

            2. 各个线程首先都进入entryList , 通过monitorenter指令尝试竞争进行加锁，此时竞争加锁是在JDK 1.6以后优化成了基于CAS来进行加锁, 操作count计数器，比如说将count值尝试从0变为1 , 如果成功了,说明获取到锁,将owner指向该线程. 然后释放锁的时候执行monitorexit指令，先是对count计数器递减1，如果为0了就会设置owner为null，不再指向自己，代表自己彻底释放锁.

            3. 如果获取锁的线程执行wait，就会将计数器count递减为0，同时owner设置为null，然后自己进入waitset中等待唤醒，别人获取了锁执行notify的时候就会唤醒waitset中的线程进入entryList尝试竞争获取锁.

               ![synchronized的底层原理](C:\Users\guozh\Desktop\java\石杉\synchronized的底层原理.jpg)

         2. 保证可见性

            1. 在获取到锁,montorenter指令之后,添加Load屏障 , 让线程执行refresh操作 , 到总线嗅探, 对别的处理器更新过的变量,从其他处理器的高速缓存或者主内存中加载到自己的高速缓存中,确保自己看到的是最新的数据.
            2. 在释放锁,monitorexit指令之后,添加store屏障,执行flush操作,把自己处理器更新的变量的值都刷新到高速缓存中或者主内存中.

         3. 保证有序性

            1.  在monitorenter之后,Load屏障之后,加Accquire屏障 , 在monitorexit之前,加Release屏障 , 可以保障同步代码块内部的指令和外部的指令是不能重排的 , 但是同步代码快内部的指令可以重排.

               ```java
               synchronized(this){ -> monitorenter
                   Load内存屏障
                   Accquire内存屏障
                   int a= b;
                   c = 1;
                   Release内存屏障
               } -> monitorexit
               Store内存屏障
               ```

      5. Java虚拟机对锁的优化

         1. 锁消除：JIT编译器通.过逃逸分析等技术发现有些被加锁的代码不会出现线程安全问题，那么动态编译的时候就会消除掉这个加锁的操作。（一般是有些框架里面自己加的synchronized而我们作为程序员并不知道，主要是优化这个） 
         2. 锁粗化：多个同步块合并在一起去执行。
         3. 偏向锁:  偏向于第一个加锁的线程(加偏向标记Bias)，下一次这个线程再来加锁就不用加锁了，提升性能。但是仅仅适用于非常低的并发场景，因为一旦有第二个线程去尝试加锁，就会回收之前分配的偏向标记，升级为轻量级锁.
         4. 轻量级锁: 主要是基于对象头里面的mark word有个轻量级锁指针, 尝试指向持有锁的线程判断一下是不是自己加的锁 , 如果不是自己加的锁 , 那就加锁失败, 说明有别人加了锁, 这时候升级为重量级锁.
         5.  自旋锁: 对于线程持有锁很短的情况 , 采取原地自旋等待, 不会切换线程上下文 (自旋锁).
         6. 重量级锁:  线程持有锁时间很长 , 其他线程长时间获取不到锁,就会切换线程 , 执行其他线程 , 这种自己暂停切换上下文获取锁的方式就是重量级锁. 

   2. CAS的底层原理

      1. CAS（compare and set），先读旧值，再拿旧值与当前值进行比较，如果一致则可进行修改；如果不一致说明，在第一步读取旧值后，有线程将数据修改，则此次修改失败 , 会自旋进行下一次的CAS操作.

      2. cas的原子性是指compare和set这两个过程中保持原子，不会让别人来打扰我的操作，其次为什么还要compare呢，那是因为你在取值范围时候是并发取值，有可能取值都一样，所以第二个线程进来的时候必须进行compare.

         cas主要基于mesi协议中的e，也就是对该变量在硬件级别上加一个独占锁，从而来实现原子性的比较替换。

      3. CAS虽然高效的解决了原子操作问题，但仍然存在三大问题：

         1. 1.ABA问题：如果变量V初次读取的时候值是A，后来变成了B，然后又变成了A，你本来期望的值是第一个A才会设置新值，第二个A跟期望不符合，但却也能设置新值。针对这种情况，java并发包中提供了一个带有标记的原子引用类AtomicStampedReference，它可以通过控制变量值的版本号来保证CAS的正确性，比较两个值的引用是否一致，如果一致，才会设置新值。

         2.  无限循环问题（自旋）：看源码可知，Atomic类设置值的时候会进入一个无限循环，只要不成功，就会不停的循环再次尝试。在高并发时，如果大量线程频繁修改同一个值，可能会导致大量线程执行compareAndSet()方法时需要循环N次才能设置成功，即大量线程执行一个重复的空循环（自旋），造成大量开销。解决无线循环问题可以使用java8中的LongAdder，分段CAS和自动分段迁移。

            为了解决这个问题，JDK8 提供了一个类 LongAdder。把一个变量分成多个变量，让同样多的线程去竞争多个资源，就解决了性能问题。LongAdder  在内部维护了多个 Cell 原子变量，另外，多个线程在争夺同一个 Cell 原子变量时如果失败了，并不是在当前 Cell 变量上一直尝试，而是尝试对其他 Cell 变量进行 CAS 操作。最后，在获取 LongAdder 当前值时，是把所有 Cell 变量的 value 值累加后再加上 base 返回的。https://juejin.im/post/6844904175218737159

         3. 多变量原子问题：只能保证一个共享变量的原子操作。一般的Atomic类，只能保证一个变量的原子性，但如果是多个变量呢？可以用AtomicReference，这个是封装自定义对象的，多个变量可以放一个自定义对象里，然后他会检查这个对象的引用是不是同一个。如果多个线程同时对一个对象变量的引用进行赋值，用AtomicReference的CAS操作可以解决并发冲突问题。 但是如果遇到ABA问题，AtomicReference就无能为力了，需要使用AtomicStampedReference来解决。

   3. ConcurrentHashMap实现线程安全的底层原理

      1.  jdk1.8之前ConcurrentHashMap实现线程安全使用的是分段锁技术，即将一个大数组分成几个小Sequence，当并发put时，处于同一个小Sequence的put操作会串行；不同小Sequence间的put操作不受影响

      2.  jdk1.8ConcurrentHashMap优化了锁的细粒度，并发操作时，当数组元素为null时 , 对数组进行CAS ,若CAS失败,说明此时数组内不为null, 如果数组不为null(是链表或红黑树) , 不走CAS , 先用synchronized锁住 , 再对链表或者红黑树进行增删操作 . 这么设计的原因:

      3. 当数组得位置存放得是链表或者红黑树得引用得时候,此时已经发生了一次哈希冲突了,讲道理,哈希冲突得概率有,但不是很高,链表里面得数据进行添加得时候,运用cas操作是比较麻烦得,因为在多线程情况下往链表里面插数据是会报错得,这个时候只能采用sync锁来进行了.cas是比较后set,那对链表来讲,这个操作是实现不了的,链表在内存中不连续,节点的增加记录下上一个的位置就行,cas操作跟谁比较,怎么比较,hashmap的entry是个单向链表,cas操作中链表的指针如果不为null,那就得到另一个地址在进行比较,在这个过程中,链表长度突破8,对于后续的转化红黑树的操作影响也是非常巨大的.

         总的来讲,就是这个过程中进行cas的消耗,以及对编码的复杂度,都没有sync来的方便快捷,哈希冲突也是个小概率事件,对数组的不同位置加锁或者cas操作,已经完全够用了,

   4. AQS实现原理

      1. Abstract Queue Synchronizer，抽象队列同步器 . JUC包下的ReentrantLock , Semaphore等都是基于AQS做的.

         ![AQS原理图](C:\Users\guozh\Desktop\java\石杉\AQS原理图.png)

      2. 过程: 1、线程1和线程2同时对state变量CAS。2、线程1成功，更新state值为1，然后加锁。3、线程2CAS失败进去等待队列。4、线程1执行完锁住的代码块逻辑后释放锁。5、线程2被唤醒，执行CAS成功，然后加锁，执行锁住的代码块后释放锁。6.如果设置是公平锁 , 线程池3会直接进入等待队列排队, 不会去同线程2争抢.

      3. AQS的原理就是提供了一个volatile修饰的状态变量和一个双向的同步队列。提供模板方法对于独占锁和共享锁的获取和释放，至于公平锁和非公平锁是它的实现类去覆盖抽象方法做的事情，和AQS无关。

      4. ReentLock中的condition:

         1. 在使用Lock之前，我们使用的最多的同步方式应该是synchronized关键字来实现同步。配合Object的wait()、notify()系列方法可以实现等待/通知模式。Condition接口也提供了类似Object的监视器方式，与Lock配合可以实现更细粒度的等待/通知模式.
         2. 调用await()方法，将当前线程加入Condition等待队列中，当前线程释放锁，否则别的线程将无法拿到锁而发生死锁。自旋（while）挂起，不断检测节点是否在同步队列中，如果是则尝试获取锁，否则挂起。当前线程被signal()方法唤醒，被唤醒的线程将从await()方法中的while循环中退出来，然后调用acquireQueue()方法竞争同步状态。
            https://juejin.im/post/6844904030590730253

   5. 线程池的底层原理

      1. 过程:  线程池初始时是没有线程的。首先任务过来会去判断当前线程池里面的线程数是否大于核心线程数，如果小于则新建线程执行任务。执行完任务后的核心线程线程会阻塞，等待任务队列中有任务到来。如果任务过来发现当前线程池里面的线程数等于核心线程数，就将任务放在任务队列中，等待有线程来处理。如果任务队列放满了，就去判断当前线程池里面的线程数是否小于最大线程数，如果小于就新建普通线程执行任务，执行完毕之后会等待空闲时间之后 , 会销毁普通线程；如果等于最大线程数(此时任务队列也放满了)，就执行拒绝策略 . 

      2. 线程池的核心参数配置

         1.  core：核心worker数量，线程池会一直维持这个数量的worker，哪怕没有任务。
         2.  queue：如果core用完了会先将task放到queue中。
         3.  max：如果queue也满了才会再次创建新的worker直到这个max限值。
         4.  reject：如果max都满了，那就执行对应的拒绝策略了。
         5.  keepalive：超过core数量时，而queue又为空，这个时候多余的woker会等待空闲时间后就被回收掉。

      3. 在线程池中使用无界阻塞队列会发生什么问题? 

         1. 同: 在远程服务异常的情况下，使用无界阻塞队列，是否会导致内存异常飙升？
         2. 调用超时，队列变得越来越大，此时会导致内存飙升起来，同时队列里的对象GC无法回收 , 还可能会导致你会OOM，内存溢出. 如果使用有界队列，然后设置max线程数=max那么会导致创建很多线程，也可能导致服务器崩溃。 
         3. 所以要根据具体的场景以及具体的压测数据，来设定这些参数。最后就是我们可以手动去实现一个拒绝策略，将请求持久化一下，然后后台线程去等线程池负载降下来了后再读出来继续执行。\

      4. 线上机器突然宕机 , 线程池的阻塞队列中请求怎么办

         1. 因为请求数据都在内存中的，因此宕机就会丢失，但是我们可以之前将任务落库 , 机器恢复后再重新捞起执行，然后针对不同类型的请求，去做幂等或者去重的一些操作。

      5. ce线程池默认的参数

         1. 核心线程数:80

            最大线程数:400

            线程队列:1000->50

            之前几起的ce堵塞故障，就是因为队列长度设置过长，没有给予最大线程数扩增到400的机会，在队列里hold时，上游就已经超时、请求异常了。我们将队列数改为50，是为了给予更大机会开启最大线程数执行任务的机会

   6. Java内存模型

      1.  java内存模型 :  是对计算机的一个抽象，将整个计算过程分成了6步(read、load、use、assign、store、write)去执行。因为每个线程都对应一个工作内存，所以导致主存中的数据值可能并不是最新的，因此多线程情况下，data++的这个操作就会被覆盖掉。 为什么要有工作内存的？它带来了内存不可见性与伪共享这些问题。是因为CPU的速度远高于内存的读写速度，因此为了充分利用CPU资源，设计了对应的缓存，还有一些其他的加载机制。 避免内存不可见用volatie就行，但是volatile的语义并不能保证data++能达到预期效果，因为它没办法保证这个执行的原子性。

         ![java内存模型](C:\Users\guozh\Desktop\java\石杉\java内存模型.png)

      2. java内存模型的原子性 , 可见性 , 有序性

         1. 可见性: 不同线程并发对同一个数据进行操作是没有可见性的的，会发生数据错误的情况。如果能保证原子性就是在线程1修改了数据后，线程2中缓存的老数据会被过期 , 会从从主内存中获取最新的数据到工作线程进行后续操作。 

         2. 原子性是指：线程1对数据读取并操作是一个原子过程，线程1在处理过程中，其他线程不能对数据进行操作.

         3. 有序性: java虚拟机会对写好的代码进行指令重排，在多线程情况就可能会因为代码顺序调整出现问题。比如线程1判断flag准备数据，线程2判断flag确定是否准备好，依赖准备好的数据进行业务操作。如果指令重排序就可能导致线程1还未准备好数据，线程2就开始执行业务操作，发生错误。有序性是指：通过一定手段，保证不会对代码进行指令重排序.

            重排序是为了提高处理器的运用效率,处理器会保证重排序后执行代码的结果跟重排序前是一样的(单线程环境下)

      3. volatile关键字的原理

         1. volatile主要是用来解决多线程场景下变量的可见性以及顺序性。 

         2. 可见性

            对volatile修饰的变量，执行写操作的话，JVM会发送一条lock前缀指令给CPU，CPU在计算完之后会立即将这个值写回主内存，同时因为有MESI缓存一致性协议，所以各个CPU都会对主内存进行嗅探，主内存中的数据是否被别人修改 .如果发现别人修改了某个主内存，那么CPU就会将自己本地缓存的数据过期掉，然后这个CPU上执行的线程在读取那个变量的时候，就会从主内存重新加载最新的数据了 .

            1. 可见性底层硬件概念

               1.  硬件方面：处理器，寄存器，写缓冲器，高速缓存 , 内存屏障。 

                  MESI协议的实现需要两个机制: flush处理器缓存和refresh处理器缓存.

                  写的过程：处理器在计算完某个变量以后，可能将计算后的值写到以上各个硬件中去，如果该变量加了volatile，会在写操作之后加Store屏障就会走MESI缓存一致性协议，把最新的计算值flush到高速缓存或主存中（硬件实现差异）, 再将该变量更改的消息发送到总线bus中.

                  volatile变量在读操作之前加Load屏障 , 那么在其他处理器在读时候, 会进行refresh操作，就会去总线嗅探该变量的更改，就会到更改了该变量的高速缓存或者主存中去加载最新的变量值，从而保证用来计算的值是最新的.

                  ![java内存模型-volatile可见性底层原理](C:\Users\guozh\Desktop\java\石杉\java内存模型-volatile可见性底层原理.jpg)

         3. 开源代码中使用:

            1. 在很多的开源中间件系统的源码里，大量的使用了volatile，每一个开源中间件系统，或者是大数据系统，都多线程并发，volatile

               ```java
               public class Kafka{
                   private volatile boolean running = true;
                   public void shutdown(){
                   // 别的线程调用shutdown来关闭kafka , 由于 volatile保证了running变量的可见性,主线程会立刻感知到最新值,从而完成关闭.
                       running= false;
                   }
                   public static void main(){
                       // 启动kafka会运行一大堆代码 , 不能直接让其退出
                       Kafka kafka = new Kafka();
                       while(running){
                           ...
                       }
                   }  
               }
               ```

         4. 有序性

            1.  指令重排：两个没有关联关系的代码可能会被打乱顺序去执行，主要原因是为了充分利用CPU的算力。指令重排的不良影响主要发生多线程并发的情况，因此需要用到volatile关键字去保证在volatile变量赋值前的语句的顺序性。 

               1. 发生指令重排的时机: 指令重排有好几个层面都可能发生，从JIT动态编译，再到处理器运算完 , 内存重排序等。 2、指令重排也会遵守一些规则，例如两条互不相关的赋值语句，还有happen-before等等。 3、指令重排在单线程运行的情况下没有什么影响，但是在多线程的场景下会存在一些问题。

               2. JIT编译器对创建对象的指令重排以及单例模式double check实践

                  创建新对象一行语句，可以大致上分为：1、内存分配，2、执行构造函数(比较耗时)，3、赋值引用。在JIT之后可能就顺序就变成了132，可能导致NPE，因此在有一种单例模式double check的时候还需要volatile来防止指令重排导致空指针异常.

               ![单例模式懒汉式代码](C:\Users\guozh\Desktop\java\石杉\单例模式懒汉式代码.jpg)

               3. 处理器指令重排
                  1. 处理器为了提升性能会出现两种重排序情况： 1、指令乱序：指令可能会按照谁先就绪就先执行谁，然后放入重排序处理器，重新整理顺序后再放入高速缓存。 2、猜测执行：可能先执行判断体内的逻辑，在判断条件生效后再采纳原先的计算结果。
               4. 高速缓存和写缓冲器的内存重排序
                  1. 指令在处理的过程中，很可能因为一些内存组件的优化出现重排序的假象。

            2. happens-before：这个主要是由java自身去保证一些场景下代码执行的顺序性，而不用程序员去操心。里面比较重要的就是**volatile变量规则**：对一个volatile变量的写操作先行发生于后面对这个volatile变量的读操作，volatile变量写，再是读，必须保证是先写，再读.

            3. 对于volatile修改变量的读写操作，都会加入内存屏障

               1. 每个volatile写操作前面，加Release屏障，禁止上面的普通写和他重排；每个volatile写操作后面，加StoreLoad屏障，禁止跟下面的volatile读/写重排
               2. 每个volatile读操作前面，加Accquire屏障，禁止下面的普通读和voaltile读重排；每个volatile读操作后面，加LoadStore屏障，禁止下面的普通写和volatile读重排

         5. 关于原子性

            1. 32位Java虚拟机中的long和double变量写操作为何不是原子的？

               1.  long / double类型对应的是8个字节,1个字节时8bit 8*8=64位在32的虚拟机中则被拆分为高低32位,导致对long类型的变量操作不是原子性的 . 如果多个线程同时并发的执行long i = 30，就会导致有的线程在修改i的高32位，有的线程在修改i的低32位，多线程并发给long类型的变量进行赋值操作.

               2. volatile保障原子性只用于一种情况:32位的java虚拟机里 , 对long/double的赋值操作不是原子的 , 加上volatile可以保障原子的. 

                  最根本的原因是32jvm对long类型操作是2次完成的，首先，这种情况是出现在32位多核CPU上，如果是32位单核CPU，是不存在线程调度的，所以也不会有CPU中断这事儿，也就出现不了这种bug。 下面说的过程，都是在32位多核CPU上发生的： 1、CPU对long类型计算，会把long类型放到寄存器中 2、寄存器最大放32位，所以需要将long的二进制分成2段存放 3、接着多核多线程对long类型的两段二进制分别操作 4、线程1修改long的一半二进制，修改完后放到自己的高速缓存，没刷到主存。 5、线程2修改long的同一半二进制，此时重点【线程2并没有拿到线程1修改的那一半最新值】，线程2依然拿到了这个long的旧的一半二进制进行了写操作。 6、最终线程1线程2都操作long的同一半二进制，并且相互不可见时，刷到主存后就必然会导致乱码 这也就是volatile可见性和有序性“变相的”解决了long再32jvm下的原子性问题。

               3. 哪些操作在java规范中是不保证原子性的

                  1.  所有变量的简单赋值写操作，jva语言规范原生给你保证原子性的；特例: 32位java虚拟机里的long/double是不保证赋值写的原子性的；volatile可以解决这个问题；

                  2. 涉及到读取-计算-赋值的复杂操作，volatile是无法保证原子操作的，这个关键字的应用场景也不是用来保证原子性的。

                     i++

                     i = y + 1

                     i = x * y ==> 先把x和y分别从主内存里加载到工作内存里面来，然后再从工作内存里加载出来到处理其执行计算，计算后的结果写回到工作内存里去，最后还要从工作内存里把i的最新的值刷回主内存.

      4. 内存屏障硬件层面的原理

         1. 高速缓存的数据结构: 拉链散列表

            1. 1、高速缓存的底层数据结构是一个拉链散列表，也就是多个bucket。 2、每个bucket挂了很多的cache entry，由tag（对应主存中的地址），cache line(缓存数据)，flag（缓存行状态）组成。 3、在处理器对高速缓存进行读写的时候，会通过变量名执行一个内存地址解码的操作，解码出三个东西：index（哪个bucket）、tag（定位到bucket中具体的一个cacke entry）、offset（找到在cache entry中cache line的相对位置） 4、如果处理器从高速缓存中读不到对应的数据，就会去主存或者其他处理器的高速缓存中读取放到高速缓存中。 5、高速缓存是分层的，L1、L2、L3越靠前的读写速度越快。

               ![高速缓存的结构-拉链散列表](C:\Users\guozh\Desktop\java\石杉\高速缓存的结构-拉链散列表.jpg)

         2. MESI协议(缓存一致性协议)的实现原理

            1. MESI协议规定：对一个共享变量的读操作可以是多个处理器并发执行的，但是如果是对一个共享变量的写操作，只有一个处理器可以执行，其实也会通过排他锁的机制保证就一个处理器能写.

               MESI协议规定: 一组消息，就说各个处理器在操作内存数据的时候，都会往总线发送消息，而且各个处理器还会不停的从总线嗅探最新的消息，通过这个总线的消息传递来保证各个处理器的协作.

            2. 整个MESI协议运作过程。 1、存在一个变量x=0，在所有处理器中都不存在，处理器1需要用到的时候，由总线去加载完放到对应的cache entry中，此时状态是S。 2、处理器2也需要读取该值，像总线发请求，然后总线从处理器1的高速缓存或者主存中取得最新的变量值返回给处理器2，此时处理器2中的变量状态也是S。 3、此时处理器1需要执行修改，因此向总线发送invalidate的消息，等待所有处理器回复invalidate ack后，对自己高速缓存中的变量进行加独占锁，此时处理器1中的变量状态是E，而处理器2的变量状态是I。 4、最后处理器1计算完后，写回高速缓存中，释放掉独占锁，将变量状态修改为M。 5、处理器2在需要计算的时候流程同上。

            3. cache entry的flag代表了缓存数据的状态，MESI协议中划分为：

               （1）invalid：无效的，标记为I，这个意思就是当前cache entry无效，里面的数据不能使用

               （2）shared：共享的，标记为S，这个意思是当前cache entry有效，而且里面的数据在各个处理器中都有各自的副本，但是这些副本的值跟主内存的值是一样的，各个处理器就是并发的在读而已

               （3）exclusive：独占的，标记为E，这个意思就是当前处理器对这个数据独占了，只有他可以有这个副本，其他的处理器都不能包含这个副本

               （4）modified：修改过的，标记为M，只能有一个处理器对共享数据更新，所以只有更新数据的处理器的cache entry，才是exclusive状态，表明当前线程更新了这个数据，这个副本的数据跟主内存是不一样的

            4. 采用写缓存器和无效队列优化MESI的性能:  

               1. 写缓冲器：修改的操作会变成：将修改的后的值直接写到写缓冲器，然后像主线发送invalidate失效消息，就认为写成功了 , 处理器就去处理别的事情了。在写缓存器收到全部的ack后，处理器再去对高速缓存进行独占和修改的操作。 

               2. 无效队列：同样是为了提高处理器的利用率，将收到的失效请求先放进一个无效队列，收到后就直接返回ack，最后自己慢慢消费无效队列的请求去将高速缓存中的数据失效掉。

                  ![写缓冲器和无效队列优化MESI性能](C:\Users\guozh\Desktop\java\石杉\写缓冲器和无效队列优化MESI性能.jpg)

               3. 引入写缓存器和无效队列带来的有序性和可见性问题

                  1.  可见性：处理器1直接将变量x修改后的值写入写缓冲器，而此时处理器2需要读x变量的值，那么就会去找主线bus加载主存或者处理器中的x变量值，那么此时处理器2读到的就是旧数据，也就是看不到处理器1对x变量的修改。还有一种情况就是，处理器2还没消费无效队列的无效请求，处理器2的高速缓存中依旧存在一个有效的旧值。 

                     有序性： storeLoad重排：处理器先写x的数据，写到了自己的写缓冲器里面了，导致其他处理器读不到，而load操作却正常执行了。结果对其他处理器而言，看起来就像是load先发生，而store确没发生。 storeStore重排：变量a的状态是s，因此将修改后的数据写到了写缓冲器里面，而变量b的状态是m，因此直接独占后直接修改高速缓存中的值。因此在这种情况下，对于其他处理器而言，就相当于a的修改不可见，而b的修改可见，也就是看到他们的顺序重排了。

                  2. 解决: 

                     1. 可见性: Store屏障 + Load屏障

                        加Store屏障 , 就会强制性要求你对一个写操作必须阻塞等待到其他处理器返回invalidate ack之后 , 才对数据加锁修改到高度缓存中,在写数据之后强制flush操作刷到高速缓存或主存中通知其他处理器.

                        加Load屏障, refresh操作就是发现无效队列里有有invalidate消息, 就读取invalidate消息把自己本地高速缓存置为 I (过期)，重新取其他处理器或者主内存中重新获取新值.

                     2. 有序性: Acquire屏障(StoreStore) , Release屏障(StoreLoad)

                        acquire还有release其实就是store和load屏障的两两组合，他们唯一的目的就是保证（本来处理器在执行代码时可能为了提交执行的效率，会让一些不太耗时的先执行，这样就会导致一些耗时的可能就后执行，这样它们就是乱序执行的）加上了此类的屏障，它们必须和前面的指令保持，相同的硬件执行过程，比如强制走主内存呀，强制读取新值呀 ,强制将写缓存器的数据写入高速缓存，这样就能保证其执行的先后顺序不再发生改变。

      5. volatile、synchronized答题套路(从硬件层面)

         1. 硬件层面的原理 -> MESI协议在硬件层面运行的原理 -> 这套原理为何会导致可见性和有序性的问题 -> 各种内存屏障是如何在硬件层面解决可见性和有序性的问题 -> volatile和synchroized是如何加各种内存屏障来分别保证可见性和有序性的.

         2.  首先硬盘和内存的发展数据远不及cpu的发展速度，而要保证cpu的告诉运行就对cpu增加一个高速缓存。但是增加高速缓存以后这就导致了各个cpu之间内的高速缓存造成数据不一致的现象， 

         3. 为了解决这种数据不一致的现象就提出了MESI协议，通过修改各个高速缓存中数据的状态来保证数据一致性的问题。M是修改状态、E是独占状态也就是加锁、S是共享状态、I是无效状态。

         4.  虽然通过MESI可以保证数据的一直性，但是却会大大的影响cpu的处理速度，因为cpu在修改一个处于S状态的数据时，首先会对总线发出一条invalid的通知，告诉所有其他的cpu(持有该数据)数据失效，然后等到接受到其他cpu的invalid ack消息才会对这条数据进行修改，等待ack这个时候其实是阻塞的，cpu只有等待所有ack返回之后才会执行其他的指令，而相对于cpu修改数据而言，等待ack消息的耗时是特别长的，这就体现出了cpu性能下降这个问题。 

         5. 为了解决这个问题，就又对cpu内增加写缓存和失效队列这两个概念，cpu要写一个数据的时候首先发送invalid指令，然后把接收ack这个工作交给写缓存器，然后cpu自己去执行其他的指令。其他的cpu收到invalid消息之后直接把invalid消息扔到失效队列中然后返回invalid ack消息，这样cpu就不用因为等待ack指令而降低处理速度。 

         6. 但是这种情况又会引发可见性和有序性的问题，被扔到写缓存里的数据不会保证什么时候完成，这就可能cpu顺序写入指令1、指令2，将他们扔到写缓存中，但是指令2先执行完成，而其他线程先看到该线程的执行顺序为指令2、指令1，这是有序性的问题。可见性也就不用说了，要修改的数据还在写缓存中等着没执行呢。

         7.  为了解决这种可见性和有序性的问题就引入了内存屏障的概念，store屏障:在修改一个数据之后强制cpu执行完写缓存,等待所有的ack消息把数据刷新到高速缓存或者主内存。load屏障: 在读取一个数据之前强制执行无效队列中对该数据时效的指令，然后从其他高速缓存或者主内存中读取最新数据。

            

   

   

   

   

   

   

   1. threadlocal内存泄漏问题以及解决方案

      1. ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value永远无法回收，造成内存泄漏。 其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。 但是这些被动的预防措施并不能保证不会内存泄漏

   2. 

   3. 

      

   <h3 id="MQ相关">MQ相关</h3> 

   1. 几种MQ的选型: 

      1. https://gitee.com/guoguotju/Java-Interview-Advanced/blob/master/docs/high-concurrency/why-mq.md

   2. 消息队列的高可用

      1. 非分布式的MQ保证高可用(RabbitMQ)

         1. 镜像集群模式
            1. 在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会**存在于多个实例上**，就是说，每个 RabbitMQ 节点都有这个 queue 的一个**完整镜像**，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上。
            2. 好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！第二，这么玩儿，不是分布式的，就**没有扩展性可言**了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并**没有办法线性扩展**你的 queue。

      2. 分布式MQ的高可用(Kafka)

         1. kafka是分布式的，数据并不是都集中在一台机器上，可以分多个机器保存。 kafka的topic的partition多台机器上都有，并且同样的partition机器中，会有一台被选举为leader，其他的为follower。数据的交互式通过leader这台机器交互的，如果leader这台机器宕机了，follow机器会被选举为leader，然后这个继续运行。
         2. **写数据**的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 
            自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。当然，这只是其中一种模式，还可以适当调整这个行为）
         3. **消费**的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

      3. 如何保证消息不被重复消费(保证消费时的幂等性)

         1. kafka消费端可能出现重复消费的问题：通过offset来记录数据的时序性，消费者会定期的返回数据处理到的具体位置offset到kafka，可能消费者处理了数据，但是还没来得及告诉给kafka，导致kafka以为数据没有消费。那么当消费者重启的时候，kafka就会把已经处理了的数据再次发给消费者，导致重复消费.
         2. 在消费者端保障幂等性:
            1. 可以将要消费的数据，在储存到数据库的时候，先保存在内存（比如Set）中，并且和set比较，如果内存中已经有了这个数据，说明已经处理过，那么不再处理。
            2. 通过数据库的主键唯一约束避免重复消费。

      4. 如何保障MQ数据不丢失

         1. RabbitMQ

            1. 生产者发送：可以开启 `confirm` 模式，在生产者那里设置开启 `confirm` 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 `ack` 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 `nack` 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

            2. MQ数据丢失 :

               **开启 RabbitMQ 的持久化**. RabbitMQ 自己挂了，**恢复之后会自动读取之前存储的数据恢复**

               1. 设置持久化有两个步骤：
                  - 创建 queue 的时候将其设置为持久化
                     这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。
                  - 第二个是发送消息的时候将消息的 `deliveryMode` 设置为 2
                     就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。
               2. 持久化可以跟生产者那边的 `confirm` 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 `ack` 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 `ack`，你也是可以自己重发的。

            3. 消费端消费:

               1. 你必须关闭 RabbitMQ 的自动 `ack`，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 `ack` 一把。如果你还没处理完，不就没有 `ack` 了 , 那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。

         2. Kafka

            1. 

   